{
    "DA": {
        "title": "Datenqualität, -schutz und -Governance",
        "short_title": "Datenqualität",
        "quality_dimension_id": 10,
        "icon": "data-quality",
        "criteria": [
            {
                "index": "DA1",
                "criterion_type_id": 10,
                "indicators": {
                    "DA1.1": {
                        "title": "Die Merkmale der Datensätze müssen dokumentiert werden.",
                        "tooltip": "",
                        "A": "Analyse - Definition<br>Zusammensetzung der Daten<br>   - Anzahl der Dateninstanzen / Größe der Daten<br>    - Standards für Datenstrukturen/-Formate    <br>  <br>Prozess der Datenerhebung<br>   - Methode der Datenerhebung<br>   - Quelle der Daten<br>   - Verantwortliche für Datenerhebung<br><br>Datenverarbeitungsschritte<br>   - Erklärung der Features und ihrer möglichen Qualitätsdimensionen und Bereiche der Qualitätsdimensionen<br>   - Vorverarbeitung<br>   - Labeling<br>   - Cleaning<br><br>Pflege der Daten<br>   - Speicherperioden<br>   - Aktualisierung der Daten",
                        "B": "Analyse - Definition<br>Zusammensetzung der Daten<br>   - Anzahl der Dateninstanzen / Größe der Daten<br>    - Standards für Datenstrukturen/-Formate    <br>  <br>Prozess der Datenerhebung<br>   - Methode der Datenerhebung<br>   - Quelle der Daten<br><br>Datenverarbeitungsschritte<br>   - Erklärung der Features und ihrer möglichen Qualitätsdimensionen und Bereiche der Qualitätsdimensionen<br>   - Labeling<br>   - Cleaning<br><br>Pflege des Datensatzes<br>   - Speicherperioden<br>   - Aktualisierung der Daten",
                        "C": "Analyse - Definition<br>Zusammensetzung der Daten<br>   - Anzahl der Dateninstanzen / Größe der Daten<br>    - Standards für Datenstrukturen/-Formate    <br>  <br>Prozess der Datenerhebung<br>   - Quelle der Daten<br><br>Datenverarbeitungsschritte<br>   - Erklärung der Features und ihrer möglichen Qualitätsdimensionen und Bereiche der Qualitätsdimension<br><br>Pflege des Datensatzes<br>   - Speicherperioden<br>   - Aktualisierung der Date",
                        "D": "Die Merkmale der Daten wurden nicht dokumentiert",
                        "docs_id": "1",
                        "reference": "Komponente",
                        "type": "Maßnahme",
                        "weighting": "Maximalwert",
                        "links": "TR1.3",
                        "criterion": "DA1",
                        "dimension": "DA"
                    },
                    "DA1.2": {
                        "title": "Die Risiken, die sich aus fehlender Datenqualität im Kontext des Zweck des KI Systems ergeben müssen analysiert und daraus Datenqualitätsanforderungen abgeleitet werden.",
                        "tooltip": "ISO/IEC 5259",
                        "A": "Analyse - Zweck Definition<br>Basierend auf dem Verwendungszweck und Anwendungsbereiches des KI Systems und den möglichen Risiken müssen relevante Datenqualitätscharakteristiken definiert und spezifische Anforderungen an diese gestellt werden<br><br>Analyse-Risiko<br>Detaillierte Risikoanalyse einschließlich Quantifizierung von Eintrittswahrscheinlichkeiten und Risiken:<br>- Identifikation der möglichen Risiken und ihrer Ursachen<br>- Zuweisung der Risikoverantwortung<br>- Schätzung der Eintrittswahrscheinlichkeit<br>- Schätzung der Aufdeckungswahrscheinlichkeit<br>- Schätzung der Auswirkung<br>- Strukturierte Abstufung und Priorisierung der Risiken <br><br>Mindestens die folgenden Risikoquellen sind zu berücksichtigen:<br>- Datenqualitätscharakteristiken passen nicht zum Verwendungszweck und Anwendungsbereich<br>- Datenqualitätscharakteristiken sind schlecht erfüllt.",
                        "B": "Analyse - Zweck Definition<br>Basierend auf dem Verwendungszweck und Anwendungsbereiches des KI Systems und den möglichen Risiken müssen relevante Datenqualitätscharakteristiken definiert und spezifische Anforderungen an diese gestellt werden<br><br>Analyse-Risiko<br>Limitierte Risikoanalyse mit Fokus auf den Schutzbedarf ohne Quantifizierung von Wahrscheinlichkeiten:<br>- Identifikation der möglichen Risiken<br>- Zuweisung der Risikoverantwortung<br>- Schätzung der Auswirkung<br>- Strukturierte Abstufung und Priorisierung der Risiken<br><br>Mindestens die folgenden Risikoquellen sind zu berücksichtigen:<br>- Datenqualitätscharakteristiken passen nicht zum Verwendungszweck und Anwendungsbereich<br>- Datenqualitätscharakteristiken sind schlecht erfüllt.",
                        "C": "Analyse - Zweck Definition<br>Basierend auf dem Verwendungszweck und Anwendungsbereiches des KI Systems und den möglichen Risiken müssen relevante Datenqualitätscharakteristiken definiert und spezifische Anforderungen an diese gestellt werden<br><br>Analyse-Risiko<br>Hauptsächlich qualitative Abschätzung ohne Wahrscheinlichkeiten:<br>- Identifikation der möglichen Gefährdungen<br>- Zuweisung der Risikoverantwortung<br>- Qualitative Schätzung der Auswirkung<br>- Qualitative Abstufung und Priorisierung der Gefährdungen<br><br>Mindestens die folgenden Risikoquellen sind zu berücksichtigen:<br>- Datenqualitätscharakteristiken passen nicht zum Verwendungszweck und Anwendungsbereich<br>- Datenqualitätscharakteristiken sind schlecht erfüllt.",
                        "D": "Die Risiken und Gefährdungen wurden nicht analysiert und es wurden keine Datenqualitätsanforderungen abgeleitet",
                        "docs_id": "2",
                        "reference": "System/Komponente",
                        "type": "Analyse",
                        "weighting": "Maximalwert",
                        "links": "TR1.1",
                        "criterion": "DA1",
                        "dimension": "DA"
                    },
                    "DA1.3": {
                        "title": "Die Datensätze müssen dem beabsichtigten Zweck des KI-Systems entsprechen und die daraus abgeleiteten Datenqualitätsanforderungen erfüllen.",
                        "tooltip": "Während des Trainings<br>ISO/IEC 5259",
                        "A": "Tech. Maßnahmen - Daten<br>Die in DA 1.2 definierten Datenqualitätscharakteristiken müssen unter Berücksichtigung des Anwendungsbereichs und Verwendungszwecks getestet und bewertet werden. Dies beinhaltet:<br>- Tests und Metriken zum Nachweis der Datenqualitätscharakteristiken<br>- Mindestens müssen Vollständigkeit, Aktualität und Korrektheit betrachtet werden<br><br><br>Die ausgewählten Metriken und Tests sollten möglichst die folgenden Merkmale aufweisen:<br>- wenn durch die Auswahl begründet, sollten die Metriken und Tests sowohl wichtige Basismethoden als auch möglichst fortgeschrittene Methoden (hinsichtlich Komplexität, Informationsgehalt, Implementierungsaufwand, z.B. umfangreiches Prüfwerkzeug) umfassen<br>- die ausgewählten Metriken und Tests sollten wenn möglich durch einen hohen Grad der Automatisierung eine kontinuierliche Evaluation der KI-Modelle erlauben <br>- Festlegung von Schwellenwerten (als Mindestanforderungen an die Funktionalität/Leistung) und Begründung der Schwellenwerte unter Berücksichtigung des Anwendungsbereichs und Verwendungszwecks<br>- falls anwendbar: Abstufung der Metriken und Schwellenwerte nach unterschiedlichen Einsatzszenarien mit Bezug zur Definition des Anwendungsbereichs",
                        "B": "Tech. Maßnahmen - Daten<br>Die in DA 1.2 definierten Datenqualitätscharakteristiken müssen unter Berücksichtigung des Anwendungsbereichs und Verwendungszwecks getestet und bewertet werden. Dies beinhaltet:<br>- Tests und Metriken zum Nachweis der Datenqualitätscharakteristiken<br>- Mindestens müssen Vollständigkeit und Korrektheit betrachtet werden<br><br><br>Die ausgewählten Metriken und Tests sollten möglichst die folgenden Merkmale aufweisen:<br>- wenn durch die Auswahl begründet, sollten die Metriken und Tests  sowohl wichtige Basismethoden als auch möglichst fortgeschrittene Methoden (hinsichtlich Komplexität, Informationsgehalt, Implementierungsaufwand, z.B. umfangreiches Prüfwerkzeug) umfassen<br>- Festlegung von Schwellenwerten (als Mindestanforderungen an die Funktionalität/Leistung) und Begründung der Schwellenwerte unter Berücksichtigung des Anwendungsbereichs und Verwendungszwecks",
                        "C": "Tech. Maßnahmen - Daten<br>Die in DA 1.2 definierten Datenqualitätscharakteristiken müssen unter Berücksichtigung des Anwendungsbereichs und Verwendungszwecks getestet und bewertet werden. Dies beinhaltet:<br>- Tests und Metriken zum Nachweis der Datenqualitätscharakteristiken<br><br><br><br>Die ausgewählten Metriken und Tests sollten möglichst die folgenden Merkmale aufweisen:<br>-es genügen Basismethoden (hinsichtlich Komplexität, Informationsgehalt, Implementierungsaufwand, z.B. eine simple Metrik) <br>- Festlegung von Schwellenwerten (als Mindestanforderungen an die Funktionalität/Leistung) und Begründung der Schwellenwerte unter Berücksichtigung des Anwendungsbereichs und Verwendungszwecks",
                        "D": "Es wurde kein Nachweis geführt, dass der Datensatz dem Zweck des KI-Systems und den Datenqualitätsanforderungen entspricht",
                        "docs_id": "3",
                        "reference": "Komponente",
                        "type": "Maßnahme",
                        "weighting": "Maximalwert",
                        "links": "DA1.4",
                        "criterion": "DA1",
                        "dimension": "DA"
                    },
                    "DA1.4": {
                        "title": "Die Daten des KI-Systems müssen in Entwicklung und Betrieb überwacht werden (können).",
                        "tooltip": "",
                        "A": "Tech. Maßnahme - Betrieb<br>Eine kontinuierliche Überwachung muss für die Implementierung des  KI-Systems vorgesehen sein und auf Basis entsprechender Protokollierung (siehe TR1.7) umgesetzt werden können. Dies beinhaltet die Erprobung folgenden Möglichkeiten:<br><br>- Monitoring der Leistung inklusive einer Überwachung der Modelle und Daten (d.h. einkommende Produktionsdaten und ggf. sich erweiternde Trainingsdatenbasis)<br>- Monitoring von Verzerrungen inklusive einer Überwachung der Daten (d.h. einkommende Produktionsdaten und ggf. sich erweiternde Trainingsdatenbasis) im Kontext der Vermeidung von ungerechtfertigter Diskriminierung und Verzerrungen<br>- Durchführung von Tests (z.B. Sanity Checks), die im Rahmen des Monitorings eingesetzt werden, um etwa Model und Concept Drift  oder auch schädliche Eingabedaten zu erkennen<br>- Falls anwendbar, Durchführung von Tests zur Erkennung von Missbrauch und schädlichen Eingabedaten<br>- Ggf. Qualitätsüberprüfung der sich erweiternden Trainingsdatenbasis  <br><br>Organisatorische Maßnahme - Systemnahe Prozesse<br>Zusätzlich zur technischen Ermöglichung des Monitorings sollten die folgenden Aspekte vorbereitet werden:<br>- Konzept zur (automatischen) Überwachung und -prüfung größerer Veränderungen am KI-System, inklusive bei Soft- und Hardware-Komponenten, aber insbesondere im Fall von Online Learning<br>- Empfohlene Tests müssen als Teil eines kontinuierlichen Testplans dokumentiert sein, insbesondere im Fall von Online Learning<br>- Falls möglich, Mechanismen in Form sinnvoller Definition von Schwellwerten bzw. Szenarien, bei denen (menschliche) Überprüfung und Mitigationsmaßnahmen eintreten sollten<br>- Mechanismen zum Teilen von neuen Informationen über mögliche sicherheitsrelevante Vorfälle und ihrer Vermeidung ",
                        "B": "Tech. Maßnahme - Betrieb<br>Eine kontinuierliche Überwachung muss für die Implementierung des  KI-Systems vorgesehen sein und auf Basis entsprechender Protokollierung (siehe TR1.7) umgesetzt werden können. Dies beinhaltet die folgenden Möglichkeiten:<br><br>- Monitoring der Leistung inklusive einer Überwachung der Modelle und Daten (d.h. einkommende Produktionsdaten und ggf. sich erweiternde Trainingsdatenbasis)<br>- Monitoring von Verzerrungen inklusive einer Überwachung der Daten (d.h. einkommende Produktionsdaten und ggf. sich erweiternde Trainingsdatenbasis) im Kontext der Vermeidung von ungerechtfertigter Diskriminierung und Verzerrungen<br>- Durchführung von Tests (z.B. Sanity Checks), die im Rahmen des Monitorings eingesetzt werden, um etwa Model und Concept Drift, oder auch schädliche Eingabedaten zu erkennen<br><br>Organisatorische Maßnahme - Systemnahe Prozesse<br>Zusätzlich zur technischen Ermöglichung des Monitorings sollten die folgenden Aspekte vorbereitet werden:<br>- Konzept zur (automatischen) Überwachung und -prüfung größerer Veränderungen am KI-System, inklusive bei Soft- und Hardware-Komponenten, aber insbesondere im Fall von Online Learning<br>- Empfohlene Tests müssen als Teil eines kontinuierlichen Testplans dokumentiert sein, insbesondere im Fall von Online Learning",
                        "C": "Tech. Maßnahme - Betrieb<br>Eine kontinuierliche Überwachung muss für die Implementierung des  KI-Systems vorgesehen sein und auf Basis entsprechender Protokollierung (siehe TR1.7) umgesetzt werden können. Dies beinhaltet die folgenden Möglichkeiten:<br><br>- Monitoring der Leistung inklusive einer Überwachung der Modelle und Daten (d.h. einkommende Produktionsdaten und ggf. sich erweiternde Trainingsdatenbasis)<br>- Monitoring von Verzerrungen inklusive einer Überwachung der Daten (d.h. einkommende Produktionsdaten und ggf. sich erweiternde Trainingsdatenbasis) im Kontext der Vermeidung von ungerechtfertigter Diskriminierung und Verzerrungen<br>- Durchführung von Tests (z.B. Sanity Checks), die im Rahmen des Monitorings eingesetzt werden, um etwa Model und Concept Drift, oder auch schädliche Eingabedaten zu erkennen",
                        "D": "",
                        "docs_id": "4",
                        "reference": "Komponente",
                        "type": "Maßnahme",
                        "weighting": "Normal",
                        "links": "DA1.3",
                        "criterion": "DA1",
                        "dimension": "DA"
                    },
                    "DA1.5": {
                        "title": "Es muss bewertet werden, ob die ergriffenen Maßnahmen die festgestellten Risiken auf ein annehmbares Maß vermindert haben und die Qualität des KI-Systems den gesetzten Zielvorgaben entspricht.",
                        "tooltip": "",
                        "A": "Bewertung<br>- Zusammenfassende Betrachtung der Effekte der Durchführung der technischen und organisatorischen Maßnahmen<br>- Abwägung von Wechselwirkungen der ergriffenen Maßnahmen, und Abwägung der Mitigation der Risiken im Zusammenspiel mit den Risiken anderer Qualitätsdimensionen<br>- Ermittlung und Beschreibung des Restrisikos nach Durchführung der technischen und organisatorischen Maßnahmen<br>- Einschätzung durch eine qualifizierte und autorisierte Person, ob das Restrisiko tolerierbar ist<br>- Begründung der Tolerierbarkeit des Restrisikos",
                        "B": "Bewertung<br>- Abwägung von Wechselwirkungen der ergriffenen Maßnahmen, und Abwägung der Mitigation der Risiken im Zusammenspiel mit den Risiken anderer Qualitätsdimensionen<br>- Einschätzung durch eine qualifizierte und autorisierte Person, ob das Restrisiko tolerierbar ist<br>- Begründung der Tolerierbarkeit des Restrisikos",
                        "C": "Bewertung<br>- Einschätzung durch eine qualifizierte und autorisierte Person, ob das Restrisiko tolerierbar ist<br>- Begründung der Tolerierbarkeit des Restrisikos",
                        "D": "Eine Bewertung wurde nicht durchgeführt",
                        "docs_id": "5",
                        "reference": "System",
                        "type": "Bewertung",
                        "weighting": "Maximalwert",
                        "links": "",
                        "criterion": "DA1",
                        "dimension": "DA"
                    }
                },
                "title": "Datenqualität"
            },
            {
                "index": "DA2",
                "criterion_type_id": 11,
                "indicators": {
                    "DA2.1": {
                        "title": "Eine Risikoanalyse für den Schutz benutzter personenbezogener Daten im KI-System muss unter Beachtung des Verwendungszwecks durchgeführt werden.",
                        "tooltip": "Relevant sind hier die <br>DSGVO und die darin enthaltenen Vorgaben für eine Datenschutzfolgeabschätzung (DSFA),  Art.35, DSGVO",
                        "A": "Datenschutzfolgeabschätzung nach DSGVO Art.35 umgesetzt <br><br>oder<br><br>Analyse - Risiko<br>Volle Risikoanalyse einschließlich Quantifizierung von Eintrittswahrscheinlichkeiten und Risiken:<br>- Identifikation der möglichen Risiken und ihrer Ursachen<br>- Zuweisung der Risikoverantwortung<br>- Schätzung der Eintrittswahrscheinlichkeit<br>- Schätzung der Aufdeckungswahrscheinlichkeit<br>- Schätzung der Auswirkung<br>- Strukturierte Abstufung und Priorisierung der Risiken <br><br>Mindestens die folgenden Risikoquellen sind unter Beachtung des Verwendungszwecks (siehe TR1.1) zu berücksichtigen:<br><br>- Datenverarbeitungsprozesse: Erhebung, Speicherung, Verarbeitung und Weitergabe personenbezogener Daten, insbesondere Risiken bei der Umsetzung des Rechts auf Datenübertragbarkeit oder Löschung.<br>- Zweckbindung: Verwendung der Daten über den ursprünglich definierten Zweck hinaus.<br>- Datenminimierung: Erhebung unnötiger oder übermäßiger personenbezogener Daten.<br>- Datenzugriffsrechte und -Speicherung: Unbefugter oder unkontrollierter Zugang zu sensiblen personenbezogenen Daten und Aufbewahrung von Daten über notwendige Fristen hinaus.<br>- Datenweitergabe an Dritte: Unkontrollierte Übertragung personenbezogener Daten an externe Partner oder Dienstleister, Risiken bei der Übermittlung personenbezogener Daten in Länder mit unzureichendem Datenschutz<br>- Missbrauch von Daten: Potenzieller Missbrauch, wie Identitätsdiebstahl oder Diskriminierung durch unsachgemäße Datenverarbeitung.<br>- Anonymisierung und Pseudonymisierung: Unzureichende Anonymisierungs- oder Pseudonymisierungstechniken.<br>- Automatisierte Entscheidungsfindung: Mangelnde Transparenz oder Kontrolle bei automatisierten Entscheidungen, die auf personenbezogenen Daten basieren.",
                        "B": "Analyse - Risiko<br>Limitierte Risikoanalyse mit Fokus auf den Schutzbedarf ohne Quantifizierung von Wahrscheinlichkeiten<br>- Identifikation der möglichen Risiken<br>- Zuweisung der Risikoverantwortung<br>- Schätzung der Auswirkung<br>- Strukturierte Abstufung und Priorisierung der Risiken<br><br>Mindestens die folgenden Risikoquellen sind unter Beachtung des Verwendungszwecks (siehe TR1.1) zu berücksichtigen:<br><br>- Datenverarbeitungsprozesse: Erhebung, Speicherung, Verarbeitung und Weitergabe personenbezogener Daten, insbesondere Risiken bei der Umsetzung des Rechts auf Datenübertragbarkeit oder Löschung.<br>- Zweckbindung: Verwendung der Daten über den ursprünglich definierten Zweck hinaus.<br>- Datenminimierung: Erhebung unnötiger oder übermäßiger personenbezogener Daten.<br>- Datenzugriffsrechte und -Speicherung: Unbefugter oder unkontrollierter Zugang zu sensiblen personenbezogenen Daten und Aufbewahrung von Daten über notwendige Fristen hinaus.<br>- Datenweitergabe an Dritte: Unkontrollierte Übertragung personenbezogener Daten an externe Partner oder Dienstleister, Risiken bei der Übermittlung personenbezogener Daten in Länder mit unzureichendem Datenschutz<br>- Missbrauch von Daten: Potenzieller Missbrauch, wie Identitätsdiebstahl oder Diskriminierung durch unsachgemäße Datenverarbeitung.<br>- Anonymisierung und Pseudonymisierung: Unzureichende Anonymisierungs- oder Pseudonymisierungstechniken.<br>- Automatisierte Entscheidungsfindung: Mangelnde Transparenz oder Kontrolle bei automatisierten Entscheidungen, die auf personenbezogenen Daten basieren.",
                        "C": "Analyse - Risiko<br>Hauptsächlich qualitative Abschätzung der Gefährdungen ohne Wahrscheinlichkeiten<br>- Identifikation der möglichen Gefährdungen:<br>- Zuweisung der Risikoverantwortung<br>- Qualitative Schätzung der Auswirkung<br>- Qualitative Abstufung und Priorisierung der Gefährdungen<br><br>Mindestens die folgenden Risikoquellen sind unter Beachtung des Verwendungszwecks (siehe TR1.1) zu berücksichtigen:<br><br>- Datenverarbeitungsprozesse: Erhebung, Speicherung, Verarbeitung und Weitergabe personenbezogener Daten, insbesondere Risiken bei der Umsetzung des Rechts auf Datenübertragbarkeit oder Löschung.<br>- Datenzugriffsrechte und -Speicherung: Unbefugter oder unkontrollierter Zugang zu sensiblen personenbezogenen Daten und Aufbewahrung von Daten über notwendige Fristen hinaus.<br>- Datenweitergabe an Dritte: Unkontrollierte Übertragung personenbezogener Daten an externe Partner oder Dienstleister, Risiken bei der Übermittlung personenbezogener Daten in Länder mit unzureichendem Datenschutz<br>- Missbrauch von Daten: Potenzieller Missbrauch, wie Identitätsdiebstahl oder Diskriminierung durch unsachgemäße Datenverarbeitung.<br>- Anonymisierung und Pseudonymisierung: Unzureichende Anonymisierungs- oder Pseudonymisierungstechniken.",
                        "D": "Es wurde keine Risikoanalyse durchgeführt.",
                        "docs_id": "6",
                        "reference": "System",
                        "type": "Analyse",
                        "weighting": "Minimalwert",
                        "links": "DA1.1, DA1.2, TR1.1 (Verwendungszweck)",
                        "criterion": "DA2",
                        "dimension": "DA"
                    },
                    "DA2.2": {
                        "title": "Es müssen nicht-KI-spezifische Maßnahmen ergriffen werden um unter Beachtung des identifizierten Risikos den Schutz personenbezogener Daten zu gewährleisten.",
                        "tooltip": "Relevant sind hier die <br>DSGVO und die darin enthaltenen Vorgaben für eine Datenschutzfolgeabschätzung (DSFA),  Art.35, DSGVO",
                        "A": "Maßnahmen entsprechend der Datenschutzfolgeabschätzung nach DSGVO Art.35 umgesetzt <br><br>oder<br><br>Orga. Maßnahmen - Governance / Systemnahe Prozesse<br>- Implementierung von Mechanismen zur Datenminimierung, um nur die notwendigen personenbezogenen Daten zu erheben und zu verarbeiten.<br>- Einführung strenger Zugriffskontrollen und von Berechtigungsmanagement, um sicherzustellen, dass nur autorisierte Personen Zugang zu personenbezogenen Daten haben.<br>- Einführung von Mechanismen zum Speicherfristen-Management, um Daten nach Ablauf der festgelegten Fristen sicher zu löschen.<br>- Sicherstellung, dass bei der Weitergabe von Daten an Dritte klare vertragliche Vereinbarungen bestehen<br>- Einführung klarer Einwilligungsprozesse und transparenter Informationsmethoden für betroffene Personen.<br>- Implementierung eines Notfallplans für die Erkennung, Meldung und Behebung von Datenschutzverletzungen innerhalb der gesetzlich vorgeschriebenen Frist.<br>- Sicherstellung, dass bei Übermittlungen personenbezogener Daten in Drittländer geeignete Schutzmaßnahmen (z.B. Standardvertragsklauseln) implementiert sind.<br><br>Tech. Maßnahmen - Daten<br>- Sicherstellung, dass Datenschutzmaßnahmen bereits in der Entwicklung und Implementierung der Systeme integriert sind (\"data-protection-by-design\")<br>- Einsatz von Verschlüsselungstechniken zum Schutz gespeicherter Daten<br>- Einsatz von Anonymisierung, Pseudonymisierung und weiterer Technologien wie Differential Privacy, um die Informationen in personenbezogene Daten zu schützen mit Begründung der Notwendigkeit und Wirksamkeit der Maßnahmen<br>- Implementierung von Prozessen, um betroffene Personen über automatisierte Entscheidungen und deren Logik zu informieren (ggfls.. Bezug zu KI-spezifischen Maßnahmen zu Erklärbarkeit, siehe TR2)<br><br>Tech. Maßnahmen - Betrieb<br>- Regelmäßige Prüfungen und Audits der Datenverarbeitungsprozesse und -praktiken, um sicherzustellen, dass die Datenschutzanforderungen entsprechend dem Verwendungszweck eingehalten werden.",
                        "B": "Orga. Maßnahmen - Governance / Systemnahe Prozesse<br>- Einführung strenger Zugriffskontrollen und von Berechtigungsmanagement, um sicherzustellen, dass nur autorisierte Personen Zugang zu personenbezogenen Daten haben.<br>- Einführung von Mechanismen zum Speicherfristen-Management, um Daten nach Ablauf der festgelegten Fristen sicher zu löschen.<br>- Sicherstellung, dass bei der Weitergabe von Daten an Dritte klare vertragliche Vereinbarungen bestehen<br>- Einführung klarer Einwilligungsprozesse und transparenter Informationsmethoden für betroffene Personen.<br>- Implementierung eines Notfallplans für die Erkennung, Meldung und Behebung von Datenschutzverletzungen innerhalb der gesetzlich vorgeschriebenen Frist.<br>- Sicherstellung, dass bei Übermittlungen personenbezogener Daten in Drittländer geeignete Schutzmaßnahmen (z.B. Standardvertragsklauseln) implementiert sind.<br><br>Tech. Maßnahmen - Daten<br>- Sicherstellung, dass Datenschutzmaßnahmen bereits in der Entwicklung und Implementierung der Systeme integriert sind (\"data-protection-by-design\")<br>- Einsatz von Verschlüsselungstechniken zum Schutz gespeicherter Daten<br>- Einsatz von Anonymisierung, Pseudonymisierung und weiterer Technologien wie Differential Privacy, um die Informationen in personenbezogene Daten zu schützen mit Begründung der Notwendigkeit und Wirksamkeit der Maßnahmen<br><br>Tech. Maßnahmen - Betrieb<br>- Regelmäßige Prüfungen und Audits der Datenverarbeitungsprozesse und -praktiken, um sicherzustellen, dass die Datenschutzanforderungen entsprechend dem Verwendungszweck eingehalten werden.",
                        "C": "Orga. Maßnahmen - Governance / Systemnahe Prozesse<br>- Einführung strenger Zugriffskontrollen und von Berechtigungsmanagement, um sicherzustellen, dass nur autorisierte Personen Zugang zu personenbezogenen Daten haben.<br>- Einführung von Mechanismen zum Speicherfristen-Management, um Daten nach Ablauf der festgelegten Fristen sicher zu löschen.<br>- Sicherstellung, dass bei der Weitergabe von Daten an Dritte klare vertragliche Vereinbarungen bestehen<br>- Implementierung eines Notfallplans für die Erkennung, Meldung und Behebung von Datenschutzverletzungen innerhalb der gesetzlich vorgeschriebenen Frist.<br>- Sicherstellung, dass bei Übermittlungen personenbezogener Daten in Drittländer geeignete Schutzmaßnahmen (z.B. Standardvertragsklauseln) implementiert sind.<br><br>Tech. Maßnahmen - Daten<br>- Einsatz von Verschlüsselungstechniken zum Schutz gespeicherter Daten<br>- Einsatz von Anonymisierung, Pseudonymisierung und weiterer Technologien wie Differential Privacy, um die Informationen in personenbezogene Daten zu schützen mit Begründung der Notwendigkeit und Wirksamkeit der Maßnahmen",
                        "D": "Es wurden keine nicht-KI-spezifischen Maßnahmen zum Schutz personenbezogener Daten ergriffen.",
                        "docs_id": "7",
                        "reference": "System/Komponente",
                        "type": "Maßnahme",
                        "weighting": "Maximalwert",
                        "links": "DA1.2, DA1.3, TR2, MA1, CY1.5",
                        "criterion": "DA2",
                        "dimension": "DA"
                    },
                    "DA2.3": {
                        "title": "Es müssen Maßnahmen und Sicherheitskontrollen vorhanden sein, um KI-spezifische Angriffe die während der Vorbereitungs- und Modelltrainingsphase der KI-Modelle stattfinden zu mitigieren.",
                        "tooltip": "Aus Plausibilitätsgründen <br>sind nicht zwangsläufig alle Maßnahmen in CY2.3 relevant zum Schutz personenbezogener Daten, z.B., wenn es um das Schutzziel Availability geht.",
                        "A": "Tech. Maßnahmen - Test<br>(Metriken KI-Modelle Angriffsszenarien Vorbereitungs- und Modelltrainingsphase): Prüfung von durch den Anwendungsbereich begründeter Auswahl und Anzahl an Metriken und Tests der adversariellen Robustheit in Bezug auf Angriffsszenarien der Vorbereitungs- und Modelltrainingsphase, die gegen Vertraulichkeit, Integrität oder Verfügbarkeit des KI-Systems gerichtet sein können.  <br>- Dies schließt eine Prüfung mit Basis- und fortgeschrittenen Methoden mindestens der folgende Angriffsarten ein:<br> a) data poisoning<br> b) label poisoning<br> c) KI-spezifische backdoor attacks<br><br>- Penetrationstests von Systemaspekten mit Bezug auf KI-spezifische Angriffe während der Vorbereitungs- und Modelltrainingsphase sollten durchgeführten werden.<br><br>Die ausgewählten Metriken und Tests sollten mindestens die folgenden Merkmale aufweisen:<br>- Methoden sollten für jedes KI-Modell im und für das KI-System als Ganzes angewendet werden, falls dieses einen gesammelten Output erzeugt<br>- wenn durch die Auswahl begründet, sollten die Metriken und Tests sowohl wichtige Basismethoden als auch fortgeschrittene Methoden (hinsichtlich Komplexität, Informationsgehalt, Implementierungsaufwand, z.B. umfangreiches Prüfwerkzeug) umfassen<br>- die ausgewählten Metriken und Tests sollten wenn möglich einen hohen Grad der Automatisierung erlauben<br>- ggf. Festlegung von Schwellenwerten (als Mindestanforderungen an die Funktionalität/Leistung) und Begründung der Schwellenwerte unter Berücksichtigung des Anwendungsbereichs und Verwendungszwecks<br>- falls anwendbar: Abstufung der Metriken und Schwellenwerte nach unterschiedlichen Einsatzszenarien mit Bezug zur Definition des Anwendungsbereichs.<br><br>Tech. Maßnahmen - Modell<br>- angemessene KI-spezifische Sicherheitskontrollen zur Mitigation des identifizierten Risikos von Angriffen in der  Vorbereitungs- und Modelltrainingsphase des KI-Systems müssen auf Modellebene eingeführt werden  (z. B Datenfiltermethoden oder Suchsysteme für Backdoors, Unsicherheitsmethoden)<br>- es sollten Robustheitsnachweise für jedes KI-Modell geführt werden zu verschiedenen relevanten Angriffsarten<br><br>Tech. Maßnahmen - System<br>- angemessene KI-spezifische oder nicht-KI-spezifische Sicherheitskontrollen zur Mitigation des identifizierten Risikos von Angriffen von Angriffen in der  Vorbereitungs- und Modelltrainingsphase des KI-Systems müssen auf Systemebene  eingeführt werden. <br>- klassisches Sicherheitskontrollen des gesamten Systems im Betrieb sollten vorhergesehen und eingeplant sein einschließlich einer Einbindung in ein existierendes CSMS.<br>- Red Teaming des gesamten Systems mit Bezug auf KI-spezifische Angriffe während der Vorbereitungs- und Modelltrainingsphase sollten durchgeführten werden.",
                        "B": "Tech. Maßnahmen - Test (Metriken KI-Modelle Angriffsszenarien Vorbereitungs- und Modelltrainingsphase): <br>Prüfung von durch den Anwendungsbereich begründeter Auswahl und Anzahl an Metriken und Tests der adversariellen Robustheit in Bezug auf Angriffsszenarien der Vorbereitungs- und Modelltrainingsphase, die gegen Vertraulichkeit, Integrität oder Verfügbarkeit des KI-Systems gerichtet sein können.  <br>- Dies schließt eine Prüfung mit Basis-Methoden mindestens der folgende Angriffsarten ein:<br> a) data poisoning<br> b) label poisoning<br> c) KI-spezifische backdoor attacks<br><br>Die ausgewählten Metriken und Tests sollten mindestens die folgenden Merkmale aufweisen:<br>- Methoden sollten für jedes KI-Modell im und für das KI-System als Ganzes angewendet werden, falls dieses einen gesammelten Output erzeugt<br>- wenn durch die Auswahl begründet, sollten die Metriken und Tests sowohl wichtige Basismethoden als auch fortgeschrittene Methoden (hinsichtlich Komplexität, Informationsgehalt, Implementierungsaufwand, z.B. umfangreiches Prüfwerkzeug) umfassen<br><br>- ggf. Festlegung von Schwellenwerten (als Mindestanforderungen an die Funktionalität/Leistung) und Begründung der Schwellenwerte unter Berücksichtigung des Anwendungsbereichs und Verwendungszwecks<br><br><br>Tech. Maßnahmen - Modell<br>- angemessene KI-spezifische Sicherheitskontrollen zur Mitigation des identifizierten Risikos von Angriffen in der  Vorbereitungs- und Modelltrainingsphase des KI-Systems müssen auf Modellebene eingeführt werden  (z. B Datenfiltermethoden oder Suchsysteme für Backdoors, Unsicherheitsmethoden)<br>- es sollten möglichst Robustheitsnachweise für jedes KI-Modell geführt werden zu verschiedenen relevanten Angriffsarten<br><br>Tech. Maßnahmen - System<br>- angemessene KI-spezifische oder nicht-KI-spezifische Sicherheitskontrollen zur Mitigation des identifizierten Risikos von Angriffen von Angriffen in der  Vorbereitungs- und Modelltrainingsphase des KI-Systems müssen auf Systemebene  eingeführt werden. ",
                        "C": "Tech. Maßnahmen - Test (Metriken KI-Modelle Angriffsszenarien Vorbereitungs- und Modelltrainingsphase): <br>Prüfung von durch den Anwendungsbereich begründeter Auswahl und Anzahl an Metriken und Tests der adversariellen Robustheit in Bezug auf Angriffsszenarien der Vorbereitungs- und Modelltrainingsphase, die gegen Vertraulichkeit, Integrität oder Verfügbarkeit des KI-Systems gerichtet sein können.  <br>- Dies schließt eine Prüfung mit Basis-Methoden möglichst der folgende Angriffsarten ein:<br> a) data poisoning<br> b) label poisoning<br> c) KI-spezifische backdoor attacks<br><br>Die ausgewählten Metriken und Tests sollten möglichst die folgenden Merkmale aufweisen:<br>- Methoden können entweder für jedes KI-Modell oder für das KI-System als Ganzes angewendet werden, je nachdem, was sinnvoller und machbar ist <br>- es genügen Basismethoden (hinsichtlich Komplexität, Informationsgehalt, Implementierungsaufwand, z.B. eine simple Metrik) <br>- ggf. Festlegung von Schwellenwerten (als Mindestanforderungen an die Funktionalität/Leistung) und Begründung der Schwellenwerte unter Berücksichtigung des Anwendungsbereichs und Verwendungszwecks<br><br>Tech. Maßnahmen - Modell<br>- angemessene KI-spezifische Sicherheitskontrollen zur Mitigation des identifizierten Risikos von Angriffen in der  Vorbereitungs- und Modelltrainingsphase des KI-Systems müssen auf Modellebene eingeführt werden  (z. B Datenfiltermethoden oder Suchsysteme für Backdoors, Unsicherheitsmethoden)<br>- es sollten möglichst Robustheitsnachweise für jedes KI-Modell geführt werden zu verschiedenen relevanten Angriffsarten<br><br>Tech. Maßnahmen - System<br>- angemessene KI-spezifische oder nicht-KI-spezifische Sicherheitskontrollen zur Mitigation des identifizierten Risikos von Angriffen von Angriffen in der  Vorbereitungs- und Modelltrainingsphase des KI-Systems müssen auf Systemebene  eingeführt werden. ",
                        "D": "Es wurden keine Maßnahmen ergriffen um KI-spezifische Angriffe während der Vorbereitungs- und Modelltrainingsphase zu mitigieren.",
                        "docs_id": "8",
                        "reference": "System/Komponente",
                        "type": "Maßnahme",
                        "weighting": "Maximalwert",
                        "links": "CY2.2, CY2.3",
                        "criterion": "DA2",
                        "dimension": "DA"
                    },
                    "DA2.4": {
                        "title": "Es müssen Maßnahmen und Sicherheitskontrollen vorhanden sein, um KI-spezifische Angriffe die während des Betriebs auftreten können zu mitigieren.",
                        "tooltip": "Aus Plausibilitätsgründen <br>sind nicht zwangsläufig alle Maßnahmen in CY1.6 relevant zum Schutz personenbezogener Daten, z.B., wenn es um das Schutzziel Availability geht.",
                        "A": "Tech. Maßnahmen - Test (Metriken KI-Modelle Angriffe on Inferenz- und Deploymentphase): <br>Prüfung von durch den Anwendungsbereich begründeter Auswahl und Anzahl an Metriken und Tests der adversariellen Robustheit in Bezug auf Angriffsszenarien in der Inferenz - und Deploymentphase, die gegen Vertraulichkeit, Integrität oder Verfügbarkeit des KI-Systems gerichtet sein können. <br>- Dies schließt eine Prüfung mit Basis- und fortgeschrittenen Methoden mindestens der folgende Angriffsarten ein:<br> a) evasion attacks,<br> b) latency attacks<br> c) model extraction attacks <br> d)  data reconstruction oder property inference attacks<br> e) prompt injection attacks oder jailbreaks <br>- Penetrationstests  von Systemaspekten mit Bezug auf KI-spezifische Angriffe während des Betriebs sollten durchgeführten werden.<br><br>Die ausgewählten Metriken und Tests sollten mindestens die folgenden Merkmale aufweisen:<br>- Methoden sollten für jedes KI-Modell im und für das KI-System als Ganzes angewendet werden, falls dieses einen gesammelten Output erzeugt<br>- wenn durch die Auswahl begründet, sollten die Metriken und Tests sowohl wichtige Basismethoden als auch fortgeschrittene Methoden (hinsichtlich Komplexität, Informationsgehalt, Implementierungsaufwand, z.B. umfangreiches Prüfwerkzeug) umfassen<br>- die ausgewählten Metriken und Tests sollten wenn möglich einen hohen Grad der Automatisierung erlauben<br>- ggf. Festlegung von Schwellenwerten (als Mindestanforderungen an die Funktionalität/Leistung) und Begründung der Schwellenwerte unter Berücksichtigung des Anwendungsbereichs und Verwendungszwecks<br>- falls anwendbar: Abstufung der Metriken und Schwellenwerte nach unterschiedlichen Einsatzszenarien mit Bezug zur Definition des Anwendungsbereichs.<br><br>Tech. Maßnahmen - Modell<br>- angemessene KI-spezifische Sicherheitskontrollen und technische Maßnahmen zur Mitigation des identifizierten Risikos von Angriffen in der Inferenzphase und während des Deployment des KI-Systems müssen auf Modellebene eingeführt werden (z.B. adversarielles Training, Methoden zur Stärkung der Modellrobustheit oder Unsicherheitsmethoden)<br>- es sollten Robustheitsnachweise für jedes KI-Modell geführt werden zu verschiedenen relevanten Angriffsarten<br><br>Tech. Maßnahmen - System<br>- angemessene KI-spezifische oder nicht-KI-spezifische Sicherheitskontrollen zur Mitigation des identifizierten Risikos von Angriffen in der Inferenzphase und während des Deployment des KI-Systems müssen auf Systemebene  eingeführt werden (z.B. Monitoring von Inputs, siehe MA2.3)<br>- klassisches Sicherheitskontrollen des gesamten Systems im Betrieb sollten vorhergesehen und eingeplant sein einschließlich einer Einbindung in ein existierendes CSMS.<br>- Red Teaming des gesamten Systems mit Bezug auf KI-spezifische Angriffe während der Betriebsphase sollten durchgeführten werden",
                        "B": "Tech. Maßnahmen - Test (Metriken KI-Modelle Angriffe on Inferenz- und Deploymentphase): <br>Prüfung von durch den Anwendungsbereich begründeter Auswahl und Anzahl an Metriken und Tests der adversariellen Robustheit in Bezug auf Angriffsszenarien in der Inferenz - und Deploymentphase, die gegen Vertraulichkeit, Integrität oder Verfügbarkeit des KI-Systems gerichtet sein können. <br>- Dies schließt eine Prüfung mit Basis-Methoden mindestens der folgende Angriffsarten ein:<br> a) evasion attacks,<br> b) latency attacks<br> c) model extraction attacks <br> d)  data reconstruction oder property inference attacks<br> e) prompt injection attacks oder jailbreaks <br>- Penetrationstests des gesamten Systems mit Bezug auf KI-spezifische Angriffe während des Betriebs sollten durchgeführten werden.<br><br>Die ausgewählten Metriken und Tests sollten mindestens die folgenden Merkmale aufweisen:<br>- Methoden sollten für jedes KI-Modell im und für das KI-System als Ganzes angewendet werden, falls dieses einen gesammelten Output erzeugt<br>- wenn durch die Auswahl begründet, sollten die Metriken und Tests sowohl wichtige Basismethoden als auch fortgeschrittene Methoden (hinsichtlich Komplexität, Informationsgehalt, Implementierungsaufwand, z.B. umfangreiches Prüfwerkzeug) umfassen<br>- die ausgewählten Metriken und Tests sollten wenn möglich einen hohen Grad der Automatisierung erlauben<br>- ggf. Festlegung von Schwellenwerten (als Mindestanforderungen an die Funktionalität/Leistung) und Begründung der Schwellenwerte unter Berücksichtigung des Anwendungsbereichs und Verwendungszwecks<br>- falls anwendbar: Abstufung der Metriken und Schwellenwerte nach unterschiedlichen Einsatzszenarien mit Bezug zur Definition des Anwendungsbereichs.<br><br>Tech. Maßnahmen - Modell<br>- angemessene KI-spezifische Sicherheitskontrollen zur Mitigation des identifizierten Risikos von Angriffen in der Inferenzphase und während des Deployment des KI-Systems müssen auf Modellebene eingeführt werden (z.B. adversarielles Training, Methoden zur Stärkung der Modellrobustheit oder Unsicherheitsmethoden)<br>- es sollten möglichst Robustheitsnachweise für jedes KI-Modell geführt werden zu verschiedenen relevanten Angriffsarten<br><br>Tech. Maßnahmen - System<br>- angemessene KI-spezifische oder nicht-KI-spezifische Sicherheitskontrollen zur Mitigation des identifizierten Risikos von Angriffen in der Inferenzphase und während des Deployment des KI-Systems müssen auf Systemebene  eingeführt werden. (z.B. Monitoring von Inputs, siehe MA2.3) <br>- klassisches Sicherheitskontrollen des gesamten Systems im Betrieb sollten vorhergesehen und eingeplant sein einschließlich einer Einbindung in ein existierendes CSMS.",
                        "C": "Tech. Maßnahmen - Test (Metriken KI-Modelle Angriffe on Inferenz- und Deploymentphase): <br>Prüfung von durch den Anwendungsbereich begründeter Auswahl und Anzahl an Metriken und Tests der adversariellen Robustheit in Bezug auf Angriffsszenarien in der Inferenz - und Deploymentphase, die gegen Vertraulichkeit, Integrität oder Verfügbarkeit des KI-Systems gerichtet sein können. <br>- Dies schließt eine Prüfung mit Basis-Methoden möglichst der folgende Angriffsarten ein:<br> a) evasion attacks,<br> b) latency attacks<br> c) model extraction attacks <br> d)  data reconstruction oder property inference attacks<br> e) prompt injection attacks oder jailbreaks <br><br>Die ausgewählten Metriken und Tests sollten möglichst die folgenden Merkmale aufweisen:<br>- Methoden können entweder für jedes KI-Modell oder für das KI-System als Ganzes angewendet werden, je nachdem, was sinnvoller und machbar ist <br>- es genügen Basismethoden (hinsichtlich Komplexität, Informationsgehalt, Implementierungsaufwand, z.B. eine simple Metrik) <br>- ggf. Festlegung von Schwellenwerten (als Mindestanforderungen an die Funktionalität/Leistung) und Begründung der Schwellenwerte unter Berücksichtigung des Anwendungsbereichs und Verwendungszwecks<br><br>Tech. Maßnahmen - Modell<br>- angemessene KI-spezifische Sicherheitskontrollen zur Mitigation des identifizierten Risikos von Angriffen in der Inferenzphase und während des Deployment des KI-Systems müssen auf Modellebene eingeführt werden (z.B. adversarielles Training, Methoden zur Stärkung der Modellrobustheit oder Unsicherheitsmethoden)<br>- es sollten Robustheitsnachweise für jedes KI-Modell geführt werden zu verschiedenen relevanten Angriffsarten<br><br>Tech. Maßnahmen - System<br>- angemessene KI-spezifische oder nicht-KI-spezifische Sicherheitskontrollen zur Mitigation des identifizierten Risikos von Angriffen in der Inferenzphase und während des Deployment des KI-Systems müssen auf Systemebene  eingeführt werden. (z.B. Monitoring von Inputs, siehe MA2.3)<br>- klassisches Sicherheitskontrollen des gesamten Systems im Betrieb sollten vorhergesehen und eingeplant sein einschließlich einer Einbindung in ein existierendes CSMS.",
                        "D": "Es wurden keine Maßnahmen ergriffen um KI-spezifische Angriffe während des Betriebs zu mitigieren.",
                        "docs_id": "9",
                        "reference": "System/Komponente",
                        "type": "Maßnahme",
                        "weighting": "Maximalwert",
                        "links": "CY2.2, CY2.3",
                        "criterion": "DA2",
                        "dimension": "DA"
                    },
                    "DA2.5": {
                        "title": "Es müssen Maßnahmen und Sicherheitskontrollen vorhanden sein, um fehlerhafte Nutzung und beabsichtigten Missbrauch des KI-Systems zu verhindern.",
                        "tooltip": "Dies sollte <br>vor allem die fehlerhafte Nutzung oder den Missbrauch des Systems abdecken, welche personenbezogene Daten fälschlich verwendet oder offenlegt",
                        "A": "Org. Maßnahmen - Systemnahe Prozesse<br>- Prozesse müssen eingeführt sein um den möglichen beabsichtigten Missbrauchs des KI-Systems im Betrieb adressieren zu können, einschließlich der Einbindung möglicher Abschaltungsmechanismen im Risikomanagement. <br>- Prozesse sollten eingeführt sein, um eine durch Monitoringsysteme und Logging festgestellte fehlerhafte Nutzung im Betrieb adressieren zu können<br>- Prozesse sollten insbesondere darauf achten, dass neben der Funktionalität, Integrität und Verfügbarkeit des KI-Systems auch die unter den unterschiedlichen Qualitätsdimensionen definierten Ziele geschützt sind bei fehlerhafter Nutzung oder Missbrauch, also Wahrung des Schutzes personenbezogener oder proprietärer Daten, des Schutzes vor Nicht-Diskriminierung, des Autonomiegrades und der dazugehörigen menschlichen Kontrollmechanismen<br><br><br>Tech. Maßnahmen - System / Betrieb<br>- Sicherheitskontrollen zur Verhinderung von Missbrauch und fehlerhafter Nutzung sollten vorgesehen sein und wenn möglich vor der Produktionsphase implementiert werden. Dies schließt Methoden der Prompt/Output-Filterung bei generativer KI mit ein. Zu Absicherung gegen Datenzugang siehe auch CY1.5<br>- Es muss Vorgesehen sein Inferenzeingaben, Anfragen und Prompts als Teil des Monitoring und Logging aufgezeichnet zu  werden, um im Falle einer Fehlnutzung, einer Kompromittierung oder eines Missbrauchs eine Untersuchung zu ermöglichen.<br>- Red Teaming des gesamten Systems mit Bezug auf Missbrauch oder fehlerhafte Nutzung des KI-Systems sollte durchgeführt werden",
                        "B": "Org. Maßnahmen - Systemnahe Prozesse<br>- Prozesse müssen eingeführt sein um den möglichen beabsichtigten Missbrauchs des KI-Systems im Betrieb adressieren zu können, einschließlich der Einbindung möglicher Abschaltungsmechanismen <br>- Prozesse sollten eingeführt sein, um eine durch Monitoringsysteme und Logging festgestellte fehlerhafte Nutzung im Betrieb adressieren zu können<br>- Prozesse sollten insbesondere darauf achten, dass neben der Funktionalität, Integrität und Verfügbarkeit des KI-Systems auch die unter den unterschiedlichen Qualitätsdimensionen definierten Ziele geschützt sind bei fehlerhafter Nutzung oder Missbrauch, also Wahrung des Schutzes personenbezogener oder proprietärer Daten, des Schutzes vor Nicht-Diskriminierung, des Autonomiegrades und der dazugehörigen Menschlichen Kontrollmechanismen<br><br><br>Tech. Maßnahmen - Betrieb<br>- Es muss Vorgesehen sein Inferenzeingaben, Anfragen und Prompts als Teil des Monitoring und Logging aufgezeichnet zu  werden, um im Falle einer Fehlnutzung, einer Kompromittierung oder eines Missbrauchs eine Untersuchung zu ermöglichen.",
                        "C": "Org. Maßnahmen - Systemnahe Prozesse<br>- Prozesse müssen eingeführt sein um den möglichen beabsichtigten Missbrauchs des KI-Systems im Betrieb adressieren zu können, einschließlich der Einbindung möglicher Abschaltungsmechanismen <br>- Prozesse sollten eingeführt sein, um eine durch Monitoringsysteme und Logging festgestellte fehlerhafte Nutzung im Betrieb adressieren zu können<br>- Prozesse sollten insbesondere darauf achten, dass neben der Funktionalität, Integrität und Verfügbarkeit des KI-Systems auch die unter den unterschiedlichen Qualitätsdimensionen definierten Ziele geschützt sind bei fehlerhafter Nutzung oder Missbrauch, also Wahrung des Schutzes personenbezogener oder proprietärer Daten, des Schutzes vor Nicht-Diskriminierung, des Autonomiegrades und der dazugehörigen Menschlichen Kontrollmechanismen",
                        "D": "Es sind keine Maßnahmen vorhanden um fehlerhafte Nutzung und Missbrauch des KI-Systems zu verhindern",
                        "docs_id": "10",
                        "reference": "System/Komponente",
                        "type": "Maßnahme",
                        "weighting": "Normal",
                        "links": "",
                        "criterion": "DA2",
                        "dimension": "DA"
                    },
                    "DA2.6": {
                        "title": " möglich sein, ihre mit personenbezogenen Daten einhergehenden Rechte zu Datenverwaltung, -löschung  und -benutzung sowie Informationspflichten auch im Betrieb des KI-Systems wahrzunehmen.",
                        "tooltip": "",
                        "A": "Orga. Maßnahme - Benutzerinstruktion<br>- Bereitstellung einer klaren und verständlichen Erklärung der Datenverarbeitung, der Betroffenenrechte und der Verantwortlichen <br>- Dokumentation und Protokollierung (\"Logging\") aller Datenverarbeitungsaktivitäten sowie der Ausübung der Betroffenenrechte (siehe TR1.7)<br><br>Orga. Maßnahme  - Governance<br>- Gewährleistung, dass Nutzer über Änderungen der Datenverarbeitung oder -nutzung zeitnah informiert werden.<br>- Einrichtung klarer Kanäle, um Betroffenen bei der Ausübung ihrer Rechte zu unterstützen (siehe MA1.4)<br>- Implementierung eines Systems zur Einholung und Verwaltung der expliziten Einwilligung zur Datenverarbeitung.<br><br>Tech. Maßnahme - Betrieb<br>- Bereitstellung leicht zugänglicher Funktionen für Betroffene, um ihre Rechte auf Auskunft, Berichtigung, Löschung und Datenübertragbarkeit auszuüben einschließlich Möglichkeiten der Datenverarbeitung zu widersprechen oder ihre Einwilligung jederzeit zu widerrufen.<br>- Integration von Mechanismen, die eine automatische Löschung personenbezogener Daten nach Ablauf der Speicherfrist oder auf Anfrage ermöglichen.",
                        "B": "Orga. Maßnahme - Benutzerinstruktion<br>- Bereitstellung einer klaren und verständlichen Erklärung der Datenverarbeitung, der Betroffenenrechte und der Verantwortlichen <br>- Dokumentation und Protokollierung (\"Logging\") aller Datenverarbeitungsaktivitäten sowie der Ausübung der Betroffenenrechte (siehe  TR1.7)<br><br>Orga. Maßnahme  - Governance<br>- Einrichtung klarer Kanäle, um Betroffenen bei der Ausübung ihrer Rechte zu unterstützen (siehe MA1.4)<br>- Implementierung eines Systems zur Einholung und Verwaltung der expliziten Einwilligung zur Datenverarbeitung.<br><br>Tech. Maßnahme - Betrieb<br>- Integration von Mechanismen, die eine automatische Löschung personenbezogener Daten nach Ablauf der Speicherfrist oder auf Anfrage ermöglichen.",
                        "C": "Orga. Maßnahme - Benutzerinstruktion<br>- Bereitstellung einer klaren und verständlichen Erklärung der Datenverarbeitung, der Betroffenenrechte und der Verantwortlichen <br><br>Orga. Maßnahme  - Governance<br>- Einrichtung klarer Kanäle, um Betroffenen bei der Ausübung ihrer Rechte zu unterstützen (siehe MA1.4)<br>- Implementierung eines Systems zur Einholung und Verwaltung der expliziten Einwilligung zur Datenverarbeitung.<br><br>Tech. Maßnahme - Betrieb<br>- Integration von Mechanismen, die eine automatische Löschung personenbezogener Daten nach Ablauf der Speicherfrist oder auf Anfrage ermöglichen.",
                        "D": "Möglichkeiten für natürliche Personen ihre Rechte in Bezug auf personenbezogene Daten wahrzunehmen bestehen nicht",
                        "docs_id": "11",
                        "reference": "Komponente",
                        "type": "Maßnahme",
                        "weighting": "Maximalwert",
                        "links": "TR1.7, MA1.4",
                        "criterion": "DA2",
                        "dimension": "DA"
                    },
                    "DA2.7": {
                        "title": "Es muss bewertet werden, ob die ergriffenen Maßnahmen die festgestellten Risiken auf ein annehmbares Maß vermindert haben und die Qualität des KI-Systems den gesetzten Zielvorgaben entspricht.",
                        "tooltip": "",
                        "A": "Bewertung<br>- Zusammenfassende Betrachtung der Effekte der Durchführung der technischen und organisatorischen Maßnahmen<br>- Abwägung von Wechselwirkungen der ergriffenen Maßnahmen, und Abwägung der Mitigation der Risiken im Zusammenspiel mit den Risiken anderer Qualitätsdimensionen<br>- Ermittlung und Beschreibung des Restrisikos nach Durchführung der technischen und organisatorischen Maßnahmen<br>- Einschätzung durch eine qualifizierte und autorisierte Person, ob das Restrisiko tolerierbar ist<br>- Begründung der Tolerierbarkeit des Restrisikos",
                        "B": "Bewertung<br>- Abwägung von Wechselwirkungen der ergriffenen Maßnahmen, und Abwägung der Mitigation der Risiken im Zusammenspiel mit den Risiken anderer Qualitätsdimensionen<br>- Einschätzung durch eine qualifizierte und autorisierte Person, ob das Restrisiko tolerierbar ist<br>- Begründung der Tolerierbarkeit des Restrisikos",
                        "C": "Bewertung<br>- Einschätzung durch eine qualifizierte und autorisierte Person, ob das Restrisiko tolerierbar ist<br>- Begründung der Tolerierbarkeit des Restrisikos",
                        "D": "Eine Bewertung wurde nicht durchgeführt",
                        "docs_id": "12",
                        "reference": "System",
                        "type": "Bewertung",
                        "weighting": "Maximalwert",
                        "links": "",
                        "criterion": "DA2",
                        "dimension": "DA"
                    }
                },
                "title": "Schutz personenbezogener Daten"
            },
            {
                "index": "DA3",
                "criterion_type_id": 12,
                "indicators": {
                    "DA3.1": {
                        "title": "Eine Risikoanalyse für den Schutz benutzter proprietärer Daten im KI-System muss unter Beachtung des Verwendungszwecks durchgeführt werden.",
                        "tooltip": "Relevant sind hier die <br>DSGVO und die darin enthaltenen Vorgaben für eine Datenschutzfolgeabschätzung (DSFA),  Art.35, DSGVO",
                        "A": "Analyse - Risiko<br>Volle Risikoanalyse einschließlich Quantifizierung von Eintrittswahrscheinlichkeiten und Risiken:<br>- Identifikation der möglichen Risiken und ihrer Ursachen<br>- Zuweisung der Risikoverantwortung<br>- Schätzung der Eintrittswahrscheinlichkeit<br>- Schätzung der Aufdeckungswahrscheinlichkeit<br>- Schätzung der Auswirkung<br>- Strukturierte Abstufung und Priorisierung der Risiken <br><br>Mindestens die folgenden Risikoquellen sind unter Beachtung des Verwendungszwecks (siehe TR1.1)  zu berücksichtigen:<br><br>- Unbefugter Zugriff und mangelnde Kontrolle über den Zugang zu sensiblen Firmendaten durch interne oder externe Akteure.<br>- Risiken von versehentlichem Verlust, Löschung oder Beschädigung proprietärer Daten durch Systemfehler oder menschliches Versagen.<br>- Gefahr durch externe Angriffe, Hacking oder Industriespionage, die auf den Diebstahl, Offenlegung oder Manipulation vertraulicher Firmendaten abzielen <br>- Kontrollverlust über Firmendaten bei deren Speicherung oder Verarbeitung durch externe Dienstleister (z.B. in Cloud-Umgebungen).<br>-  Vertrags- oder Vereinbarungsverstöße durch Partner oder Dienstleister hinsichtlich unzulässigen Datenzugriff oder nicht-autorisierte Datenweitergabe<br>-  Nichteinhaltung von branchenspezifischen Vorschriften, bezüglich der Nutzung und Weitergabe von Daten.",
                        "B": "Analyse - Risiko<br>Limitierte Risikoanalyse mit Fokus auf den Schutzbedarf ohne Quantifizierung von Wahrscheinlichkeiten<br>- Identifikation der möglichen Risiken<br>- Zuweisung der Risikoverantwortung<br>- Schätzung der Auswirkung<br>- Strukturierte Abstufung und Priorisierung der Risiken<br><br>Mindestens die folgenden Risikoquellen sind  unter Beachtung des Verwendungszwecks (siehe TR1.1) zu berücksichtigen:<br><br>- Unbefugter Zugriff und mangelnde Kontrolle über den Zugang zu sensiblen Firmendaten durch interne oder externe Akteure.<br>- Risiken von versehentlichem Verlust, Löschung oder Beschädigung proprietärer Daten durch Systemfehler oder menschliches Versagen.<br>- Gefahr durch externe Angriffe, Hacking oder Industriespionage, die auf den Diebstahl, Offenlegung oder Manipulation vertraulicher Firmendaten abzielen <br>- Kontrollverlust über Firmendaten bei deren Speicherung oder Verarbeitung durch externe Dienstleister (z.B. in Cloud-Umgebungen).<br>-  Vertrags- oder Vereinbarungsverstöße durch Partner oder Dienstleister hinsichtlich unzulässigen Datenzugriff oder nicht-autorisierte Datenweitergabe<br>-  Nichteinhaltung von branchenspezifischen Vorschriften, bezüglich der Nutzung und Weitergabe von Daten.",
                        "C": "Analyse - Risiko<br>Hauptsächlich qualitative Abschätzung der Gefährdungen ohne Wahrscheinlichkeiten<br>- Identifikation der möglichen Gefährdungen:<br>- Zuweisung der Risikoverantwortung<br>- Qualitative Schätzung der Auswirkung<br>- Qualitative Abstufung und Priorisierung der Gefährdungen<br><br>Mindestens die folgenden Risikoquellen sind  unter Beachtung des Verwendungszwecks (siehe TR1.1) zu berücksichtigen:<br><br>- Unbefugter Zugriff und mangelnde Kontrolle über den Zugang zu sensiblen Firmendaten durch interne oder externe Akteure.<br>- Risiken von versehentlichem Verlust, Löschung oder Beschädigung proprietärer Daten durch Systemfehler oder menschliches Versagen.<br>- Gefahr durch externe Angriffe, Hacking oder Industriespionage, die auf den Diebstahl, Offenlegung oder Manipulation vertraulicher Firmendaten abzielen <br>- Kontrollverlust über Firmendaten bei deren Speicherung oder Verarbeitung durch externe Dienstleister (z.B. in Cloud-Umgebungen).<br>-  Vertrags- oder Vereinbarungsverstöße durch Partner oder Dienstleister hinsichtlich unzulässigen Datenzugriff oder nicht-autorisierte Datenweitergabe<br>-  Nichteinhaltung von branchenspezifischen Vorschriften, bezüglich der Nutzung und Weitergabe von Daten.",
                        "D": "Es wurde keine Risiko- oder Gefährdungsanalyse durchgeführt.",
                        "docs_id": "13",
                        "reference": "System",
                        "type": "Analyse",
                        "weighting": "Maximalwert",
                        "links": "DA1.1, DA1.2, TR1.1 (Verwendungszweck)",
                        "criterion": "DA3",
                        "dimension": "DA"
                    },
                    "DA3.2": {
                        "title": "Es müssen nicht-KI-spezifische Maßnahmen ergriffen werden um unter Beachtung des identifizierten Risikos den Schutz proprietärer Daten zu gewährleisten.",
                        "tooltip": "",
                        "A": "Orga. Maßnahmen - Governance / Systemnahe Prozesse<br><br>- Einführung von Mechanismen zum Speicherfristen-Management, um Daten nach Ablauf der festgelegten Fristen sicher zu löschen.<br>- Klare vertragliche Vereinbarungen mit externen Dienstleistern über den Zugriff, die Nutzung und den Schutz proprietärer Daten<br>- Gewährleistung, dass Unternehmen jederzeit die Kontrolle über ihre Daten behalten, insbesondere bei der Nutzung externer Cloud- oder Speicherdienste.<br>- Implementierung eines Notfallplans für die Erkennung, Meldung und Behebung von Datenschutzverletzungen <br><br>Tech. Maßnahmen - Daten<br><br>- Einführung strenger Zugriffskontrollen und von Berechtigungsmanagement, um sicherzustellen, dass nur autorisierte Personen Zugang zu proprietären Daten haben.<br>- Sicherstellung, dass Datenschutzmaßnahmen bereits in der Entwicklung und Implementierung der Systeme integriert sind (\"data-protection-by-design\")<br>- Implementierung von Verschlüsselungstechniken und Sicherheitsprotokollen, um die Vertraulichkeit und Integrität der Firmendaten zu schützen, insbesondere während der Übertragung und Speicherung.<br>- Einführung von Mechanismen zur Sicherstellung der Integrität und Authentizität von Firmendaten, um Manipulationen zu verhindern und deren Echtheit zu gewährleisten.<br>- Einführung regelmäßiger Datensicherungen und Notfallpläne zur Wiederherstellung von Daten bei Verlust oder Beschädigung.<br>Sicherstellung der Interoperabilität von Datenformaten und die Möglichkeit, Firmendaten einfach zwischen Systemen oder Anbietern zu übertragen<br><br>Tech. Maßnahmen - Betrieb<br><br>- Regelmäßige Prüfungen und Audits der Datenverarbeitungsprozesse und -praktiken, um sicherzustellen, dass die Datenschutzanforderungen entsprechend dem Verwendungszweck eingehalten werden.",
                        "B": "Orga. Maßnahmen - Governance / Systemnahe Prozesse<br><br>- Einführung von Mechanismen zum Speicherfristen-Management, um Daten nach Ablauf der festgelegten Fristen sicher zu löschen.<br>- Klare vertragliche Vereinbarungen mit externen Dienstleistern über den Zugriff, die Nutzung und den Schutz proprietärer Daten<br>- Gewährleistung, dass Unternehmen jederzeit die Kontrolle über ihre Daten behalten, insbesondere bei der Nutzung externer Cloud- oder Speicherdienste.<br>- Implementierung eines Notfallplans für die Erkennung, Meldung und Behebung von Datenschutzverletzungen <br><br>Tech. Maßnahmen - Daten<br><br>- Einführung strenger Zugriffskontrollen und von Berechtigungsmanagement, um sicherzustellen, dass nur autorisierte Personen Zugang zu proprietären Daten haben.<br>- Implementierung von Verschlüsselungstechniken und Sicherheitsprotokollen, um die Vertraulichkeit und Integrität der Firmendaten zu schützen, insbesondere während der Übertragung und Speicherung.<br>- Einführung von Mechanismen zur Sicherstellung der Integrität und Authentizität von Firmendaten, um Manipulationen zu verhindern und deren Echtheit zu gewährleisten.<br>- Einführung regelmäßiger Datensicherungen und Notfallpläne zur Wiederherstellung von Daten bei Verlust oder Beschädigung.<br><br>Tech. Maßnahmen - Betrieb<br><br>- Regelmäßige Prüfungen und Audits der Datenverarbeitungsprozesse und -praktiken, um sicherzustellen, dass die Datenschutzanforderungen entsprechend dem Verwendungszweck eingehalten werden.",
                        "C": "Orga. Maßnahmen - Governance / Systemnahe Prozesse<br><br>- Einführung von Mechanismen zum Speicherfristen-Management, um Daten nach Ablauf der festgelegten Fristen sicher zu löschen.<br>- Klare vertragliche Vereinbarungen mit externen Dienstleistern über den Zugriff, die Nutzung und den Schutz proprietärer Daten<br>- Gewährleistung, dass Unternehmen jederzeit die Kontrolle über ihre Daten behalten, insbesondere bei der Nutzung externer Cloud- oder Speicherdienste.<br><br><br>Tech. Maßnahmen - Daten<br><br>- Einführung von Zugriffskontrollen und von Berechtigungsmanagement, um sicherzustellen, dass nur autorisierte Personen Zugang zu proprietären Daten haben.<br>- Implementierung von Verschlüsselungstechniken, um die Vertraulichkeit und Integrität der Firmendaten zu schützen, insbesondere während der Übertragung und Speicherung.<br>- Einführung regelmäßiger Datensicherungen und Notfallpläne zur Wiederherstellung von Daten bei Verlust oder Beschädigung.",
                        "D": "Es wurden keine nicht-KI-spezifischen Maßnahmen zum Schutz proprietärer Daten ergriffen.",
                        "docs_id": "14",
                        "reference": "System/Komponente",
                        "type": "Maßnahme",
                        "weighting": "Maximalwert",
                        "links": "DA1.2, DA1.3, MA1, CY1.5",
                        "criterion": "DA3",
                        "dimension": "DA"
                    },
                    "DA3.3": {
                        "title": "Es müssen Maßnahmen und Sicherheitskontrollen vorhanden sein, um KI-spezifische Angriffe die während der Vorbereitungs- und Modelltrainingsphase der KI-Modelle stattfinden zu mitigieren.",
                        "tooltip": "Aus Plausibilitätsgründen <br>sind nicht zwangsläufig alle Maßnahmen in CY2.3 relevant zum Schutz proprietärer Daten, z.B., wenn es um das Schutzziel Availability geht.",
                        "A": "Tech. Maßnahmen - Test<br>(Metriken KI-Modelle Angriffsszenarien Vorbereitungs- und Modelltrainingsphase): Prüfung von durch den Anwendungsbereich begründeter Auswahl und Anzahl an Metriken und Tests der adversariellen Robustheit in Bezug auf Angriffsszenarien der Vorbereitungs- und Modelltrainingsphase, die gegen Vertraulichkeit, Integrität oder Verfügbarkeit des KI-Systems gerichtet sein können.  <br>- Dies schließt eine Prüfung mit Basis- und fortgeschrittenen Methoden mindestens der folgende Angriffsarten ein:<br> a) data poisoning<br> b) label poisoning<br> c) KI-spezifische backdoor attacks<br><br>- Penetrationstests von Systemaspekten mit Bezug auf KI-spezifische Angriffe während der Vorbereitungs- und Modelltrainingsphase sollten durchgeführten werden.<br><br>Die ausgewählten Metriken und Tests sollten mindestens die folgenden Merkmale aufweisen:<br>- Methoden sollten für jedes KI-Modell im und für das KI-System als Ganzes angewendet werden, falls dieses einen gesammelten Output erzeugt<br>- wenn durch die Auswahl begründet, sollten die Metriken und Tests sowohl wichtige Basismethoden als auch fortgeschrittene Methoden (hinsichtlich Komplexität, Informationsgehalt, Implementierungsaufwand, z.B. umfangreiches Prüfwerkzeug) umfassen<br>- die ausgewählten Metriken und Tests sollten wenn möglich einen hohen Grad der Automatisierung erlauben<br>- ggf. Festlegung von Schwellenwerten (als Mindestanforderungen an die Funktionalität/Leistung) und Begründung der Schwellenwerte unter Berücksichtigung des Anwendungsbereichs und Verwendungszwecks<br>- falls anwendbar: Abstufung der Metriken und Schwellenwerte nach unterschiedlichen Einsatzszenarien mit Bezug zur Definition des Anwendungsbereichs.<br><br>Tech. Maßnahmen - Modell<br>- angemessene KI-spezifische Sicherheitskontrollen zur Mitigation des identifizierten Risikos von Angriffen in der  Vorbereitungs- und Modelltrainingsphase des KI-Systems müssen auf Modellebene eingeführt werden  (z. B Datenfiltermethoden oder Suchsysteme für Backdoors, Unsicherheitsmethoden)<br>- es sollten Robustheitsnachweise für jedes KI-Modell geführt werden zu verschiedenen relevanten Angriffsarten<br><br>Tech. Maßnahmen - System<br>- angemessene KI-spezifische oder nicht-KI-spezifische Sicherheitskontrollen zur Mitigation des identifizierten Risikos von Angriffen von Angriffen in der  Vorbereitungs- und Modelltrainingsphase des KI-Systems müssen auf Systemebene  eingeführt werden. <br>- klassisches Sicherheitskontrollen des gesamten Systems im Betrieb sollten vorhergesehen und eingeplant sein einschließlich einer Einbindung in ein existierendes CSMS.<br>- Red Teaming des gesamten Systems mit Bezug auf KI-spezifische Angriffe während der Vorbereitungs- und Modelltrainingsphase sollten durchgeführten werden.",
                        "B": "Tech. Maßnahmen - Test (Metriken KI-Modelle Angriffsszenarien Vorbereitungs- und Modelltrainingsphase): <br>Prüfung von durch den Anwendungsbereich begründeter Auswahl und Anzahl an Metriken und Tests der adversariellen Robustheit in Bezug auf Angriffsszenarien der Vorbereitungs- und Modelltrainingsphase, die gegen Vertraulichkeit, Integrität oder Verfügbarkeit des KI-Systems gerichtet sein können.  <br>- Dies schließt eine Prüfung mit Basis-Methoden mindestens der folgende Angriffsarten ein:<br> a) data poisoning<br> b) label poisoning<br> c) KI-spezifische backdoor attacks<br><br>Die ausgewählten Metriken und Tests sollten mindestens die folgenden Merkmale aufweisen:<br>- Methoden sollten für jedes KI-Modell im und für das KI-System als Ganzes angewendet werden, falls dieses einen gesammelten Output erzeugt<br>- wenn durch die Auswahl begründet, sollten die Metriken und Tests sowohl wichtige Basismethoden als auch fortgeschrittene Methoden (hinsichtlich Komplexität, Informationsgehalt, Implementierungsaufwand, z.B. umfangreiches Prüfwerkzeug) umfassen<br><br>- ggf. Festlegung von Schwellenwerten (als Mindestanforderungen an die Funktionalität/Leistung) und Begründung der Schwellenwerte unter Berücksichtigung des Anwendungsbereichs und Verwendungszwecks<br><br><br>Tech. Maßnahmen - Modell<br>- angemessene KI-spezifische Sicherheitskontrollen zur Mitigation des identifizierten Risikos von Angriffen in der  Vorbereitungs- und Modelltrainingsphase des KI-Systems müssen auf Modellebene eingeführt werden  (z. B Datenfiltermethoden oder Suchsysteme für Backdoors, Unsicherheitsmethoden)<br>- es sollten möglichst Robustheitsnachweise für jedes KI-Modell geführt werden zu verschiedenen relevanten Angriffsarten<br><br>Tech. Maßnahmen - System<br>- angemessene KI-spezifische oder nicht-KI-spezifische Sicherheitskontrollen zur Mitigation des identifizierten Risikos von Angriffen von Angriffen in der  Vorbereitungs- und Modelltrainingsphase des KI-Systems müssen auf Systemebene  eingeführt werden. ",
                        "C": "Tech. Maßnahmen - Test (Metriken KI-Modelle Angriffsszenarien Vorbereitungs- und Modelltrainingsphase): <br>Prüfung von durch den Anwendungsbereich begründeter Auswahl und Anzahl an Metriken und Tests der adversariellen Robustheit in Bezug auf Angriffsszenarien der Vorbereitungs- und Modelltrainingsphase, die gegen Vertraulichkeit, Integrität oder Verfügbarkeit des KI-Systems gerichtet sein können.  <br>- Dies schließt eine Prüfung mit Basis-Methoden möglichst der folgende Angriffsarten ein:<br> a) data poisoning<br> b) label poisoning<br> c) KI-spezifische backdoor attacks<br><br>Die ausgewählten Metriken und Tests sollten möglichst die folgenden Merkmale aufweisen:<br>- Methoden können entweder für jedes KI-Modell oder für das KI-System als Ganzes angewendet werden, je nachdem, was sinnvoller und machbar ist <br>- es genügen Basismethoden (hinsichtlich Komplexität, Informationsgehalt, Implementierungsaufwand, z.B. eine simple Metrik) <br>- ggf. Festlegung von Schwellenwerten (als Mindestanforderungen an die Funktionalität/Leistung) und Begründung der Schwellenwerte unter Berücksichtigung des Anwendungsbereichs und Verwendungszwecks<br><br>Tech. Maßnahmen - Modell<br>- angemessene KI-spezifische Sicherheitskontrollen zur Mitigation des identifizierten Risikos von Angriffen in der  Vorbereitungs- und Modelltrainingsphase des KI-Systems müssen auf Modellebene eingeführt werden  (z. B Datenfiltermethoden oder Suchsysteme für Backdoors, Unsicherheitsmethoden)<br>- es sollten möglichst Robustheitsnachweise für jedes KI-Modell geführt werden zu verschiedenen relevanten Angriffsarten<br><br>Tech. Maßnahmen - System<br>- angemessene KI-spezifische oder nicht-KI-spezifische Sicherheitskontrollen zur Mitigation des identifizierten Risikos von Angriffen von Angriffen in der  Vorbereitungs- und Modelltrainingsphase des KI-Systems müssen auf Systemebene  eingeführt werden. ",
                        "D": "Es wurden keine Maßnahmen ergriffen um KI-spezifische Angriffe während der Vorbereitungs- und Modelltrainingsphase zu mitigieren.",
                        "docs_id": "15",
                        "reference": "System/Komponente",
                        "type": "Maßnahme",
                        "weighting": "Maximalwert",
                        "links": "",
                        "criterion": "DA3",
                        "dimension": "DA"
                    },
                    "DA3.4": {
                        "title": "Es müssen Maßnahmen und Sicherheitskontrollen vorhanden sein, um KI-spezifische Angriffe die während des Betriebs auftreten können zu mitigieren.",
                        "tooltip": "Aus Plausibilitätsgründen <br>sind nicht zwangsläufig alle Maßnahmen in CY1.6 relevant zum Schutz proprietärer Daten, z.B., wenn es um das Schutzziel Availability geht.",
                        "A": "Tech. Maßnahmen - Test (Metriken KI-Modelle Angriffe on Inferenz- und Deploymentphase): <br>Prüfung von durch den Anwendungsbereich begründeter Auswahl und Anzahl an Metriken und Tests der adversariellen Robustheit in Bezug auf Angriffsszenarien in der Inferenz - und Deploymentphase, die gegen Vertraulichkeit, Integrität oder Verfügbarkeit des KI-Systems gerichtet sein können. <br>- Dies schließt eine Prüfung mit Basis- und fortgeschrittenen Methoden mindestens der folgende Angriffsarten ein:<br> a) evasion attacks,<br> b) latency attacks<br> c) model extraction attacks <br> d)  data reconstruction oder property inference attacks<br> e) prompt injection attacks oder jailbreaks <br>- Penetrationstests  von Systemaspekten mit Bezug auf KI-spezifische Angriffe während des Betriebs sollten durchgeführten werden.<br><br>Die ausgewählten Metriken und Tests sollten mindestens die folgenden Merkmale aufweisen:<br>- Methoden sollten für jedes KI-Modell im und für das KI-System als Ganzes angewendet werden, falls dieses einen gesammelten Output erzeugt<br>- wenn durch die Auswahl begründet, sollten die Metriken und Tests sowohl wichtige Basismethoden als auch fortgeschrittene Methoden (hinsichtlich Komplexität, Informationsgehalt, Implementierungsaufwand, z.B. umfangreiches Prüfwerkzeug) umfassen<br>- die ausgewählten Metriken und Tests sollten wenn möglich einen hohen Grad der Automatisierung erlauben<br>- ggf. Festlegung von Schwellenwerten (als Mindestanforderungen an die Funktionalität/Leistung) und Begründung der Schwellenwerte unter Berücksichtigung des Anwendungsbereichs und Verwendungszwecks<br>- falls anwendbar: Abstufung der Metriken und Schwellenwerte nach unterschiedlichen Einsatzszenarien mit Bezug zur Definition des Anwendungsbereichs.<br><br>Tech. Maßnahmen - Modell<br>- angemessene KI-spezifische Sicherheitskontrollen und technische Maßnahmen zur Mitigation des identifizierten Risikos von Angriffen in der Inferenzphase und während des Deployment des KI-Systems müssen auf Modellebene eingeführt werden (z.B. adversarielles Training, Methoden zur Stärkung der Modellrobustheit oder Unsicherheitsmethoden)<br>- es sollten Robustheitsnachweise für jedes KI-Modell geführt werden zu verschiedenen relevanten Angriffsarten<br><br>Tech. Maßnahmen - System<br>- angemessene KI-spezifische oder nicht-KI-spezifische Sicherheitskontrollen zur Mitigation des identifizierten Risikos von Angriffen in der Inferenzphase und während des Deployment des KI-Systems müssen auf Systemebene  eingeführt werden (z.B. Monitoring von Inputs, siehe MA2.3)<br>- klassisches Sicherheitskontrollen des gesamten Systems im Betrieb sollten vorhergesehen und eingeplant sein einschließlich einer Einbindung in ein existierendes CSMS.<br>- Red Teaming des gesamten Systems mit Bezug auf KI-spezifische Angriffe während der Betriebsphase sollten durchgeführten werden",
                        "B": "Tech. Maßnahmen - Test (Metriken KI-Modelle Angriffe on Inferenz- und Deploymentphase): <br>Prüfung von durch den Anwendungsbereich begründeter Auswahl und Anzahl an Metriken und Tests der adversariellen Robustheit in Bezug auf Angriffsszenarien in der Inferenz - und Deploymentphase, die gegen Vertraulichkeit, Integrität oder Verfügbarkeit des KI-Systems gerichtet sein können. <br>- Dies schließt eine Prüfung mit Basis-Methoden mindestens der folgende Angriffsarten ein:<br> a) evasion attacks,<br> b) latency attacks<br> c) model extraction attacks <br> d)  data reconstruction oder property inference attacks<br> e) prompt injection attacks oder jailbreaks <br>- Penetrationstests des gesamten Systems mit Bezug auf KI-spezifische Angriffe während des Betriebs sollten durchgeführten werden.<br><br>Die ausgewählten Metriken und Tests sollten mindestens die folgenden Merkmale aufweisen:<br>- Methoden sollten für jedes KI-Modell im und für das KI-System als Ganzes angewendet werden, falls dieses einen gesammelten Output erzeugt<br>- wenn durch die Auswahl begründet, sollten die Metriken und Tests sowohl wichtige Basismethoden als auch fortgeschrittene Methoden (hinsichtlich Komplexität, Informationsgehalt, Implementierungsaufwand, z.B. umfangreiches Prüfwerkzeug) umfassen<br>- die ausgewählten Metriken und Tests sollten wenn möglich einen hohen Grad der Automatisierung erlauben<br>- ggf. Festlegung von Schwellenwerten (als Mindestanforderungen an die Funktionalität/Leistung) und Begründung der Schwellenwerte unter Berücksichtigung des Anwendungsbereichs und Verwendungszwecks<br>- falls anwendbar: Abstufung der Metriken und Schwellenwerte nach unterschiedlichen Einsatzszenarien mit Bezug zur Definition des Anwendungsbereichs.<br><br>Tech. Maßnahmen - Modell<br>- angemessene KI-spezifische Sicherheitskontrollen zur Mitigation des identifizierten Risikos von Angriffen in der Inferenzphase und während des Deployment des KI-Systems müssen auf Modellebene eingeführt werden (z.B. adversarielles Training, Methoden zur Stärkung der Modellrobustheit oder Unsicherheitsmethoden)<br>- es sollten möglichst Robustheitsnachweise für jedes KI-Modell geführt werden zu verschiedenen relevanten Angriffsarten<br><br>Tech. Maßnahmen - System<br>- angemessene KI-spezifische oder nicht-KI-spezifische Sicherheitskontrollen zur Mitigation des identifizierten Risikos von Angriffen in der Inferenzphase und während des Deployment des KI-Systems müssen auf Systemebene  eingeführt werden. (z.B. Monitoring von Inputs, siehe MA2.3) <br>- klassisches Sicherheitskontrollen des gesamten Systems im Betrieb sollten vorhergesehen und eingeplant sein einschließlich einer Einbindung in ein existierendes CSMS.",
                        "C": "Tech. Maßnahmen - Test (Metriken KI-Modelle Angriffe on Inferenz- und Deploymentphase): <br>Prüfung von durch den Anwendungsbereich begründeter Auswahl und Anzahl an Metriken und Tests der adversariellen Robustheit in Bezug auf Angriffsszenarien in der Inferenz - und Deploymentphase, die gegen Vertraulichkeit, Integrität oder Verfügbarkeit des KI-Systems gerichtet sein können. <br>- Dies schließt eine Prüfung mit Basis-Methoden möglichst der folgende Angriffsarten ein:<br> a) evasion attacks,<br> b) latency attacks<br> c) model extraction attacks <br> d)  data reconstruction oder property inference attacks<br> e) prompt injection attacks oder jailbreaks <br><br>Die ausgewählten Metriken und Tests sollten möglichst die folgenden Merkmale aufweisen:<br>- Methoden können entweder für jedes KI-Modell oder für das KI-System als Ganzes angewendet werden, je nachdem, was sinnvoller und machbar ist <br>- es genügen Basismethoden (hinsichtlich Komplexität, Informationsgehalt, Implementierungsaufwand, z.B. eine simple Metrik) <br>- ggf. Festlegung von Schwellenwerten (als Mindestanforderungen an die Funktionalität/Leistung) und Begründung der Schwellenwerte unter Berücksichtigung des Anwendungsbereichs und Verwendungszwecks<br><br>Tech. Maßnahmen - Modell<br>- angemessene KI-spezifische Sicherheitskontrollen zur Mitigation des identifizierten Risikos von Angriffen in der Inferenzphase und während des Deployment des KI-Systems müssen auf Modellebene eingeführt werden (z.B. adversarielles Training, Methoden zur Stärkung der Modellrobustheit oder Unsicherheitsmethoden)<br>- es sollten Robustheitsnachweise für jedes KI-Modell geführt werden zu verschiedenen relevanten Angriffsarten<br><br>Tech. Maßnahmen - System<br>- angemessene KI-spezifische oder nicht-KI-spezifische Sicherheitskontrollen zur Mitigation des identifizierten Risikos von Angriffen in der Inferenzphase und während des Deployment des KI-Systems müssen auf Systemebene  eingeführt werden. (z.B. Monitoring von Inputs, siehe MA2.3)<br>- klassisches Sicherheitskontrollen des gesamten Systems im Betrieb sollten vorhergesehen und eingeplant sein einschließlich einer Einbindung in ein existierendes CSMS.",
                        "D": "Es wurden keine Maßnahmen ergriffen um KI-spezifische Angriffe während des Betriebs zu mitigieren.",
                        "docs_id": "16",
                        "reference": "System/Komponente",
                        "type": "Maßnahme",
                        "weighting": "Maximalwert",
                        "links": "",
                        "criterion": "DA3",
                        "dimension": "DA"
                    },
                    "DA3.5": {
                        "title": "Es müssen Maßnahmen und Sicherheitskontrollen vorhanden sein, um fehlerhafte Nutzung und beabsichtigten Missbrauch des KI-Systems zu verhindern.",
                        "tooltip": "Dies sollte <br>vor allem die fehlerhafte Nutzung oder den Missbrauch des Systems abdecken, welche proprietäre Daten fälschlich verwendet oder offenlegt",
                        "A": "Org. Maßnahmen - Systemnahe Prozesse<br>- Prozesse müssen eingeführt sein um den möglichen beabsichtigten Missbrauchs des KI-Systems im Betrieb adressieren zu können, einschließlich der Einbindung möglicher Abschaltungsmechanismen im Risikomanagement. <br>- Prozesse sollten eingeführt sein, um eine durch Monitoringsysteme und Logging festgestellte fehlerhafte Nutzung im Betrieb adressieren zu können<br>- Prozesse sollten insbesondere darauf achten, dass neben der Funktionalität, Integrität und Verfügbarkeit des KI-Systems auch die unter den unterschiedlichen Qualitätsdimensionen definierten Ziele geschützt sind bei fehlerhafter Nutzung oder Missbrauch, also Wahrung des Schutzes personenbezogener oder proprietärer Daten, des Schutzes vor Nicht-Diskriminierung, des Autonomiegrades und der dazugehörigen menschlichen Kontrollmechanismen<br><br><br>Tech. Maßnahmen - System / Betrieb<br>- Sicherheitskontrollen zur Verhinderung von Missbrauch und fehlerhafter Nutzung sollten vorgesehen sein und wenn möglich vor der Produktionsphase implementiert werden. Dies schließt Methoden der Prompt/Output-Filterung bei generativer KI mit ein. Zu Absicherung gegen Datenzugang siehe auch CY1.5<br>- Es muss Vorgesehen sein Inferenzeingaben, Anfragen und Prompts als Teil des Monitoring und Logging aufgezeichnet zu  werden, um im Falle einer Fehlnutzung, einer Kompromittierung oder eines Missbrauchs eine Untersuchung zu ermöglichen.<br>- Red Teaming des gesamten Systems mit Bezug auf Missbrauch oder fehlerhafte Nutzung des KI-Systems sollte durchgeführt werden",
                        "B": "Org. Maßnahmen - Systemnahe Prozesse<br>- Prozesse müssen eingeführt sein um den möglichen beabsichtigten Missbrauchs des KI-Systems im Betrieb adressieren zu können, einschließlich der Einbindung möglicher Abschaltungsmechanismen <br>- Prozesse sollten eingeführt sein, um eine durch Monitoringsysteme und Logging festgestellte fehlerhafte Nutzung im Betrieb adressieren zu können<br>- Prozesse sollten insbesondere darauf achten, dass neben der Funktionalität, Integrität und Verfügbarkeit des KI-Systems auch die unter den unterschiedlichen Qualitätsdimensionen definierten Ziele geschützt sind bei fehlerhafter Nutzung oder Missbrauch, also Wahrung des Schutzes personenbezogener oder proprietärer Daten, des Schutzes vor Nicht-Diskriminierung, des Autonomiegrades und der dazugehörigen Menschlichen Kontrollmechanismen<br><br><br>Tech. Maßnahmen - Betrieb<br>- Es muss Vorgesehen sein Inferenzeingaben, Anfragen und Prompts als Teil des Monitoring und Logging aufgezeichnet zu  werden, um im Falle einer Fehlnutzung, einer Kompromittierung oder eines Missbrauchs eine Untersuchung zu ermöglichen.",
                        "C": "Org. Maßnahmen - Systemnahe Prozesse<br>- Prozesse müssen eingeführt sein um den möglichen beabsichtigten Missbrauchs des KI-Systems im Betrieb adressieren zu können, einschließlich der Einbindung möglicher Abschaltungsmechanismen <br>- Prozesse sollten eingeführt sein, um eine durch Monitoringsysteme und Logging festgestellte fehlerhafte Nutzung im Betrieb adressieren zu können<br>- Prozesse sollten insbesondere darauf achten, dass neben der Funktionalität, Integrität und Verfügbarkeit des KI-Systems auch die unter den unterschiedlichen Qualitätsdimensionen definierten Ziele geschützt sind bei fehlerhafter Nutzung oder Missbrauch, also Wahrung des Schutzes personenbezogener oder proprietärer Daten, des Schutzes vor Nicht-Diskriminierung, des Autonomiegrades und der dazugehörigen Menschlichen Kontrollmechanismen",
                        "D": "Es sind keine Maßnahmen vorhanden um fehlerhafte Nutzung und Missbrauch des KI-Systems zu verhindern",
                        "docs_id": "17",
                        "reference": "System/Komponente",
                        "type": "Maßnahme",
                        "weighting": "Maximalwert",
                        "links": "",
                        "criterion": "DA3",
                        "dimension": "DA"
                    },
                    "DA3.6": {
                        "title": "Es muss bewertet werden, ob die ergriffenen Maßnahmen die festgestellten Risiken auf ein annehmbares Maß vermindert haben und die Qualität des KI-Systems den gesetzten Zielvorgaben entspricht.",
                        "tooltip": "",
                        "A": "Bewertung<br>- Zusammenfassende Betrachtung der Effekte der Durchführung der technischen und organisatorischen Maßnahmen<br>- Abwägung von Wechselwirkungen der ergriffenen Maßnahmen, und Abwägung der Mitigation der Risiken im Zusammenspiel mit den Risiken anderer Qualitätsdimensionen<br>- Ermittlung und Beschreibung des Restrisikos nach Durchführung der technischen und organisatorischen Maßnahmen<br>- Einschätzung durch eine qualifizierte und autorisierte Person, ob das Restrisiko tolerierbar ist<br>- Begründung der Tolerierbarkeit des Restrisikos",
                        "B": "Bewertung<br>- Abwägung von Wechselwirkungen der ergriffenen Maßnahmen, und Abwägung der Mitigation der Risiken im Zusammenspiel mit den Risiken anderer Qualitätsdimensionen<br>- Einschätzung durch eine qualifizierte und autorisierte Person, ob das Restrisiko tolerierbar ist<br>- Begründung der Tolerierbarkeit des Restrisikos",
                        "C": "Bewertung<br>- Einschätzung durch eine qualifizierte und autorisierte Person, ob das Restrisiko tolerierbar ist<br>- Begründung der Tolerierbarkeit des Restrisikos",
                        "D": "Eine Bewertung wurde nicht durchgeführt",
                        "docs_id": "18",
                        "reference": "System",
                        "type": "Bewertung",
                        "weighting": "Maximalwert",
                        "links": "",
                        "criterion": "DA3",
                        "dimension": "DA"
                    }
                },
                "title": "Schutz proprietärer Daten"
            }
        ]
    },
    "ND": {
        "title": "Nicht-Diskriminierung",
        "short_title": "Nicht-Diskriminierung",
        "quality_dimension_id": 20,
        "icon": "non-discrimination",
        "criteria": [
            {
                "index": "ND1",
                "criterion_type_id": 20,
                "indicators": {
                    "ND1.1": {
                        "title": "Das Risiko von Diskriminierung im Zusammenhang mit dem beabsichtigten Zweck des KI-Systems muss analysiert werden.",
                        "tooltip": "",
                        "A": "Analyse-Risiko<br>Detaillierte Risikoanalyse einschließlich Quantifizierung von Eintrittswahrscheinlichkeiten und Risiken:<br>- Identifikation der möglichen Risiken und ihrer Ursachen<br>- Zuweisung der Risikoverantwortung<br>- Schätzung der Eintrittswahrscheinlichkeit<br>- Schätzung der Aufdeckungswahrscheinlichkeit<br>- Schätzung der Auswirkung<br>- Strukturierte Abstufung und Priorisierung der Risiken <br><br>Mindestens die folgenden Risikoquellen sind unter Beachtung des Verwendungszwecks (siehe TR1.1) zu berücksichtigen:<br>- Historische Verzerrungen<br>- Stichprobenverzerrung<br>- Modellverzerrungen<br>- Attributionsfehler<br>- Impliziter Bias<br>- Bestätigungsfehler<br>- Voreingenommenheit von Entwicklern <br>- Verzerrung durch Nutzerinteraktionen<br>- Missinterpretation von Resultaten<br>- Mangelnde Berücksichtigung der möglichen (Nutzer-)Gruppen<br>- Benachteiligung/Diskriminierung von Gruppen mit geschützten Eigenschaften",
                        "B": "Analyse-Risiko<br>Limitierte Risikoanalyse mit Fokus auf den Schutzbedarf ohne Quantifizierung von Wahrscheinlichkeiten:<br>- Identifikation der möglichen Risiken<br>- Zuweisung der Risikoverantwortung<br>- Schätzung der Auswirkung<br>- Strukturierte Abstufung und Priorisierung der Risiken<br><br>Mindestens die folgenden Risikoquellen sind unter Beachtung des Verwendungszwecks (siehe TR1.1) zu berücksichtigen:<br>- Historische Verzerrungen<br>- Stichprobenverzerrung<br>- Modellverzerrungen<br>- Attributionsfehler<br>- Impliziter Bias<br>- Bestätigungsfehler<br>- Voreingenommenheit von Entwicklern <br>- Verzerrung durch Nutzerinteraktionen<br>- Missinterpretation von Resultaten<br>- Mangelnde Berücksichtigung der möglichen (Nutzer-)Gruppen<br>- Benachteiligung/Diskriminierung von Gruppen mit geschützten Eigenschaften",
                        "C": "Analyse-Risiko<br>Hauptsächlich qualitative Abschätzung ohne Wahrscheinlichkeiten:<br>- Identifikation der möglichen Gefährdungen<br>- Zuweisung der  Risikoverantwortung<br>- Qualitative Schätzung der Auswirkung<br>- Qualitative Abstufung und Priorisierung der Risiken<br><br>Mindestens die folgenden Risikoquellen sind unter Beachtung des Verwendungszwecks (siehe TR1.1) zu berücksichtigen:<br>- Historische Verzerrungen<br>- Stichprobenverzerrung<br>- Modellverzerrungen<br>- Attributionsfehler<br>- Impliziter Bias<br>- Bestätigungsfehler<br>- Voreingenommenheit von Entwicklern <br>- Verzerrung durch Nutzerinteraktionen<br>- Missinterpretation von Resultaten<br>- Mangelnde Berücksichtigung der möglichen (Nutzer-)Gruppen<br>- Benachteiligung/Diskriminierung von Gruppen mit geschützten Eigenschaften",
                        "D": "Es wurde keine Risikoanalyse durchgeführt.",
                        "docs_id": "19",
                        "reference": "System",
                        "type": "Analyse",
                        "weighting": "Maximalwert",
                        "links": "TR1.1",
                        "criterion": "ND1",
                        "dimension": "ND"
                    },
                    "ND1.2": {
                        "title": "Das notwendige Maß an Vermeidung von ungerechtfertigter Verzerrung bzw. Diskriminierung muss im Kontext des beabsichtigten Zwecks definiert werden.",
                        "tooltip": "",
                        "A": "Analyse - Definition / Metriken & Schwellenwerte<br>Basierend auf dem festgelegten Zweck des KI-Systems (TR1.1) muss definiert werden welches Maß an Vermeidung von Verzerrung bzw. Schutz vor Nicht-Diskriminierung notwendig ist. Hierzu gehört:<br><br>- Identifikation sensitiver bzw. schützenswerter Merkmale in den Daten mit Begründung<br>- Identifikation von Gruppen mit geschützten Eigenschaften basierend auf den möglichen Nutzer*innen und betroffenen Personen<br>- Identifikation zusätzlicher Gruppen, die unvorhergesehen betroffen werden können, z.B. da deren Merkmale nicht als Features sondern nur implizit in den Daten enthalten sind)<br>- Definition der beabsichtigten Fairness<br>- Kollaboration mit Repräsentanten von identifizierten Gruppen mit geschützten Eigenschaften<br>- Festlegung von Test, Metriken und Schwellenwerten zur Erfassung der Zielsetzung im Rahmen der Fairness-Definition<br><br>Die ausgewählten Metriken und Tests sollten mindestens die folgenden Merkmale aufweisen:<br>- Methoden sollten für jedes KI-Modell im und für das KI-System als Ganzes angewendet werden, falls dieses einen gesammelten Output erzeugt<br>- Wenn durch die Auswahl begründet, sollten die Metriken und Tests sowohl wichtige Basismethoden als auch fortgeschrittene Methoden (hinsichtlich Komplexität, Informationsgehalts, Implementierungsaufwands, z.B. umfangreiches Prüfwerkzeug) umfassen<br>- Die ausgewählten Metriken und Tests sollten wenn möglich durch einen hohen Grad der Automatisierung eine kontinuierliche Evaluation der KI-Modelle erlauben ",
                        "B": "Analyse - Definition / Metriken & Schwellenwerte<br>Basierend auf dem festgelegten Zweck des KI-Systems (TR1.1) muss definiert werden welches Maß an Vermeidung von Verzerrung bzw. Schutz vor Nicht-Diskriminierung notwendig ist. Hierzu gehört:<br><br>- Identifikation sensitiver bzw. schützenswerter Merkmale in den Daten mit Begründung<br>- Identifikation von  Gruppen mit geschützten Eigenschaften basierend auf den möglichen Nutzer*innen und betroffenen Personen<br>- Definition der beabsichtigten Fairness<br>- Festlegung von Test, Metriken und Schwellenwerten zur Erfassung der Zielsetzung im Rahmen der Fairness-Definition<br><br>Die ausgewählten Metriken und Tests sollten mindestens die folgenden Merkmale aufweisen:<br>- Methoden sollten für jedes KI-Modell im und für das KI-System als Ganzes angewendet werden, falls dieses einen gesammelten Output erzeugt<br>- Wenn durch die Auswahl begründet, sollten die Metriken und Tests sowohl wichtige Basismethoden als auch fortgeschrittene Methoden (hinsichtlich Komplexität, Informationsgehalts, Implementierungsaufwands, z.B. umfangreiches Prüfwerkzeug) umfassen",
                        "C": "Analyse - Definition / Metriken & Schwellenwerte<br>Basierend auf dem festgelegten Zweck des KI-Systems (TR1.1) muss definiert werden welches Maß an Vermeidung von Verzerrung bzw. Schutz vor Nicht-Diskriminierung notwendig ist. Hierzu gehört:<br><br>- Identifikation sensitiver bzw. schützenswerter Merkmale in den Daten<br>- Identifikation von Gruppen mit geschützten Eigenschaften basierend auf den möglichen Nutzer*innen und betroffenen Personen<br>- Definition der beabsichtigten Fairness<br>- Festlegung von Test, Metriken und Schwellenwerten zur Erfassung der Zielsetzung im Rahmen der Fairness-Definition<br><br>Die ausgewählten Metriken und Tests sollten mindestens die folgenden Merkmale aufweisen:<br>- Methoden sollten für jedes KI-Modell im und für das KI-System als Ganzes angewendet werden, falls dieses einen gesammelten Output erzeugt<br>- Es genügen Basismethoden (hinsichtlich Komplexität, Informationsgehalts, Implementierungsaufwands, z.B. eine simple Metrik) ",
                        "D": "Eine Definition und Zielsetzung zur Vermeidung ungerechtfertigter Verzerrung und Diskriminierung ist nicht erfolgt.",
                        "docs_id": "20",
                        "reference": "System/Komponente",
                        "type": "Analyse",
                        "weighting": "Maximalwert",
                        "links": "TR1.1",
                        "criterion": "ND1",
                        "dimension": "ND"
                    },
                    "ND1.3": {
                        "title": "Eine Analyse des KI-Systems hinsichtlich bestehender Verzerrungen und möglicher Diskriminierung muss durchgeführt werden.",
                        "tooltip": "",
                        "A": "Tech. Maßnahmen - Modell, Daten & Tests<br>Das KI-System und die darin enthaltenen Modelle und Daten wurden in Bezug auf die in ND1.2 festgelegte Zielsetzung hin untersucht. Das beinhaltet mindestens:<br><br>- Begründung der Modellauswahl (einschließlich der Aufgabenstellung und Optimierungsstrategie, sowie ggf. Vor- oder Nachverarbeitungsmaßnahmen im KI-System zur Abschwächung von Verzerrungen)<br>- Beschreibung des Umfangs und Durchführung von Test (siehe ND1.2)<br>- Abgleich mit alternativen Tests/Metriken <br>- Bewertung der Einhaltung vorgegebener Schwellen- bzw. Zielwerte<br>- Dokumentation der Testergebnisse und daraus abgeleiteter Schlussfolgerungen<br>- Beschreibung der Grenzen der Aussagekraft der durchgeführten Tests und ihrer Ergebnisse<br>- Kollaboration mit relevanten Gruppen mit geschützten Eigenschaften",
                        "B": "Tech. Maßnahmen - Modell, Daten & Tests<br>Das KI-System und die darin enthaltenen Modelle und Daten wurden in Bezug auf die in ND1.2 festgelegte Zielsetzung hin untersucht. Das beinhaltet mindestens:<br><br>- Beschreibung des Umfangs und Durchführung von Test (siehe ND1.2)<br>- Abgleich mit alternativen Tests/Metriken <br>- Bewertung der Einhaltung vorgegebener Schwellen- bzw. Zielwerte<br>- Dokumentation der Testergebnisse und daraus abgeleiteter Schlussfolgerungen",
                        "C": "Tech. Maßnahmen - Modell, Daten & Tests<br>Das KI-System und die darin enthaltenen Modelle und Daten wurden in Bezug auf die in ND1.2 festgelegte Zielsetzung hin untersucht. Das beinhaltet mindestens:<br><br>- Beschreibung des Umfangs und Durchführung von Test (siehe ND1.2)<br>- Bewertung der Einhaltung vorgegebener Schwellen- bzw. Zielwerte<br>- Dokumentation der Testergebnisse und daraus abgeleiteter Schlussfolgerungen",
                        "D": "Es wurde keine Analyse hinsichtlich bestehender Verzerrungen und möglicher Diskriminierung durchgeführt.",
                        "docs_id": "21",
                        "reference": "System/Komponente",
                        "type": "Analyse",
                        "weighting": "Maximalwert",
                        "links": "",
                        "criterion": "ND1",
                        "dimension": "ND"
                    },
                    "ND1.4": {
                        "title": "Bei der Entwicklung eines KI-Systems müssen die Grundsätze des universellen Designs angewandt werden, um die Zugänglichkeit für Menschen mit  Einschränkungen zu gewährleisten.",
                        "tooltip": "",
                        "A": "Tech. Maßnahme - Betrieb<br>Dort wo das KI-System mit natürlichen Personen in Kontakt kommt, wird die Zugänglichkeit für mögliche Personen mit Einschränkungen untersucht und durch Maßnahmen unterstützt. Hierzu gehört die Berücksichtigung der folgenden Maßnahmen:<br><br>- Gestaltung der Benutzeroberfläche des KI-Systems berücksichtigt Personen mit Einschränkungen (z.B. Rot-Grün-Schwäche oder motorische Einschränkungen)<br>- Informationen über Ergebnisse und Mechanismen, auch bspw. über eine Benutzeroberfläche,  sind adressatengerecht aufbereitet und berücksichtigen mögliche Einschränkungen der Empfänger<br>- Die Gestaltung der Benutzeroberfläche bzw. bereitgestellter Informationen basiert auf Kollaboration mit Nutzergruppen, die Personen mit Einschränkungen umfassen",
                        "B": "Tech. Maßnahme - Betrieb<br>Dort wo das KI-System mit natürlichen Personen in Kontakt kommt, wird die Zugänglichkeit für mögliche Personen mit Einschränkungen untersucht und durch Maßnahmen unterstützt. Hierzu gehört die Berücksichtigung der folgenden Maßnahmen:<br><br>- Gestaltung der Benutzeroberfläche des KI-Systems berücksichtigt Personen mit Einschränkungen (z.B. Rot-Grün-Schwäche oder motorische Einschränkungen)<br>- Informationen über Ergebnisse und Mechanismen, auch bspw. über eine Benutzeroberfläche,  sind adressatengerecht aufbereitet und berücksichtigen mögliche Einschränkungen der Empfänger",
                        "C": "Tech. Maßnahme - Betrieb<br>Dort wo das KI-System mit natürlichen Personen in Kontakt kommt, wird die Zugänglichkeit für mögliche Personen mit Einschränkungen untersucht und durch Maßnahmen unterstützt. Hierzu gehört die Berücksichtigung der folgenden Maßnahmen:<br><br>- Informationen über Ergebnisse und Mechanismen, auch bspw. über eine Benutzeroberfläche,  sind adressatengerecht aufbereitet und berücksichtigen mögliche Einschränkungen der Empfänger",
                        "D": "Grundsätze des universellen Designs wurden in der Entwicklung nicht betrachtet.",
                        "docs_id": "22",
                        "reference": "System",
                        "type": "Maßnahme",
                        "weighting": "Normal",
                        "links": "",
                        "criterion": "ND1",
                        "dimension": "ND"
                    },
                    "ND1.5": {
                        "title": "Das Personal, das an der Entwicklung des KI-Systems und an der Umsetzung der Maßnahmen zur Verringerung des Risikos von ungerechtfertigter Verzerrung und Diskriminierung beteiligt ist, muss informiert und geschult werden.",
                        "tooltip": "",
                        "A": "Orga. Maßnahmen - Schulung<br>Ein zielgruppenorientiertes Schulungsprogramm wird für alle mit der Entwicklung des KI-Systems betrauten internen und externen Mitarbeiter betrieben. Dieses Programm umfasst mindestens die folgenden Aspekte:<br><br>- Vermittlung der Zweckbestimmung des KI-Systems<br>- Sensibilisierung zu unterschiedlichen möglichen Verzerrungen und dem Erkennen von potenziellen Diskriminierungen im Kontext von KI-Systemen<br>- Umgang mit relevanten Datentypen (z.B. Trainings- und Validierungsdaten, Betriebsdaten, Kundendaten) gemäß den geltenden Richtlinien sowie gesetzlichen und regulatorischen Anforderungen<br>- Anforderungen an die Durchführung von Trainings, Validierungen und Tests der KI-Modells im Kontext von Verzerrungen, Fairness und Diskriminierung<br><br>Das Programm wird regelmäßig basierend auf den gewonnenen Erkenntnissen, Änderungen der Richtlinien aktualisiert. Die verwendeten Inhalte und die Teilnahme am Programm werden dokumentiert.",
                        "B": "Orga. Maßnahmen - Schulung<br>Ein Schulungsprogramm wird für alle mit der Entwicklung des KI-Systems betrauten internen und externen Mitarbeiter betrieben. Dieses Programm umfasst mindestens die folgenden Aspekte:<br><br>- Sensibilisierung zu unterschiedlichen möglichen Verzerrungen und dem Erkennen von potenziellen Diskriminierungen im Kontext von KI-Systemen<br>- Umgang mit relevanten Datentypen (z.B. Trainings- und Validierungsdaten, Betriebsdaten, Kundendaten) gemäß den geltenden Richtlinien sowie gesetzlichen und regulatorischen Anforderungen<br>- Anforderungen an die Durchführung von Trainings, Validierungen und Tests der KI-Modells im Kontext von Verzerrungen, Fairness und Diskriminierung<br><br>Die verwendeten Inhalte und die Teilnahme am Programm werden dokumentiert.",
                        "C": "Orga. Maßnahmen - Schulung<br>Ein Schulungsprogramm wird für alle mit der Entwicklung des KI-Systems betrauten internen und externen Mitarbeiter betrieben. Dieses Programm umfasst mindestens die folgenden Aspekte:<br><br>- Sensibilisierung zu unterschiedlichen möglichen Verzerrungen und dem Erkennen von potenziellen Diskriminierungen im Kontext von KI-Systemen<br>- Anforderungen an die Durchführung von Trainings, Validierungen und Tests der KI-Modells im Kontext von Verzerrungen, Fairness und Diskriminierung<br><br>Die verwendeten Inhalte und die Teilnahme am Programm werden dokumentiert.",
                        "D": "Es ist kein Anleiten des mit der KI-Entwicklung betrauten Personals im Kontext von Verzerrungen und Diskriminierung erfolgt.",
                        "docs_id": "23",
                        "reference": "System",
                        "type": "Maßnahme",
                        "weighting": "Normal",
                        "links": "",
                        "criterion": "ND1",
                        "dimension": "ND"
                    },
                    "ND1.6": {
                        "title": "Technische Maßnahmen zur Vermeidung von ungerechtfertigten Verzerrungen und Diskriminierungen müssen während der Entwicklung des KI-Systems ergriffen werden.",
                        "tooltip": "",
                        "A": "Tech. Maßnahmen - Daten<br>Die zum Training, zur Validierung und zum Testen verwendeten Daten spiegeln die Fairness-Zielsetzung wider und die Testdaten sind geeignet, um mögliche Verzerrungen im KI-System aufzudecken. Hierzu zählt mindestens: <br><br>- Dokumentation der Daten,  Auswahl- oder Erhebungsverfahren und Aufbereitungsschritte  (siehe DA 1.1)<br>- Durchführung von Aufbereitungsschritten zur Verminderung von ungerechtfertigten Verzerrungen in den Daten<br>- Nutzen- und Angemessenheitsargumentation der Maßnahmen in den Trainings- und Testdaten in Bezug auf das Risiko von ungerechtfertigten Verzerrungen und Diskriminierungen)",
                        "B": "Tech. Maßnahmen - Daten<br>Die zum Training, zur Validierung und zum Testen verwendeten Daten spiegeln die Fairness-Zielsetzung wider und die Testdaten sind geeignet, um mögliche Verzerrungen im KI-System aufzudecken. Hierzu zählt mindestens:  <br><br>- Dokumentation der Daten,  Auswahl- oder Erhebungsverfahren und Aufbereitungsschritte  (siehe DA 1.1)<br>- Durchführung von Aufbereitungsschritten zur Verminderung von ungerechtfertigten Verzerrungen in den Daten",
                        "C": "Tech. Maßnahmen - Daten<br>Die zum Training, zur Validierung und zum Testen verwendeten Daten spiegeln die Fairness-Zielsetzung wider und die Testdaten sind geeignet, um mögliche Verzerrungen im KI-System aufzudecken. Hierzu zählt mindestens: <br><br>- Dokumentation der Daten,  Auswahl- oder Erhebungsverfahren und Aufbereitungsschritte  (siehe DA 1.1)<br>- Durchführung von Aufbereitungsschritten zur Verminderung von ungerechtfertigten Verzerrungen in den Daten",
                        "D": "Es wurden keine Maßnahmen zur Vermeidung von ungerechtfertigten Verzerrungen in der Entwicklung ergriffen.",
                        "docs_id": "24",
                        "reference": "System/Komponente",
                        "type": "Maßnahme",
                        "weighting": "Normal",
                        "links": "DA1.1",
                        "criterion": "ND1",
                        "dimension": "ND"
                    },
                    "ND1.7": {
                        "title": "Ein Mechanismus für Nutzerfeedback muss verfügbar sein, um Probleme im Zusammenhang mit möglicher Diskriminierung zu melden.",
                        "tooltip": "",
                        "A": "Tech. Maßnahmen - Betrieb<br>- Es gibt mindestens einen Kanal durch den mit dem Anbieter zum Zweck des Feedbacks in Kontakt getreten werden kann<br>- Kanäle sind durch jeden mit begründetem Interesse  klar im Kontext des KI-Systems identifizierbar<br>- Es ist erkennbar, dass die möglichen Kanäle zur Abgabe von Feedback vorgesehen sind<br><br>Orga. Maßnahmen - Systemnahe Prozesse<br>- Sichtung und Überprüfung des Feedbacks und die Vergabe der Verantwortung hierfür erfolgt<br>- Garantierte und individualisierte Beantwortung von Anfragen<br>- Prozess zur Weiterleitung und Einarbeitung des Feedbacks in die Weiterentwicklung des KI-Systems",
                        "B": "Tech. Maßnahmen - Betrieb<br>- Es gibt mindestens einen Kanal durch den mit dem Anbieter zum Zweck des Feedbacks in Kontakt getreten werden kann<br>- Kanäle sind durch jeden mit begründetem Interesse  klar im Kontext des KI-Systems identifizierbar<br><br>Orga. Maßnahmen - Systemnahe Prozesse<br>- Sichtung und Überprüfung des Feedbacks und die Vergabe der Verantwortung hierfür erfolgt",
                        "C": "Tech. Maßnahmen - Betrieb<br>- Die Kontaktinformationen sind dem KI-System beigefügt und können zum Zweck des Feedbacks genutzt werden",
                        "D": "Es sind keine Kanäle vorhanden, um Feedback zum KI-System zu geben",
                        "docs_id": "25",
                        "reference": "System",
                        "type": "Maßnahme",
                        "weighting": "Normal",
                        "links": "",
                        "criterion": "ND1",
                        "dimension": "ND"
                    },
                    "ND1.8": {
                        "title": "Das KI-System muss in Entwicklung und Betrieb zum Zweck der Vermeidung unerwünschter  Verzerrung und Diskriminierung überwacht werden (können).",
                        "tooltip": "",
                        "A": "Tech. Maßnahme - Betrieb<br>Eine kontinuierliche Überwachung muss für die Implementierung des  KI-Systems vorgesehen sein und auf Basis entsprechender Protokollierung (siehe TR1.7) umgesetzt werden können. Dies beinhaltet die Erprobung folgenden Möglichkeiten:<br><br>- Monitoring der Leistung inklusive einer Überwachung der Modelle und Daten (d.h. einkommende Produktionsdaten und ggf. sich erweiternde Trainingsdatenbasis)<br>- Monitoring von Verzerrungen inklusive einer Überwachung der Daten (d.h. einkommende Produktionsdaten und ggf. sich erweiternde Trainingsdatenbasis) im Kontext der Vermeidung von ungerechtfertigter Diskriminierung und Verzerrungen<br>- Durchführung von Tests (z.B. Sanity Checks), die im Rahmen des Monitorings eingesetzt werden, um etwa Model und Concept Drift  oder auch schädliche Eingabedaten zu erkennen<br>- Falls anwendbar, Durchführung von Tests zur Erkennung von Missbrauch und schädlichen Eingabedaten<br>- Ggf. Qualitätsüberprüfung der sich erweiternden Trainingsdatenbasis  <br><br>Organisatorische Maßnahme - Systemnahe Prozesse<br>Zusätzlich zur technischen Ermöglichung des Monitorings sollten die folgenden Aspekte vorbereitet werden:<br>- Konzept zur (automatischen) Überwachung und -prüfung größerer Veränderungen am KI-System, inklusive bei Soft- und Hardware-Komponenten, aber insbesondere im Fall von Online Learning<br>- Empfohlene Tests müssen als Teil eines kontinuierlichen Testplans dokumentiert sein, insbesondere im Fall von Online Learning<br>- Falls möglich, Mechanismen in Form sinnvoller Definition von Schwellwerten bzw. Szenarien, bei denen (menschliche) Überprüfung und Mitigationsmaßnahmen eintreten sollten<br>- Mechanismen zum Teilen von neuen Informationen über mögliche sicherheitsrelevante Vorfälle und ihrer Vermeidung ",
                        "B": "Tech. Maßnahme - Betrieb<br>Eine kontinuierliche Überwachung muss für die Implementierung des  KI-Systems vorgesehen sein und auf Basis entsprechender Protokollierung (siehe TR1.7) umgesetzt werden können. Dies beinhaltet die folgenden Möglichkeiten:<br><br>- Monitoring der Leistung inklusive einer Überwachung der Modelle und Daten (d.h. einkommende Produktionsdaten und ggf. sich erweiternde Trainingsdatenbasis)<br>- Monitoring von Verzerrungen inklusive einer Überwachung der Daten (d.h. einkommende Produktionsdaten und ggf. sich erweiternde Trainingsdatenbasis) im Kontext der Vermeidung von ungerechtfertigter Diskriminierung und Verzerrungen<br>- Durchführung von Tests (z.B. Sanity Checks), die im Rahmen des Monitorings eingesetzt werden, um etwa Model und Concept Drift, oder auch schädliche Eingabedaten zu erkennen<br><br>Organisatorische Maßnahme - Systemnahe Prozesse<br>Zusätzlich zur technischen Ermöglichung des Monitorings sollten die folgenden Aspekte vorbereitet werden:<br>- Konzept zur (automatischen) Überwachung und -prüfung größerer Veränderungen am KI-System, inklusive bei Soft- und Hardware-Komponenten, aber insbesondere im Fall von Online Learning<br>- Empfohlene Tests müssen als Teil eines kontinuierlichen Testplans dokumentiert sein, insbesondere im Fall von Online Learning",
                        "C": "Tech. Maßnahme - Betrieb<br>Eine kontinuierliche Überwachung muss für die Implementierung des  KI-Systems vorgesehen sein und auf Basis entsprechender Protokollierung (siehe TR1.7) umgesetzt werden können. Dies beinhaltet die folgenden Möglichkeiten:<br><br>- Monitoring der Leistung inklusive einer Überwachung der Modelle und Daten (d.h. einkommende Produktionsdaten und ggf. sich erweiternde Trainingsdatenbasis)<br>- Monitoring von Verzerrungen inklusive einer Überwachung der Daten (d.h. einkommende Produktionsdaten und ggf. sich erweiternde Trainingsdatenbasis) im Kontext der Vermeidung von ungerechtfertigter Diskriminierung und Verzerrungen<br>- Durchführung von Tests (z.B. Sanity Checks), die im Rahmen des Monitorings eingesetzt werden, um etwa Model und Concept Drift, oder auch schädliche Eingabedaten zu erkennen",
                        "D": "",
                        "docs_id": "26",
                        "reference": "System",
                        "type": "Maßnahme",
                        "weighting": "Normal",
                        "links": "",
                        "criterion": "ND1",
                        "dimension": "ND"
                    },
                    "ND1.9": {
                        "title": "Es muss bewertet werden, ob die ergriffenen Maßnahmen die festgestellten Risiken auf ein annehmbares Maß vermindert haben und die Qualität des KI-Systems den gesetzten Zielvorgaben entspricht.",
                        "tooltip": "",
                        "A": "Bewertung<br>- Zusammenfassende Betrachtung der Effekte der Durchführung der technischen und organisatorischen Maßnahmen<br>- Abwägung von Wechselwirkungen der ergriffenen Maßnahmen, und Abwägung der Mitigation der Risiken im Zusammenspiel mit den Risiken anderer Qualitätsdimensionen<br>- Ermittlung und Beschreibung des Restrisikos nach Durchführung der technischen und organisatorischen Maßnahmen<br>- Einschätzung durch eine qualifizierte und autorisierte Person, ob das Restrisiko tolerierbar ist<br>- Begründung der Tolerierbarkeit des Restrisikos",
                        "B": "Bewertung<br>- Abwägung von Wechselwirkungen der ergriffenen Maßnahmen, und Abwägung der Mitigation der Risiken im Zusammenspiel mit den Risiken anderer Qualitätsdimensionen<br>- Einschätzung durch eine qualifizierte und autorisierte Person, ob das Restrisiko tolerierbar ist<br>- Begründung der Tolerierbarkeit des Restrisikos",
                        "C": "Bewertung<br>- Einschätzung durch eine qualifizierte und autorisierte Person, ob das Restrisiko tolerierbar ist<br>- Begründung der Tolerierbarkeit des Restrisikos",
                        "D": "Eine Bewertung wurde nicht durchgeführt",
                        "docs_id": "27",
                        "reference": "System",
                        "type": "Bewertung",
                        "weighting": "Maximalwert",
                        "links": "",
                        "criterion": "ND1",
                        "dimension": "ND"
                    }
                },
                "title": "Vermeidung von ungerechtfertigter Diskriminierung und Verzerrung"
            }
        ]
    },
    "TR": {
        "title": "Transparenz",
        "short_title": "Transparenz",
        "quality_dimension_id": 30,
        "icon": "transparency",
        "criteria": [
            {
                "index": "TR1",
                "criterion_type_id": 30,
                "indicators": {
                    "TR1.1": {
                        "title": "Verwendungszweck und Anwendungsbereich des KI-Systems sind klar definiert und beschrieben.",
                        "tooltip": "Siehe auch Glossar",
                        "A": "Analyse - Definition<br>Der Verwendungszweck ist definiert im Sinne von: <br>i) Verbesserungen und Vorteile, die mit dem System erreicht werden können und <br>ii) Funktionalitäten des KI-Systems, mithilfe derer diese Verbesserungen und Vorteile realisierbar sein sollen<br>iii) angestrebte/mögliche/erlaubte Nutzergruppen und Betroffene Personen (\"Data Subjects\") <br><br>Der Anwendungsbereich ist mit Bezug auf den Verwendungszweck definiert und umfasst:<br>- die zu erwarteten Eingabedaten und angestrebte Systemausgaben (inklusive Format und Inhalt)<br>- eine umfassende Beschreibung von Einsatzkontexten/ Umgebungen, für die das KI-System geeignet ist und auch solche, in denen das KI-System nicht eingesetzt werden darf<br>- Beschreibung von vorhersehbarer missbräuchlicher oder fehlgeleiteter Anwendung des KI-Systems<br>-falls anwendbar: Definition einer ODD<br><br>Die Einsehbarkeit der Definitionen ist für relevante Interessensgruppen möglich.",
                        "B": "Analyse - Definition<br>Der Verwendungszweck ist definiert im Sinne von Funktionalitäten des KI-Systems sowie angestrebte/mögliche/erlaubte Nutzergruppen und Betroffene Personen (\"Data Subjects\").<br><br>Der Anwendungsbereich ist mit Bezug auf den Verwendungszweck definiert und umfasst:<br>- die zu erwarteten Eingabedaten und angestrebte Systemausgaben (inklusive Format und Inhalt)<br>- Grobe Beschreibung von Einsatzkontexten/ Umgebungen, für die das KI-System geeignet ist und auch solche, in denen das KI-System nicht eingesetzt werden darf",
                        "C": "Analyse - Definition<br>Der Verwendungszweck ist definiert im Sinne von Funktionalitäten des KI-Systems.<br><br>Der Anwendungsbereich ist mit Bezug auf den Verwendungszweck definiert und umfasst:<br>- die zu erwarteten Eingabedaten und angestrebte Systemausgaben (inklusive Format und Inhalt)<br>- Grobe Beschreibung von Einsatzkontexten/ Umgebungen, für die das KI-System geeignet ist",
                        "D": "Der Verwendungszweck und Anwendungsbereich  sind nicht klar definiert.",
                        "docs_id": "28",
                        "reference": "System",
                        "type": "Analyse",
                        "weighting": "Maximalwert",
                        "links": "global relevant; insbesondere TR1.2, TR2.1, VE1.1, VE2.1, CY1.1, DA2.1, DA3.1, ND1.1, MA1.2, MA2.2",
                        "criterion": "TR1",
                        "dimension": "TR"
                    },
                    "TR1.2": {
                        "title": "Die Risiken im Kontext einer mangelnden Rückverfolgbarkeit und Dokumentation des KI-System müssen analysiert werden.",
                        "tooltip": "",
                        "A": "Analyse-Risiko<br>Detaillierte Risikoanalyse einschließlich Quantifizierung von Eintrittswahrscheinlichkeiten und Risiken:<br>- Identifikation der möglichen Risiken und ihrer Ursachen<br>- Zuweisung der Risikoverantwortung<br>- Schätzung der Eintrittswahrscheinlichkeit<br>- Schätzung der Aufdeckungswahrscheinlichkeit<br>- Schätzung der Auswirkung<br>- Strukturierte Abstufung und Priorisierung der Risiken <br><br>Mindestens die folgenden Risikoquellen sind unter Beachtung des Verwendungszwecks (siehe TR1.1) zu berücksichtigen:<br>- Mangelndes Vertrauen von Nutzer<br>- Unklare Rechenschaft<br>- Verschleiern von Verzerrungen oder Sicherheitsschwachstellen<br>- Nicht-Einhaltung regulatorischer Vorgaben<br>- Probleme mit der Interoperabilität",
                        "B": "Analyse-Risiko<br>Limitierte Risikoanalyse mit Fokus auf den Schutzbedarf ohne Quantifizierung von Wahrscheinlichkeiten:<br>- Identifikation der möglichen Risiken<br>- Zuweisung der Risikoverantwortung<br>- Schätzung der Auswirkung<br>- Strukturierte Abstufung und Priorisierung der Risiken<br><br>Mindestens die folgenden Risikoquellen sind unter Beachtung des Verwendungszwecks (siehe TR1.1) zu berücksichtigen:<br>- Mangelndes Vertrauen von Nutzer*innen<br>- Unklare Rechenschaft<br>- Verschleiern von Verzerrungen oder Sicherheitsschwachstellen<br>- Nicht-Einhaltung regulatorischer Vorgaben<br>- Probleme mit der Interoperabilität",
                        "C": "Analyse-Risiko<br>Hauptsächlich qualitative Abschätzung ohne Wahrscheinlichkeiten:<br>- Identifikation der möglichen Gefährdungen<br>- Zuweisung der  Risikoverantwortung<br>- Qualitative Schätzung der Auswirkung<br>- Qualitative Abstufung und Priorisierung der Risiken<br><br>Mindestens die folgenden Risikoquellen sind unter Beachtung des Verwendungszwecks (siehe TR1.1) zu berücksichtigen:<br>- Mangelndes Vertrauen von Nutzer*innen<br>- Unklare Rechenschaft<br>- Verschleiern von Verzerrungen oder Sicherheitsschwachstellen<br>- Nicht-Einhaltung regulatorischer Vorgaben<br>- Probleme mit der Interoperabilität",
                        "D": "Es wurde keine Risikoanalyse durchgeführt",
                        "docs_id": "29",
                        "reference": "System",
                        "type": "Analyse",
                        "weighting": "Maximalwert",
                        "links": "TR1.1",
                        "criterion": "TR1",
                        "dimension": "TR"
                    },
                    "TR1.3": {
                        "title": "Die Architektur des KI-Systems muss dokumentiert werden.",
                        "tooltip": "",
                        "A": "Tech. Maßnahmen - Sonstige<br>Die Systemarchitektur ist dokumentiert, einschließlich:<br>- KI-Komponenten (siehe TR1.4)<br>- Hard- und Software-Einbettung und Anforderungen an diese<br>- Schnittstellen z.B. für Nutzer*innen oder zu anderen Systemen<br>- Informationsfluss zwischen einzelnen Bestandeilen des Systems<br>- Begründung der Wahl der Architektur mit einer Beschreibung der Rolle der einzelnen Bestandteile im Kontext des Zwecks des KI-Systems <br>- Ggf. Lizenz unter welcher das System verwendet werden darf<br>- Vorgesehene Modalitäten des KI-Systems zur \"eigenständigen\" Anpassung/Weiterentwicklung während des Betriebs inklusive Online-Learning",
                        "B": "Tech. Maßnahmen -  Sonstige<br>Die Systemarchitektur ist dokumentiert, einschließlich:<br>- KI-Komponenten (siehe TR1.4)<br>- Hard- und Software-Einbettung und Anforderungen an diese<br>- Schnittstellen z.B. für Nutzer*innen oder zu anderen Systemen<br>- Informationsfluss zwischen einzelnen Bestandeilen des Systems<br>- Ggf. Lizenz unter welcher das System verwendet werden darf",
                        "C": "Tech. Maßnahmen - Sonstige<br>Die Systemarchitektur ist dokumentiert, einschließlich:<br>- KI-Komponenten (siehe TR1.4)<br>- Hard- und Software-Einbettung<br>- Schnittstellen z.B. für Nutzer*innen oder zu anderen Systemen<br>- Informationsfluss zwischen einzelnen Bestandeilen des Systems<br>- Ggf. Lizenz unter welcher das System verwendet werden darf",
                        "D": "Die Architektur des Systems ist nicht dokumentiert.",
                        "docs_id": "30",
                        "reference": "System",
                        "type": "Analyse",
                        "weighting": "Maximalwert",
                        "links": "VE1.1, VE2.1, VE1.2, VE1.3, CY1.5, CY1.6",
                        "criterion": "TR1",
                        "dimension": "TR"
                    },
                    "TR1.4": {
                        "title": "Die Merkmale des/der KI-Modells/Modelle müssen dokumentiert werden.",
                        "tooltip": "Die Architekturbeschreibung des KI-Modells kann z.B. Typ des Modells, Art und Anzahl der Ebenen/Schichten bei neuronalen Netzen sowie auch  Funktionen zur Aktivierung oder Belohnung umfassen.",
                        "A": "Tech. Maßnahmen - Modell<br>Eigenschaften werden dokumentiert, einschließlich:<br>- Modellbezeichnung<br>- Modellversion(-shistorie) inklusive Datum<br>- Architekturbeschreibung und -diagramm des KI-Modells<br>- Erwartete Eingabedaten<br>- Erwartete Ausgabedaten<br>- Verwendete Trainings- & Testdaten<br>- Erwartete Leistungsfähigkeit<br>- Durchgeführte Tests, ermittelte Testergebnisse und abgeleitete Schlussfolgerungen<br><br>Die Wahl der Architektur und des Designs des KI-Systems und/oder -Modells muss begründet werden inklusive der Vorteile des Modells und Abwägungen in Bezug auf mögliche Zielkonflikte sind beschrieben.",
                        "B": "Tech. Maßnahmen - Modell<br>Eigenschaften werden dokumentiert, einschließlich:<br>- Modellbezeichnung<br>- Modellversion(-shistorie) inklusive Datum<br>- Architekturbeschreibung und -diagramm des KI-Modells<br>- Erwartete Eingabedaten<br>- Erwartete Ausgabedaten<br>- Verwendete Trainings- & Testdaten<br>- Erwartete Leistungsfähigkeit",
                        "C": "Tech. Maßnahmen - Modell<br>Eigenschaften werden dokumentiert, einschließlich:<br>- Modellbezeichnung<br>- Aktuellste Modellversion mit Datum<br>- Grobe Architekturbeschreibung des KI-Modells<br>- Erwartete Eingabedaten<br>- Erwartete Ausgabedaten<br>- Verwendete Trainings- & Testdaten<br>- Erwartete Leistungsfähigkeit",
                        "D": "Es ist keine Dokumentation des/der KI-Modells/Modelle vorhanden.",
                        "docs_id": "31",
                        "reference": "Komponente",
                        "type": "Analyse",
                        "weighting": "Maximalwert",
                        "links": "VE1.2, VE1.3, CY1.5, CY1.6",
                        "criterion": "TR1",
                        "dimension": "TR"
                    },
                    "TR1.5": {
                        "title": "Die Merkmale der verwendeten Datensätze müssen dokumentiert werden.",
                        "tooltip": "",
                        "A": "Analyse - Definition<br>Zusammensetzung der Daten<br>   - Anzahl der Dateninstanzen / Größe der Daten<br>    - Standards für Datenstrukturen/-Formate    <br>  <br>Prozess der Datenerhebung<br>   - Methode der Datenerhebung<br>   - Quelle der Daten<br>   - Verantwortliche für Datenerhebung<br><br>Datenverarbeitungsschritte<br>   - Erklärung der Features und ihrer möglichen Qualitätsdimensionen und Bereiche der Qualitätsdimensionen<br>   - Vorverarbeitung<br>   - Labeling<br>   - Cleaning<br><br>Pflege der Daten<br>   - Speicherperioden<br>   - Aktualisierung der Daten",
                        "B": "Analyse - Definition<br>Zusammensetzung der Daten<br>   - Anzahl der Dateninstanzen / Größe der Daten<br>    - Standards für Datenstrukturen/-Formate    <br>  <br>Prozess der Datenerhebung<br>   - Methode der Datenerhebung<br>   - Quelle der Daten<br><br>Datenverarbeitungsschritte<br>   - Erklärung der Features und ihrer möglichen Qualitätsdimensionen und Bereiche der Qualitätsdimensionen<br>   - Labeling<br>   - Cleaning<br><br>Pflege des Datensatzes<br>   - Speicherperioden<br>   - Aktualisierung der Daten",
                        "C": "Analyse - Definition<br>Zusammensetzung der Daten<br>   - Anzahl der Dateninstanzen / Größe der Daten<br>    - Standards für Datenstrukturen/-Formate    <br>  <br>Prozess der Datenerhebung<br>   - Quelle der Daten<br><br>Datenverarbeitungsschritte<br>   - Erklärung der Features und ihrer möglichen Qualitätsdimensionen und Bereiche der Qualitätsdimension<br><br>Pflege des Datensatzes<br>   - Speicherperioden<br>   - Aktualisierung der Date",
                        "D": "Die Merkmale der Daten wurden nicht dokumentiert",
                        "docs_id": "32",
                        "reference": "Komponente",
                        "type": "Analyse",
                        "weighting": "Maximalwert",
                        "links": "",
                        "criterion": "TR1",
                        "dimension": "TR"
                    },
                    "TR1.6": {
                        "title": "Der Entwurfs- und Entwicklungsprozess des KI-Systems muss beschrieben werden.",
                        "tooltip": "Für die Dokumentation von Datensätzen und Modell können z.B. geläufige Formate, wie Data Sheets bzw. Model Cards verwendet werden.",
                        "A": "Orga. Maßnahme - Systemnahe Prozesse<br>Die Dokumentation zum Entwurfs- und Entwicklungsprozess umfasst:<br>- Übersichtl der verantwortlichen Person(en) und deren Aufgaben <br>- Rückverfolgbarkeit und systematische Vorgehensweise einzelner Arbeitselemente (z.B. durch Projektmanagement-Tool)<br>- Ggfs. Beschreibung und Begründung der Anpassungen der Architektur des KI-Systems im Laufe der Entwicklung <br><br>Tech. Maßnahmen - Daten<br>Die Dokumentation zum Entwurfs- und Entwicklungsprozess umfasst:<br>- Verwendete Daten und ihre Herkunft<br>- Relevante Datenvorbereitungsprozesse<br>(z.B. Bereinigung, Annotation, Kennzeichnung, Bereinigung, Anreicherung, Aggregation, Feature Engineering)<br>- Rückverfolgung der Data-Lineage und zur möglichen Wiederherstellung der Daten<br><br>Tech. Maßnahmen - Modell<br>Die Dokumentation zum Entwurfs- und Entwicklungsprozess umfasst: <br>- Ein System zur Versionsverwaltung und Nachverfolgung von Änderungen an den KI-Modellen und Aufzeichnung der Trainings und der jeweils eingesetzten Daten<br>- Beschreibung der Änderungen an KI-Modellen im Laufe des Entwicklungsprozesses",
                        "B": "Orga. Maßnahme - Systemnahe Prozesse<br>Die Dokumentation zum Entwurfs- und Entwicklungsprozess umfasst:<br>- Übersichtl der verantwortlichen Person(en) und deren Aufgaben<br>- Rückverfolgbarkeit und systematische Vorgehensweise einzelner Arbeitselemente (z.B. durch Projektmanagement-Tool)<br><br>Tech. Maßnahmen - Daten<br>Die Dokumentation zum Entwurfs- und Entwicklungsprozess umfasst:<br>- Verwendete Daten und ihre Herkunft<br>- Relevante Datenvorbereitungsprozesse<br>(z.B. Bereinigung, Annotation, Kennzeichnung, Bereinigung, Anreicherung, Aggregation, Feature Engineering)<br>- Rückverfolgung der Data-Lineage<br><br>Tech. Maßnahmen - Modell<br>Die Dokumentation zum Entwurfs- und Entwicklungsprozess umfasst: <br>- Ein System zur Versionsverwaltung und Nachverfolgung von Änderungen an den KI-Modellen und Aufzeichnung der Trainings und der jeweils eingesetzten Daten",
                        "C": "Orga. Maßnahme - Systemnahe Prozesse<br>Die Dokumentation zum Entwurfs- und Entwicklungsprozess umfasst:<br>- Übersichtl der verantwortlichen Person(en) und deren Aufgaben<br>- Rückverfolgbarkeit und systematische Vorgehensweise einzelner Arbeitselemente (z.B. durch Projektmanagement-Tool)<br><br>Tech. Maßnahmen - Daten<br>Die Dokumentation zum Entwurfs- und Entwicklungsprozess umfasst:<br>- Verwendete Daten und ihre Herkunft<br>- Rückverfolgung der Data-Lineage<br><br>Tech. Maßnahmen - Modell<br>Die Dokumentation zum Entwurfs- und Entwicklungsprozess umfasst: <br>- Ein System zur Versionsverwaltung und Nachverfolgung von Änderungen an den KI-Modellen und Aufzeichnung der Trainings und der jeweils eingesetzten Daten",
                        "D": "Der Entwurfs- und Entwicklungsprozess wurde nicht dokumentiert.",
                        "docs_id": "33",
                        "reference": "System/Komponente",
                        "type": "Analyse",
                        "weighting": "Normal",
                        "links": "VE1.4, VE1.5",
                        "criterion": "TR1",
                        "dimension": "TR"
                    },
                    "TR1.7": {
                        "title": "Das KI-System muss Funktionen zur Überwachung, Erfassung und Aufzeichnung seines Verhaltens enthalten.",
                        "tooltip": "",
                        "A": "Orga. Maßnahmen - Systemnahe Prozesse<br>Es muss ein zweckorientiertes Konzept zur Protokollierung (\"Logging\") des KI-Systems sowie der darin verwendeten während der Entwicklung und des Betriebs erstellt werden. Das Konzept umfasst mindestens die folgenden Informationen:<br>- Definition der zu überwachenden Daten und Metriken<br>- Definition einer dem Zweck entsprechenden Aufbewahrungsfrist der Protokolle<br>- Definition einer dem Zweck entsprechenden Aufzeichnungshäufigkeit<br>- Definition der Aufzeichnungsstruktur<br>- Beschreibung zur Schnittstelle, über die die Protokollierung angesprochen werden kann<br><br>Tech. Maßnahmen - Betrieb<br>Es ist eine Schnittstelle vorhanden, die es im Betrieb erlaubt mindestens die folgenden Informationen zur erfassen und zu überwachen:<br>- Falls technisch möglich und sinnvoll im Anwendungskontext,, Nutzerinteraktionen und Modellanfragen einschließlich der für die Anfrage verwendeten Modellversion, Eingaben und Ausgaben über einen definierten Zeitraum<br>- Fehlfunktionen (z.B. bei der Verarbeitung von automatischen oder manuellen Aktionen)<br>- Zugriffe auf Daten, Dienste oder Funktionen durch die Nutzer<br>- Änderungen an sicherheitsrelevanten Konfigurationsparametern (z.B. Fehlerbehandlung und Protokollierungsmechanismen, Benutzerauthentifizierung, Aktionsautorisierung, Kryptographie und Kommunikationssicherheit)<br>- Verletzung der Funktionalitäts-, Schutz- oder Qualitätsziele des KI-Systems<br><br>Sind bestimmte Informationen technisch nicht sinnvoll zu protokollieren, ist dies zu begründen.<br><br>Die zu jeweils zu erfassenden Metadaten erfassen im Rahmen der technischen Möglichkeiten mindestens Informationen über:<br>- Art, Zeitpunkt, Dauer, Speicherort und Akteur/System von aufgezeichneten Ereignissen oder Aktionen",
                        "B": "Orga. Maßnahmen - Systemnahe Prozesse<br>Es muss ein zweckorientiertes  Konzept zur Protokollierung (\"Logging\") des KI-Systems sowie der darin verwendeten während der Entwicklung und des Betriebs erstellt werden. Das Konzept umfasst mindestens die folgenden Informationen:<br>- Definition der zu überwachenden Daten und Metriken<br>- Definition einer dem Zweck entsprechenden Aufbewahrungsfrist der Protokolle<br>- Definition einer dem Zweck entsprechenden Aufzeichnungshäufigkeit<br>- Definition der Aufzeichnungsstruktur<br>- Beschreibung zur Schnittstelle, über die die Protokollierung angesprochen werden kann<br><br>Tech. Maßnahmen - Betrieb<br>Es ist eine Schnittstelle vorhanden, die es im Betrieb erlaubt mindestens die folgenden Informationen zur erfassen und zu überwachen:<br>- Falls technisch möglich und sinnvoll im Anwendungskontext, Nutzerinteraktionen und Modellanfragen einschließlich der für die Anfrage verwendeten, Modellversion, Eingaben und Ausgaben <br>- Fehlfunktionen (z.B. bei der Verarbeitung von automatischen oder manuellen Aktionen)<br><br>Sind bestimmte Informationen technisch nicht sinnvoll zu protokollieren, ist dies zu begründen.<br><br>Die zu jeweils zu erfassenden Metadaten erfassen im Rahmen der technischen Möglichkeiten mindestens Informationen über:<br>- Art, Zeitpunkt, Dauer, Speicherort und Akteur/System von aufgezeichneten Ereignissen oder Aktionen",
                        "C": "Orga. Maßnahmen - Systemnahe Prozesse<br>Es muss ein zweckorientiertes Konzept zur Protokollierung (\"Logging\") des KI-Systems sowie der darin verwendeten während der Entwicklung und des Betriebs erstellt werden. Das Konzept umfasst mindestens die folgenden Informationen:<br>- Definition der zu überwachenden Daten und Metriken<br>- Beschreibung zur Schnittstelle, über die die Protokollierung angesprochen werden kann<br><br>Tech. Maßnahmen - Betrieb<br>Es ist eine Schnittstelle vorhanden, die es im Betrieb erlaubt mindestens die folgenden Informationen zur erfassen und zu überwachen:<br>- Falls technisch möglich und sinnvoll im Anwendungskontext, Nutzerinteraktionen und Modellanfragen einschließlich der für die Anfrage verwendeten Modellversion, Eingaben und Ausgaben <br>- Fehlfunktionen (z.B. bei der Verarbeitung von automatischen oder manuellen Aktionen)<br><br>Sind bestimmte Informationen technisch nicht sinnvoll zu protokollieren, ist dies zu begründen.<br><br>Die zu jeweils zu erfassenden Metadaten erfassen im Rahmen der technischen Möglichkeiten mindestens Informationen über:<br>- Art, Zeitpunkt, Dauer, Speicherort und Akteur/System von aufgezeichneten Ereignissen oder Aktionen",
                        "D": "Eine Aufzeichnung wichtiger Daten zum System ist nicht vorbereitet.",
                        "docs_id": "34",
                        "reference": "System/Komponente",
                        "type": "Maßnahme",
                        "weighting": "Normal",
                        "links": "VE1.6, DA2.6",
                        "criterion": "TR1",
                        "dimension": "TR"
                    },
                    "TR1.8": {
                        "title": "Es muss bewertet werden, ob die ergriffenen Maßnahmen die festgestellten Risiken auf ein annehmbares Maß vermindert haben und die Qualität des KI-Systems den gesetzten Zielvorgaben entspricht.",
                        "tooltip": "",
                        "A": "Bewertung<br>- Zusammenfassende Betrachtung der Effekte der Durchführung der technischen und organisatorischen Maßnahmen<br>- Abwägung von Wechselwirkungen der ergriffenen Maßnahmen, und Abwägung der Mitigation der Risiken im Zusammenspiel mit den Risiken anderer Qualitätsdimensionen<br>- Ermittlung und Beschreibung des Restrisikos nach Durchführung der technischen und organisatorischen Maßnahmen<br>- Einschätzung durch eine qualifizierte und autorisierte Person, ob das Restrisiko tolerierbar ist<br>- Begründung der Tolerierbarkeit des Restrisikos",
                        "B": "Bewertung<br>- Abwägung von Wechselwirkungen der ergriffenen Maßnahmen, und Abwägung der Mitigation der Risiken im Zusammenspiel mit den Risiken anderer Qualitätsdimensionen<br>- Einschätzung durch eine qualifizierte und autorisierte Person, ob das Restrisiko tolerierbar ist<br>- Begründung der Tolerierbarkeit des Restrisikos",
                        "C": "Bewertung<br>- Einschätzung durch eine qualifizierte und autorisierte Person, ob das Restrisiko tolerierbar ist<br>- Begründung der Tolerierbarkeit des Restrisikos",
                        "D": "Eine Bewertung wurde nicht durchgeführt.",
                        "docs_id": "35",
                        "reference": "System",
                        "type": "Bewertung",
                        "weighting": "Maximalwert",
                        "links": "",
                        "criterion": "TR1",
                        "dimension": "TR"
                    }
                },
                "title": "Rückverfolgbarkeit & Dokumentation"
            },
            {
                "index": "TR2",
                "criterion_type_id": 31,
                "indicators": {
                    "TR2.1": {
                        "title": "Die Risiken im Kontext einer mangelnden Interpretierbarkeit oder Erklärbarkeit des KI-System müssen analysiert werden.",
                        "tooltip": "",
                        "A": "Analyse-Risiko<br>Detaillierte Risikoanalyse zur Erklärbarkeit einschließlich Quantifizierung von Eintrittswahrscheinlichkeiten und Risiken:<br>- Identifikation der möglichen Risiken und ihrer Ursachen<br>- Zuweisung der Risikoverantwortung<br>- Schätzung der Eintrittswahrscheinlichkeit<br>- Schätzung der Aufdeckungswahrscheinlichkeit<br>- Schätzung der Auswirkung<br>- Strukturierte Abstufung und Priorisierung der Risiken <br><br>Mindestens die folgenden Risikoquellen sind unter Beachtung des Verwendungszwecks (siehe TR1.1) zu berücksichtigen:<br>- Mangelndes Vertrauen von Nutzer*innen<br>- Mangelndes Verständnis der Ausgaben<br>- Fehlerhafte Entscheidungen aufgrund eines unzureichenden Verständnisses der Ausgaben",
                        "B": "Analyse-Risiko<br>Limitierte Risikoanalyse zur Erklärbarkeit mit Fokus auf den Schutzbedarf ohne Quantifizierung von Wahrscheinlichkeiten:<br>- Identifikation der möglichen Risiken<br>- Zuweisung der Risikoverantwortung<br>- Schätzung der Auswirkung<br>- Strukturierte Abstufung und Priorisierung der Risiken<br><br>Mindestens die folgenden Risikoquellen sind unter Beachtung des Verwendungszwecks (siehe TR1.1) zu berücksichtigen:<br>- Mangelndes Vertrauen von Nutzer*innen<br>- Mangelndes Verständnis der Ausgaben<br>- Fehlerhafte Entscheidungen aufgrund eines unzureichenden Verständnisses der Ausgaben",
                        "C": "Analyse-Risiko<br>Hauptsächlich qualitative Abschätzung ohne Wahrscheinlichkeiten zur Erklärbarkeit:<br>- Identifikation der möglichen Gefährdungen<br>- Zuweisung der  Risikoverantwortung<br>- Qualitative Schätzung der Auswirkung<br>- Qualitative Abstufung und Priorisierung der Risiken<br><br>Mindestens die folgenden Risikoquellen sind unter Beachtung des Verwendungszwecks (siehe TR1.1) zu berücksichtigen:<br>- Mangelndes Vertrauen von Nutzer*innen<br>- Mangelndes Verständnis der Ausgaben<br>- Fehlerhafte Entscheidungen aufgrund eines unzureichenden Verständnisses der Ausgaben",
                        "D": "Es wurde keine Risikoanalyse durchgeführt.",
                        "docs_id": "36",
                        "reference": "System",
                        "type": "Analyse",
                        "weighting": "Maximalwert",
                        "links": "TR1.1",
                        "criterion": "TR2",
                        "dimension": "TR"
                    },
                    "TR2.2": {
                        "title": "Die Interpretierbarkeit und Erklärbarkeit des KI-Systems muss in Hinblick auf die Nutzergruppen, den Zweck und die Risiken analysiert werden.",
                        "tooltip": "",
                        "A": "Tech. Maßnahme - Tests<br>Der Grad, zu dem das KI-System interpretierbar oder erklärbar für die erlaubten Nutzergruppen ist, muss unter Beachtung der Risikoanalyse (TR2.1) und Zweckbestimmung (TR1.1) analysiert werden.<br><br>Hierzu muss der Zusammenhang zwischen Eingaben und Ausgaben der KI-Komponenten des Systems anhand der inhärenten Merkmale der Komponente oder geeigneter technischer Tests untersucht werden.<br><br>Die ausgewählten Tests sollten mindestens die folgenden Merkmale aufweisen:<br>- Wenn durch die Auswahl begründet, sollten die Metriken und Tests sowohl wichtige Basismethoden als auch fortgeschrittene Methoden (hinsichtlich Komplexität, Informationsgehalt, Implementierungsaufwand, z.B. umfangreiches Prüfwerkzeug) umfassen<br>- ggf. Festlegung von Schwellenwerten (als Mindestanforderungen an die Erklärbarkeit) und Begründung der Schwellenwerte unter Berücksichtigung des Anwendungsbereichs und Verwendungszwecks<br>- falls anwendbar: Abstufung der Metriken und Schwellenwerte nach unterschiedlichen Einsatzszenarien mit Bezug zur Definition des Anwendungsbereichs.",
                        "B": "Tech. Maßnahme - Tests<br>Der Grad, zu dem das KI-System interpretierbar oder erklärbar für die erlaubten Nutzergruppen ist, muss unter Beachtung der Risikoanalyse (TR2.1) und Zweckbestimmung (TR1.1) analysiert werden.<br><br>Hierzu muss der Zusammenhang zwischen Eingaben und Ausgaben der KI-Komponenten des Systems anhand der inhärenten Merkmale der Komponente oder geeigneter technischer Tests untersucht werden.<br><br>Die ausgewählten Tests sollten mindestens die folgenden Merkmale aufweisen:<br>- Wenn durch die Auswahl begründet, sollten die Metriken und Tests sowohl wichtige Basismethoden als auch fortgeschrittene Methoden (hinsichtlich Komplexität, Informationsgehalt, Implementierungsaufwand, z.B. umfangreiches Prüfwerkzeug) umfassen",
                        "C": "Tech. Maßnahme - Tests<br>Der Grad, zu dem das KI-System interpretierbar oder erklärbar für die erlaubten Nutzergruppen ist, muss unter Beachtung der Risikoanalyse (TR2.1) und Zweckbestimmung (TR1.1) analysiert werden.<br><br>Hierzu muss der Zusammenhang zwischen Eingaben und Ausgaben der KI-Komponenten des Systems anhand der inhärenten Merkmale der Komponente oder geeigneter technischer Tests untersucht werden.<br><br>- Es genügen Basismethoden (hinsichtlich Komplexität, Informationsgehalt, Implementierungsaufwand, z.B. eine simple Metrik) ",
                        "D": "Die Interpretierbarkeit und Erklärbarkeit des KI-System wurden nicht analysiert.",
                        "docs_id": "37",
                        "reference": "System/Komponente",
                        "type": "Analyse",
                        "weighting": "Normal",
                        "links": "",
                        "criterion": "TR2",
                        "dimension": "TR"
                    },
                    "TR2.3": {
                        "title": "Es müssen Maßnahmen ergriffen werden, um das KI-System im Hinblick auf seinen Verwendungszweck interpretierbar oder angemessen erklärbar zu machen.",
                        "tooltip": "",
                        "A": "Tech. Maßnahmen - Modell<br>Das KI-System muss im Kontext seines Verwendungszweckes und mit dem Ziel der Risikominimierung angemessen erklärbar gemacht werden. Das kann beinhalten:<br>i) die Wahl von inhärent interpretierbaren Algorithmen oder<br>ii) die Wahl von Algorithmen zu denen entsprechende Ansätze zur Herstellung der (lokalen) Erklärbarkeit einzelner Ausgaben existieren und deren anschließende Implementierung<br><br>Tech. Maßnahmen - Benutzerinstruktionen<br>Das KI-System muss für den nichtfachkundigen Nutzer*innen die notwendigen Informationen zur Nachvollziehung von Modellausgaben liefern. Hierzu ist eine Benutzeroberfläche verfügbar, die folgende Aspekte enthält:<br><br>- Beschreibung der verwendeten Methoden um Systemausgaben verständlich zu machen<br>- Erläuterung der erzeugten Erklärung<br>- Anforderungen an die Nutzer*innen (z.B. informatische Kenntnisse), um diese prinzipiell verstehen zu können. <br><br>Orga. Maßnahmen - Schulungen<br>Zur Qualifikation und Schulung des Personals, welches mit dem Betrieb und der Aufsicht des KI-Systems betraut ist bzw. menschlicher Endnutzer, sind zielgruppenorientierte Schulungen vorbereitet worden. Diese Schulungen legen einen Fokus auf die Interpretation von Ergebnissen des KI-Systems und möglicher Funktionen, die die Erklärbarkeit der Ergebnisse unterstützen.Dabei sind mindestens folgende Aspekte abgedeckt:<br><br>- Relevanz und Nutzen der Erklärbarkeit des KI-Systems im Einsatzkontext<br>- Eingesetzte Methoden und Werkzeuge zur Erklärbarkeit<br>- Übung der Anwendung der Methoden und Werkzeuge zur Erklärung",
                        "B": "Tech. Maßnahmen - Modell<br>Das KI-System muss im Kontext seines Verwendungszweckes und mit dem Ziel der Risikominimierung angemessen erklärbar gemacht werden. Das kann beinhalten:<br>i) die Wahl von inhärent interpretierbaren Algorithmen oder<br>ii) die Wahl von Algorithmen zu denen entsprechende Ansätze zur Herstellung der (lokalen) Erklärbarkeit einzelner Ausgaben existieren und deren anschließende Implementierung<br><br>Orga. Maßnahmen - Benutzerinstruktionen<br>Das KI-System muss für den nichtfachkundigen Nutzer*innen die notwendigen Informationen zur Nachvollziehung von Modellausgaben liefern. Hierzu sind folgende Informationen zu liefern:<br><br>- Beschreibung der verwendeten Methoden um Systemausgaben verständlich zu machen<br>- Erläuterung der erzeugten Erklärung<br>- Anforderungen an die Nutzer (z.B. informatische Kenntnisse), um diese prinzipiell verstehen zu können. <br><br>Benutzerinstruktionen können inhaltlich auch gänzlich über Schulungen abgedeckt werden.",
                        "C": "Tech. Maßnahmen - Modell<br>Das KI-System muss im Kontext seines Verwendungszweckes und mit dem Ziel der Risikominimierung angemessen erklärbar gemacht werden. Das kann beinhalten:<br>i) die Wahl von inhärent interpretierbaren Algorithmen oder<br>ii) die Wahl von Algorithmen zu denen entsprechende Ansätze zur Herstellung der (lokalen) Erklärbarkeit einzelner Ausgaben existieren und deren anschließende Implementierung<br><br>Orga. Maßnahmen - Benutzerinstruktionen<br>Das KI-System muss für den nichtfachkundigen Nutzer*innen die notwendigen Informationen zur Nachvollziehung von Modellausgaben liefern. Hierzu sind folgende Informationen zu liefern:<br><br>- Beschreibung der verwendeten Methoden um Systemausgaben verständlich zu machen<br>- Anforderungen an die Nutzer (z.B. informatische Kenntnisse), um diese prinzipiell verstehen zu können. <br><br>Benutzerinstruktionen können inhaltlich auch gänzlich über Schulungen abgedeckt werden.",
                        "D": "Es wurden keine angemessenen Maßnahmen zum Herstellen von Interpretierbarkeit oder Erklärbarkeit vorgenommen.",
                        "docs_id": "38",
                        "reference": "System/Komponente",
                        "type": "Maßnahme",
                        "weighting": "Normal",
                        "links": "",
                        "criterion": "TR2",
                        "dimension": "TR"
                    },
                    "TR2.4": {
                        "title": "Es muss bewertet werden, ob die ergriffenen Maßnahmen die festgestellten Risiken auf ein annehmbares Maß vermindert haben und die Qualität des KI-Systems den gesetzten Zielvorgaben entspricht.",
                        "tooltip": "",
                        "A": "Bewertung<br>- Zusammenfassende Betrachtung der Effekte der Durchführung der technischen und organisatorischen Maßnahmen<br>- Abwägung von Wechselwirkungen der ergriffenen Maßnahmen, und Abwägung der Mitigation der Risiken im Zusammenspiel mit den Risiken anderer Qualitätsdimensionen<br>- Ermittlung und Beschreibung des Restrisikos nach Durchführung der technischen und organisatorischen Maßnahmen<br>- Einschätzung durch eine qualifizierte und autorisierte Person, ob das Restrisiko tolerierbar ist<br>- Begründung der Tolerierbarkeit des Restrisikos",
                        "B": "Bewertung<br>- Abwägung von Wechselwirkungen der ergriffenen Maßnahmen, und Abwägung der Mitigation der Risiken im Zusammenspiel mit den Risiken anderer Qualitätsdimensionen<br>- Einschätzung durch eine qualifizierte und autorisierte Person, ob das Restrisiko tolerierbar ist<br>- Begründung der Tolerierbarkeit des Restrisikos",
                        "C": "Bewertung<br>- Einschätzung durch eine qualifizierte und autorisierte Person, ob das Restrisiko tolerierbar ist<br>- Begründung der Tolerierbarkeit des Restrisikos",
                        "D": "Eine Bewertung wurde nicht durchgeführt.",
                        "docs_id": "39",
                        "reference": "System",
                        "type": "Bewertung",
                        "weighting": "Maximalwert",
                        "links": "",
                        "criterion": "TR2",
                        "dimension": "TR"
                    }
                },
                "title": "Erklärbarkeit & Interpretierbarkeit"
            }
        ]
    },
    "MA": {
        "title": "Menschliche Aufsicht und Kontrolle",
        "short_title": "Menschliche Aufsicht",
        "quality_dimension_id": 40,
        "icon": "human-oversight",
        "criteria": [
            {
                "index": "MA1",
                "criterion_type_id": 40,
                "indicators": {
                    "MA1.1": {
                        "title": "Der Grad der Autonomie des KI-Systems muss analysiert und dokumentiert werden.",
                        "tooltip": "Autonomiestufen werden in der ISO/IEC 22989 vorgestellt",
                        "A": "Analyse - Definition<br>- Feststellung der Autonomiestufe bzw. des Grads an menschlicher Kontrolle und Einbindung in Entscheidungsprozesse <br>- Begründete Abgrenzung von anderen Autonomiestufen<br>- Ableitung von spezifischen gesetzlichen Anforderungen in Bezug auf menschliche Aufsicht und Kontrolle",
                        "B": "Analyse - Definition<br>- Feststellung der Autonomiestufe bzw. des Grads an menschlicher Kontrolle und Einbindung in Entscheidungsprozesse <br>- Ableitung von spezifischen gesetzlichen Anforderungen in Bezug auf menschliche Aufsicht und Kontrolle",
                        "C": "Analyse - Definition<br>- Feststellung der Autonomiestufe bzw. des Grads an menschlicher Kontrolle und Einbindung in Entscheidungsprozesse <br>- Ableitung von spezifischen gesetzlichen Anforderungen in Bezug auf menschliche Aufsicht und Kontrolle",
                        "D": "Es wurden keine Einordnung der Autonomiestufe vorgenommen",
                        "docs_id": "40",
                        "reference": "System",
                        "type": "Analyse",
                        "weighting": "Maximalwert",
                        "links": "MA2.1",
                        "criterion": "MA1",
                        "dimension": "MA"
                    },
                    "MA1.2": {
                        "title": "Die Risiken im Kontext der Einschränkung der menschlichen Handlungsfähigkeit durch das KI-System müssen analysiert werden.",
                        "tooltip": "",
                        "A": "Analyse-Risiko<br>Detaillierte Risikoanalyse einschließlich Quantifizierung von Eintrittswahrscheinlichkeiten und Risiken:<br>- Identifikation der möglichen Risiken und ihrer Ursachen<br>- Zuweisung der Risikoverantwortung<br>- Schätzung der Eintrittswahrscheinlichkeit<br>- Schätzung der Aufdeckungswahrscheinlichkeit<br>- Schätzung der Auswirkung<br>- Strukturierte Abstufung und Priorisierung der Risiken <br><br>Mindestens die folgenden Risikoquellen sind unter Beachtung des Verwendungszwecks (siehe TR1.1) zu berücksichtigen:<br>- Ethische Dilemmata / Entscheidungsfindung<br>- Unklare Rechenschaft<br>- Automation Bias / übermäßige Abhängigkeit<br>- Vortäuschung menschlicher Züge oder unklare Urheberschaft<br>- Mangelnde Nachvollziehbarkeit von Entscheidungen",
                        "B": "Analyse-Risiko<br>Limitierte Risikoanalyse mit Fokus auf den Schutzbedarf ohne Quantifizierung von Wahrscheinlichkeiten:<br>- Identifikation der möglichen Risiken<br>- Zuweisung der Risikoverantwortung<br>- Schätzung der Auswirkung<br>- Strukturierte Abstufung und Priorisierung der Risiken<br><br>Mindestens die folgenden Risikoquellen sind unter Beachtung des Verwendungszwecks (siehe TR1.1) zu berücksichtigen:<br>- Ethische Dilemmata / Entscheidungsfindung<br>- Unklare Rechenschaft<br>- Automation Bias<br>- Vortäuschung menschlicher Züge oder unklare Urheberschaft<br>- Mangelnde Nachvollziehbarkeit von Entscheidungen",
                        "C": "Analyse-Risiko<br>Hauptsächlich qualitative Abschätzung ohne Wahrscheinlichkeiten:<br>- Identifikation der möglichen Gefährdungen<br>- Zuweisung der  Risikoverantwortung<br>- Qualitative Schätzung der Auswirkung<br>- Qualitative Abstufung und Priorisierung der Risiken<br><br>Mindestens die folgenden Risikoquellen sind unter Beachtung des Verwendungszwecks (siehe TR1.1) zu berücksichtigen:<br>- Ethische Dilemmata / Entscheidungsfindung<br>- Unklare Rechenschaft<br>- Automation Bias<br>- Vortäuschung menschlicher Züge oder unklare Urheberschaft<br>- Mangelnde Nachvollziehbarkeit von Entscheidungen",
                        "D": "Es wurde keine Risikoanalyse durchgeführt",
                        "docs_id": "41",
                        "reference": "System",
                        "type": "Analyse",
                        "weighting": "Maximalwert",
                        "links": "TR1.1",
                        "criterion": "MA1",
                        "dimension": "MA"
                    },
                    "MA1.3": {
                        "title": "möglich sein, ihre mit personenbezogenen Daten einhergehenden Rechte zu Datenverwaltung, -löschung  und -benutzung sowie Informationspflichten auch im Betrieb des KI-Systems wahrzunehmen.",
                        "tooltip": "",
                        "A": "Orga. Maßnahme - Benutzerinstruktion<br>- Bereitstellung einer klaren und verständlichen Erklärung der Datenverarbeitung, der Betroffenenrechte und der Verantwortlichen <br>- Dokumentation und Protokollierung (\"Logging\") aller Datenverarbeitungsaktivitäten sowie der Ausübung der Betroffenenrechte (siehe TR1.7)<br><br>Orga. Maßnahme  - Governance<br>- Gewährleistung, dass Nutzer über Änderungen der Datenverarbeitung oder -nutzung zeitnah informiert werden.<br>- Einrichtung klarer Kanäle, um Betroffenen bei der Ausübung ihrer Rechte zu unterstützen (siehe MA1.4)<br>- Implementierung eines Systems zur Einholung und Verwaltung der expliziten Einwilligung zur Datenverarbeitung.<br><br>Tech. Maßnahme - Betrieb<br>- Bereitstellung leicht zugänglicher Funktionen für Betroffene, um ihre Rechte auf Auskunft, Berichtigung, Löschung und Datenübertragbarkeit auszuüben einschließlich Möglichkeiten der Datenverarbeitung zu widersprechen oder ihre Einwilligung jederzeit zu widerrufen.<br>- Integration von Mechanismen, die eine automatische Löschung personenbezogener Daten nach Ablauf der Speicherfrist oder auf Anfrage ermöglichen.",
                        "B": "Orga. Maßnahme - Benutzerinstruktion<br>- Bereitstellung einer klaren und verständlichen Erklärung der Datenverarbeitung, der Betroffenenrechte und der Verantwortlichen <br>- Dokumentation und Protokollierung (\"Logging\") aller Datenverarbeitungsaktivitäten sowie der Ausübung der Betroffenenrechte (siehe  TR1.7)<br><br>Orga. Maßnahme  - Governance<br>- Einrichtung klarer Kanäle, um Betroffenen bei der Ausübung ihrer Rechte zu unterstützen (siehe MA1.4)<br>- Implementierung eines Systems zur Einholung und Verwaltung der expliziten Einwilligung zur Datenverarbeitung.<br><br>Tech. Maßnahme - Betrieb<br>- Integration von Mechanismen, die eine automatische Löschung personenbezogener Daten nach Ablauf der Speicherfrist oder auf Anfrage ermöglichen.",
                        "C": "Orga. Maßnahme - Benutzerinstruktion<br>- Bereitstellung einer klaren und verständlichen Erklärung der Datenverarbeitung, der Betroffenenrechte und der Verantwortlichen <br><br>Orga. Maßnahme  - Governance<br>- Einrichtung klarer Kanäle, um Betroffenen bei der Ausübung ihrer Rechte zu unterstützen (siehe MA1.4)<br>- Implementierung eines Systems zur Einholung und Verwaltung der expliziten Einwilligung zur Datenverarbeitung.<br><br>Tech. Maßnahme - Betrieb<br>- Integration von Mechanismen, die eine automatische Löschung personenbezogener Daten nach Ablauf der Speicherfrist oder auf Anfrage ermöglichen.",
                        "D": "Möglichkeiten für natürliche Personen ihre Rechte in Bezug auf personenbezogene Daten wahrzunehmen bestehen nicht",
                        "docs_id": "42",
                        "reference": "System",
                        "type": "Maßnahme",
                        "weighting": "Normal",
                        "links": "TR1.7, MA1.4, MA1.6, MA2.3",
                        "criterion": "MA1",
                        "dimension": "MA"
                    },
                    "MA1.4": {
                        "title": "Es muss möglich sein, Feedback zum KI-System zu geben, Rückfragen zu stellen und Probleme zu melden.",
                        "tooltip": ", betroffene Personen oder Betreiber sein.<br><br>Mögliche Feedback-Kanäle sind Umfragen/Fragebögen, Feedback-Formulare, Service-Rufnummern, E-Mail-Adressen, Auftritte in sozialen Medien, Vorschlagsboxen, Chat-Bots oder Kommentarfunktionen. ",
                        "A": "Tech. Maßnahmen - Betrieb<br>- Es gibt mindestens einen Kanal durch den mit dem Anbieter zum Zweck des Feedbacks in Kontakt getreten werden kann<br>- Kanäle sind durch jeden mit begründetem Interesse  klar im Kontext des KI-Systems identifizierbar<br>- Es ist erkennbar, dass die möglichen Kanäle zur Abgabe von Feedback vorgesehen sind<br><br>Orga. Maßnahmen - Systemnahe Prozesse<br>- Sichtung und Überprüfung des Feedbacks und die Vergabe der Verantwortung hierfür erfolgt<br>- Garantierte und individualisierte Beantwortung von Anfragen<br>- Prozess zur Weiterleitung und Einarbeitung des Feedbacks in die Weiterentwicklung des KI-Systems",
                        "B": "Tech. Maßnahmen - Betrieb<br>- Es gibt mindestens einen Kanal durch den mit dem Anbieter zum Zweck des Feedbacks in Kontakt getreten werden kann<br>- Kanäle sind durch jeden mit begründetem Interesse  klar im Kontext des KI-Systems identifizierbar<br><br>Orga. Maßnahmen - Systemnahe Prozesse<br>- Sichtung und Überprüfung des Feedbacks und die Vergabe der Verantwortung hierfür erfolgt",
                        "C": "Tech. Maßnahmen - Betrieb<br>- Die Kontaktinformationen sind dem KI-System beigefügt und können zum Zweck des Feedbacks genutzt werden",
                        "D": "Es sind keine Kanäle vorhanden, um Feedback zum KI-System zu geben",
                        "docs_id": "43",
                        "reference": "System",
                        "type": "Maßnahme",
                        "weighting": "Normal",
                        "links": "DA2.6",
                        "criterion": "MA1",
                        "dimension": "MA"
                    },
                    "MA1.5": {
                        "title": " müssen die Möglichkeit haben, sich über die Anwendung des KI-Systems, die Art und Weise, wie das KI-System eine Entscheidung unterstützt, und die Interpretation seiner Ausgaben zu informieren.",
                        "tooltip": "Die Bereitstellung der Benachrichtigungen und Instruktionen kann über eine grafische Schnittstelle erfolgen.",
                        "A": " (z.B. Schulung) für die Verwendung des KI-Systems<br>- Notwendige Instandhaltungsmaßnahmen (inklusive Softwareupdates)<br><br>Tech. Maßnahmen - Betrieb<br>- Integration von Benachrichtigungen an natürliche Personen, die mit dem KI-System interagieren darüber, dass die Ergebnisse und potenzielle Entscheidungsfindung auf dem KI-System basieren<br>- Bereitstellung von Informationen zu Ausgaben oder getroffenen Entscheidungen des KI-Systems, die eine korrekte Interpretation ermöglichen<br>- Warnung vor sogenanntem \"Automation Bias\" und möglichen Folgen",
                        "B": "Orga. Maßnahmen - Benutzerinstruktion<br>Bereitstellung von adressatengerecht aufbereiteten Instruktionen und Informationen mit mindestens den folgenden Inhalten:<br>- Kontaktinformationen<br> - Zweck des KI-Systems<br>- Vorgesehener Anwendungsbereich des KI-Systems<br>- Erwartbare Leistung und Funktionalität des KI-Systems<br>- Beschreibung über die Interpretation der Ausgaben des KI-Systems<br>- Notwendige Maßnahmen zur menschlichen Aufsicht über das System<br>- Notwendige Instandhaltungsmaßnahmen (inklusive Softwareupdates)<br><br>Tech. Maßnahmen - Betrieb<br>- Integration von Benachrichtigungen an natürliche Personen, die mit dem KI-System interagiert darüber, dass die Ergebnisse und potenzielle Entscheidungsfindung auf dem KI-System basieren<br>- Warnung vor sogenanntem \"Automation Bias\" und möglichen Folgen",
                        "C": "Orga. Maßnahmen - Benutzerinstruktion<br>Bereitstellung von Instruktionen und Informationen mit mindestens den folgenden Inhalten:<br>- Kontaktinformationen<br> - Zweck des KI-Systems<br>- Vorgesehener Anwendungsbereich des KI-Systems<br>- Beschreibung über die Interpretation der Ausgaben des KI-Systems<br>- Notwendige Maßnahmen zur menschlichen Aufsicht über das System<br><br>Tech. Maßnahmen - Betrieb<br>- Integration von Benachrichtigungen an natürliche Personen, die mit dem KI-System interagiert darüber, dass die Ergebnisse und potenzielle Entscheidungsfindung auf dem KI-System basieren<br>- Warnung vor sogenanntem \"Automation Bias\" und möglichen Folgen",
                        "D": " oder betroffene Personen ausgespielt",
                        "docs_id": "44",
                        "reference": "System",
                        "type": "Maßnahme",
                        "weighting": "Normal",
                        "links": "TR2, MA1.6",
                        "criterion": "MA1",
                        "dimension": "MA"
                    },
                    "MA1.6": {
                        "title": " oder betroffenen Personen ermöglichen, die Entscheidungen und Ausgaben des KI-Systems zu verwerfen, anzufechten, zu korrigieren oder zu unterbrechen.",
                        "tooltip": "Sowohl human-in-the-loop (HITL) als auch human-on-the-loop (HOTL) Konstruktionen sind möglich",
                        "A": "Tech. Maßnahmen - Betrieb<br>Die entsprechenden Mechanismen zum Anfechten, Korrigieren oder Unterbrechen des KI-Systems müssen auf die identifizierten Risiken, den Zweck des KI-Systems und die Adressaten der Maßnahme abgestimmt werden.<br><br>Maßnahmen, die in Betracht gezogen werden, umfassen zumindest:<br>- Widerspruchsformular über das Anfechtungen von Entscheidungen eingereicht werden können<br>- Weiterleitung zu einer menschlichen Überprüfung, wo durch eine qualifizierte und autorisierte natürliche Person eine Entscheidung bestätigt oder eine Ausgabe verarbeitet werden muss<br>- Not-Aus-Funktion welche das System durch eine autorisierte natürliche Person in einen sicheren Zustand versetzt<br>- Interaktive grafische Nutzeroberfläche zur Abbildung der Aktionen",
                        "B": "Tech. Maßnahmen - Betrieb<br>Die entsprechenden Mechanismen zum Anfechten, Korrigieren oder Unterbrechen des KI-Systems müssen auf die identifizierten Risiken, den Zweck des KI-Systems und die Adressaten der Maßnahme abgestimmt werden.<br><br>Maßnahmen, die in Betracht gezogen werden, umfassen zumindest:<br>- Widerspruchsformular über das Anfechtungen von Entscheidungen eingereicht werden können<br>- Weiterleitung zu einer menschlichen Überprüfung, wo durch eine qualifizierte und autorisierte natürliche Person eine Entscheidung bestätigt oder eine Ausgabe verarbeitet werden muss<br>- Not-Aus-Funktion welche das System durch eine autorisierte natürliche Person in einen sicheren Zustand versetzt<br>- Interaktive grafische Nutzeroberfläche zur Abbildung der Aktionen",
                        "C": "Tech. Maßnahmen - Betrieb<br>Maßnahmen, die in Betracht gezogen werden, umfassen zumindest:<br>- Widerspruchsformular über das Anfechtungen von Entscheidungen eingereicht werden können<br>- Weiterleitung zu einer menschlichen Überprüfung, wo durch eine qualifizierte und autorisierte Person eine Entscheidung bestätigt oder eine Ausgabe verarbeitet werden muss<br>- Not-Aus-Funktion welche das System durch eine natürliche Person in einen sicheren Zustand versetzt<br>- Interaktive grafische Nutzeroberfläche zur Abbildung der Aktionen",
                        "D": "Es sind keine Mechanismen zum Anfechten, Korrigieren oder Unterbrechen des KI-Systems vorhanden",
                        "docs_id": "45",
                        "reference": "System",
                        "type": "Maßnahme",
                        "weighting": "Maximalwert",
                        "links": "MA1.4,<br>VE2.2",
                        "criterion": "MA1",
                        "dimension": "MA"
                    },
                    "MA1.7": {
                        "title": "Es muss bewertet werden, ob die ergriffenen Maßnahmen die festgestellten Risiken auf ein annehmbares Maß vermindert haben und die Qualität des KI-Systems den gesetzten Zielvorgaben entspricht",
                        "tooltip": "",
                        "A": "Bewertung<br>- Zusammenfassende Betrachtung der Effekte der Durchführung der technischen und organisatorischen Maßnahmen<br>- Abwägung von Wechselwirkungen der ergriffenen Maßnahmen, und Abwägung der Mitigation der Risiken im Zusammenspiel mit den Risiken anderer Qualitätsdimensionen<br>- Ermittlung und Beschreibung des Restrisikos nach Durchführung der technischen und organisatorischen Maßnahmen<br>- Einschätzung durch eine qualifizierte und autorisierte Person, ob das Restrisiko tolerierbar ist<br>- Begründung der Tolerierbarkeit des Restrisikos",
                        "B": "Bewertung<br>- Abwägung von Wechselwirkungen der ergriffenen Maßnahmen, und Abwägung der Mitigation der Risiken im Zusammenspiel mit den Risiken anderer Qualitätsdimensionen<br>- Einschätzung durch eine qualifizierte und autorisierte Person, ob das Restrisiko tolerierbar ist<br>- Begründung der Tolerierbarkeit des Restrisikos",
                        "C": "Bewertung<br>- Einschätzung durch eine qualifizierte und autorisierte Person, ob das Restrisiko tolerierbar ist<br>- Begründung der Tolerierbarkeit des Restrisikos",
                        "D": "Eine Bewertung wurde nicht durchgeführt",
                        "docs_id": "46",
                        "reference": "System",
                        "type": "Bewertung",
                        "weighting": "Maximalwert",
                        "links": "",
                        "criterion": "MA1",
                        "dimension": "MA"
                    }
                },
                "title": "Menschliche Handlungsfähigkeit"
            },
            {
                "index": "MA2",
                "criterion_type_id": 41,
                "indicators": {
                    "MA2.1": {
                        "title": "Der Grad der Autonomie des KI-Systems muss analysiert und dokumentiert werden",
                        "tooltip": "",
                        "A": "Analyse - Definition<br>- Feststellung der Autonomiestufe bzw. des Grads an menschlicher Kontrolle und Einbindung in Entscheidungsprozesse <br>- Begründete Abgrenzung von anderen Autonomiestufen<br>- Ableitung von spezifischen gesetzlichen Anforderungen in Bezug auf menschliche Aufsicht und Kontrolle",
                        "B": "Analyse - Definition<br>- Feststellung der Autonomiestufe bzw. des Grads an menschlicher Kontrolle und Einbindung in Entscheidungsprozesse <br>- Ableitung von spezifischen gesetzlichen Anforderungen in Bezug auf menschliche Aufsicht und Kontrolle",
                        "C": "Analyse - Definition<br>- Feststellung der Autonomiestufe bzw. des Grads an menschlicher Kontrolle und Einbindung in Entscheidungsprozesse <br>- Ableitung von spezifischen gesetzlichen Anforderungen in Bezug auf menschliche Aufsicht und Kontrolle",
                        "D": "Es wurden keine Einordnung der Autonomiestufe vorgenommen",
                        "docs_id": "47",
                        "reference": "System",
                        "type": "Analyse",
                        "weighting": "Maximalwert",
                        "links": "MA1.1",
                        "criterion": "MA2",
                        "dimension": "MA"
                    },
                    "MA2.2": {
                        "title": "Die Risiken, dass das KI-System ohne menschliche Aufsicht (und Kontrolle) zu Schäden führt, müssen analysiert werden",
                        "tooltip": "",
                        "A": "Analyse-Risiko<br>Detaillierte Risikoanalyse einschließlich Quantifizierung von Eintrittswahrscheinlichkeiten und Risiken:<br>- Identifikation der möglichen Risiken und ihrer Ursachen<br>- Zuweisung der Risikoverantwortung<br>- Schätzung der Eintrittswahrscheinlichkeit<br>- Schätzung der Aufdeckungswahrscheinlichkeit<br>- Schätzung der Auswirkung<br>- Strukturierte Abstufung und Priorisierung der Risiken <br><br>Mindestens die folgenden Risikoquellen sind unter Beachtung des Verwendungszwecks (siehe TR1.1) zu berücksichtigen:<br>- Implikationen (Teil-)autonomer Entscheidungen des Systems ohne Kontrolle, Eingriff oder Korrektur durch natürliche Personen <br>- Ethische Dilemmata / Entscheidungsfindung<br>- Mangelnde Nachvollziehbarkeit von Entscheidungen<br>- Haftung für Entscheidungen des KI-Systems<br>- Urheberschaft für Ausgaben des KI-Systems<br>- Fehleranfälligkeit des KI-Systems ohne das dies durch Menschen erkannt wird<br>- Fehlerhafte/unsachgemäße Nutzung (z.B. durch mangelnde Qualifikation)",
                        "B": "Analyse-Risiko<br>Limitierte Risikoanalyse mit Fokus auf den Schutzbedarf ohne Quantifizierung von Wahrscheinlichkeiten:<br>- Identifikation der möglichen Risiken<br>- Zuweisung der Risikoverantwortung<br>- Schätzung der Auswirkung<br>- Strukturierte Abstufung und Priorisierung der Risiken<br><br>Mindestens die folgenden Risikoquellen sind unter Beachtung des Verwendungszwecks (siehe TR1.1) zu berücksichtigen:<br>- Implikationen (Teil-)autonomer Entscheidungen des Systems ohne Kontrolle, Eingriff oder Korrektur durch natürliche Personen <br>- Ethische Dilemmata / Entscheidungsfindung<br>- Mangelnde Nachvollziehbarkeit von Entscheidungen<br>- Haftung für Entscheidungen des KI-Systems<br>- Urheberschaft für Ausgaben des KI-Systems<br>- Fehleranfälligkeit des KI-Systems ohne das dies durch Menschen erkannt wird<br>- Fehlerhafte/unsachgemäße Nutzung (z.B. durch mangelnde Qualifikation)",
                        "C": "Analyse-Risiko<br>Hauptsächlich qualitative Abschätzung ohne Wahrscheinlichkeiten:<br>- Identifikation der möglichen Gefährdungen<br>- Zuweisung der  Risikoverantwortung<br>- Qualitative Schätzung der Auswirkung<br>- Qualitative Abstufung und Priorisierung der Risiken<br><br>Mindestens die folgenden Risikoquellen sind unter Beachtung des Verwendungszwecks (siehe TR1.1) zu berücksichtigen:<br>- Implikationen (Teil-)autonomer Entscheidungen des Systems ohne Kontrolle, Eingriff oder Korrektur durch natürliche Personen <br>- Ethische Dilemmata / Entscheidungsfindung<br>- Mangelnde Nachvollziehbarkeit von Entscheidungen<br>- Haftung für Entscheidungen des KI-Systems<br>- Urheberschaft für Ausgaben des KI-Systems<br>- Fehleranfälligkeit des KI-Systems ohne das dies durch Menschen erkannt wird<br>- Fehlerhafte/unsachgemäße Nutzung (z.B. durch mangelnde Qualifikation)",
                        "D": "Es wurde keine Risikoanalyse durchgeführt",
                        "docs_id": "48",
                        "reference": "System",
                        "type": "Analyse",
                        "weighting": "Maximalwert",
                        "links": "TR1.1",
                        "criterion": "MA2",
                        "dimension": "MA"
                    },
                    "MA2.3": {
                        "title": "Das KI-System muss in Entwicklung und Betrieb überwacht werden (können)",
                        "tooltip": "",
                        "A": "Tech. Maßnahme - Betrieb<br>Eine kontinuierliche Überwachung muss für die Implementierung des  KI-Systems vorgesehen sein und auf Basis entsprechender Protokollierung (siehe TR1.7) umgesetzt werden können. Dies beinhaltet die Erprobung folgenden Möglichkeiten:<br><br>- Monitoring der Leistung inklusive einer Überwachung der Modelle und Daten (d.h. einkommende Produktionsdaten und ggf. sich erweiternde Trainingsdatenbasis)<br>- Monitoring von Verzerrungen inklusive einer Überwachung der Daten (d.h. einkommende Produktionsdaten und ggf. sich erweiternde Trainingsdatenbasis) im Kontext der Vermeidung von ungerechtfertigter Diskriminierung und Verzerrungen<br>- Durchführung von Tests (z.B. Sanity Checks), die im Rahmen des Monitorings eingesetzt werden, um etwa Model und Concept Drift  oder auch schädliche Eingabedaten zu erkennen<br>- Falls anwendbar, Durchführung von Tests zur Erkennung von Missbrauch und schädlichen Eingabedaten<br>- Ggf. Qualitätsüberprüfung der sich erweiternden Trainingsdatenbasis  <br><br>Organisatorische Maßnahme - Systemnahe Prozesse<br>Zusätzlich zur technischen Ermöglichung des Monitorings sollten die folgenden Aspekte vorbereitet werden:<br>- Konzept zur (automatischen) Überwachung und -prüfung größerer Veränderungen am KI-System, inklusive bei Soft- und Hardware-Komponenten, aber insbesondere im Fall von Online Learning<br>- Empfohlene Tests müssen als Teil eines kontinuierlichen Testplans dokumentiert sein, insbesondere im Fall von Online Learning<br>- Falls möglich, Mechanismen in Form sinnvoller Definition von Schwellwerten bzw. Szenarien, bei denen (menschliche) Überprüfung und Mitigationsmaßnahmen eintreten sollten<br>- Mechanismen zum Teilen von neuen Informationen über mögliche sicherheitsrelevante Vorfälle und ihrer Vermeidung ",
                        "B": "Tech. Maßnahme - Betrieb<br>Eine kontinuierliche Überwachung muss für die Implementierung des  KI-Systems vorgesehen sein und auf Basis entsprechender Protokollierung (siehe TR1.7) umgesetzt werden können. Dies beinhaltet die folgenden Möglichkeiten:<br><br>- Monitoring der Leistung inklusive einer Überwachung der Modelle und Daten (d.h. einkommende Produktionsdaten und ggf. sich erweiternde Trainingsdatenbasis)<br>- Monitoring von Verzerrungen inklusive einer Überwachung der Daten (d.h. einkommende Produktionsdaten und ggf. sich erweiternde Trainingsdatenbasis) im Kontext der Vermeidung von ungerechtfertigter Diskriminierung und Verzerrungen<br>- Durchführung von Tests (z.B. Sanity Checks), die im Rahmen des Monitorings eingesetzt werden, um etwa Model und Concept Drift, oder auch schädliche Eingabedaten zu erkennen<br><br>Organisatorische Maßnahme - Systemnahe Prozesse<br>Zusätzlich zur technischen Ermöglichung des Monitorings sollten die folgenden Aspekte vorbereitet werden:<br>- Konzept zur (automatischen) Überwachung und -prüfung größerer Veränderungen am KI-System, inklusive bei Soft- und Hardware-Komponenten, aber insbesondere im Fall von Online Learning<br>- Empfohlene Tests müssen als Teil eines kontinuierlichen Testplans dokumentiert sein, insbesondere im Fall von Online Learning",
                        "C": "Tech. Maßnahme - Betrieb<br>Eine kontinuierliche Überwachung muss für die Implementierung des  KI-Systems vorgesehen sein und auf Basis entsprechender Protokollierung (siehe TR1.7) umgesetzt werden können. Dies beinhaltet die folgenden Möglichkeiten:<br><br>- Monitoring der Leistung inklusive einer Überwachung der Modelle und Daten (d.h. einkommende Produktionsdaten und ggf. sich erweiternde Trainingsdatenbasis)<br>- Monitoring von Verzerrungen inklusive einer Überwachung der Daten (d.h. einkommende Produktionsdaten und ggf. sich erweiternde Trainingsdatenbasis) im Kontext der Vermeidung von ungerechtfertigter Diskriminierung und Verzerrungen<br>- Durchführung von Tests (z.B. Sanity Checks), die im Rahmen des Monitorings eingesetzt werden, um etwa Model und Concept Drift, oder auch schädliche Eingabedaten zu erkennen",
                        "D": "",
                        "docs_id": "49",
                        "reference": "System",
                        "type": "Maßnahme",
                        "weighting": "Maximalwert",
                        "links": "VE1.7, CY1.5 (Angriffe während der Betriebsphase), DA1.4",
                        "criterion": "MA2",
                        "dimension": "MA"
                    },
                    "MA2.4": {
                        "title": "Die mit dem Betrieb und der Aufsicht betrauten Personen müssen Zugang zu einer verständlichen Beschreibung des KI-Systems haben und angemessen auf die Ausübung ihrer Aufgaben vorbereitet werden",
                        "tooltip": "",
                        "A": "Orga. Maßnahmen - Benutzerinstruktion<br>Bereitstellung von Adressatengerecht aufbereiteten Instruktionen und Informationen mit mindestens den folgenden Inhalten:<br>- Kontaktinformationen<br>- Zweck des KI-Systems<br>- Vorgesehener Anwendungsbereich des KI-Systems<br>- Erwartbare Leistung und Funktionalität des KI-Systems<br>- Bekannte Risiken und Implikationen für die Nutzung (der Ergebnisse) des KI-Systems <br>- Zusammenfassung der erwarteten Eingabedaten<br>- Beschreibung über die Interpretation der Ausgaben des KI-Systems<br>- Beschreibung des Grads der Autonomie und der Entscheidungsprozesse des KI-Systems<br>- Notwendige/mögliche Maßnahmen zur menschlichen Aufsicht und Kontrolle über das System, wann diese angewendet werden sollen/können, und wie erkennbar wird, dass ein menschlicher Eingriff gefordert ist<br>- Anforderungen an die Nutzer (z.B. Schulung) für die Verwendung des KI-Systems<br>- Notwendige Instandhaltungsmaßnahmen (inklusive Softwareupdates)<br><br>Orga. Maßnahmen - Schulungen<br>Zur Qualifikation und Schulung des Personals, welches mit dem Betrieb und der Aufsicht des KI-Systems betraut ist, sind zielgruppenorientierte Schulungsmaterialien erstellt worden, die ein Fokus auf den Sachgemäßen Einsatz und ein erhöhtes Sicherheitsbewusstsein legen. Das Material umfasst mindestens folgende Aspekte:<br>- Ordnungsgemäßer Umgang mit Systemkomponenten in der Produktionsumgebung<br>   - Ordnungsgemäßer Umgang mit relevanten Datentypen (z.B. Trainings- und Validierungsdaten, Betriebsdaten, Kundendaten) auch gemäß den geltenden Richtlinien sowie gesetzlichen und regulatorischen Anforderungen<br>   - Angemessene Durchführung von Training, Validierung und Testen im Betrieb des KI-Systems und seiner Komponenten <br>   - Überwachung der Leistung des KI-Systems und seiner Komponenten<br>   - Informationen über potenzielle Bedrohungsszenarien und dazugehöriger Mitigationsmaßnahmen (z.B. Interventionen)<br>   - Verhalten im Falle von Sicherheitsvorfällen",
                        "B": "Orga. Maßnahmen - Benutzerinstruktion<br>Bereitstellung von Adressatengerecht aufbereiteten Instruktionen und Informationen mit mindestens den folgenden Inhalten:<br>- Kontaktinformationen<br>- Zweck des KI-Systems<br>- Vorgesehener Anwendungsbereich des KI-Systems<br>- Beschreibung über die Interpretation der Ausgaben des KI-Systems<br>- Notwendige(mögliche Maßnahmen zur menschlichen Aufsicht und Kontrolle über das System, wann diese angewendet werden sollen/können, und wie erkennbar wird, dass ein menschlicher Eingriff gefordert ist<br>- Notwendige Instandhaltungsmaßnahmen (inklusive Softwareupdates)<br><br>Orga. Maßnahmen - Schulungen<br>Zur Qualifikation und Schulung des Personals, welches mit dem Betrieb und der Aufsicht des KI-Systems betraut ist, sind zielgruppenorientierte Schulungsmaterialien erstellt worden, die ein Fokus auf den Sachgemäßen Einsatz und ein erhöhtes Sicherheitsbewusstsein legen. Das Material umfasst mindestens folgende Aspekte:<br>- Ordnungsgemäßer Umgang mit Systemkomponenten in der Produktionsumgebung<br>   - Überwachung der Leistung des KI-Systems und seiner Komponenten<br>   - Informationen über potenzielle Bedrohungsszenarien und dazugehöriger Mitigationsmaßnahmen (z.B. Interventionen)<br>   - Verhalten im Falle von Sicherheitsvorfällen",
                        "C": "Orga. Maßnahmen - Benutzerinstruktion<br>Bereitstellung von Instruktionen und Informationen mit mindestens den folgenden Inhalten:<br>- Kontaktinformationen<br>- Zweck des KI-Systems<br>- Vorgesehener Anwendungsbereich des KI-Systems<br>- Beschreibung über die Interpretation der Ausgaben des KI-Systems<br>- Notwendige(mögliche Maßnahmen zur menschlichen Aufsicht und Kontrolle über das System, wann diese angewendet werden sollen/können, und wie erkennbar wird, dass ein menschlicher Eingriff gefordert ist<br>- Notwendige Instandhaltungsmaßnahmen (inklusive Softwareupdates)",
                        "D": "Es sind keine Materialien vorhanden, die die mit dem Betrieb und der Aufsicht betrauten Personen auf einen Umgang mit dem KI-System vorbereiten ",
                        "docs_id": "50",
                        "reference": "System",
                        "type": "Maßnahme",
                        "weighting": "Normal",
                        "links": "MA1.5",
                        "criterion": "MA2",
                        "dimension": "MA"
                    },
                    "MA2.5": {
                        "title": "Es muss bewertet werden, ob die ergriffenen Maßnahmen die festgestellten Risiken auf ein annehmbares Maß vermindert haben und die Qualität des KI-Systems den gesetzten Zielvorgaben entspricht",
                        "tooltip": "",
                        "A": "Bewertung<br>- Zusammenfassende Betrachtung der Effekte der Durchführung der technischen und organisatorischen Maßnahmen<br>- Abwägung von Wechselwirkungen der ergriffenen Maßnahmen, und Abwägung der Mitigation der Risiken im Zusammenspiel mit den Risiken anderer Qualitätsdimensionen<br>- Ermittlung und Beschreibung des Restrisikos nach Durchführung der technischen und organisatorischen Maßnahmen<br>- Einschätzung durch eine qualifizierte und autorisierte Person, ob das Restrisiko tolerierbar ist<br>- Begründung der Tolerierbarkeit des Restrisikos",
                        "B": "Bewertung<br>- Abwägung von Wechselwirkungen der ergriffenen Maßnahmen, und Abwägung der Mitigation der Risiken im Zusammenspiel mit den Risiken anderer Qualitätsdimensionen<br>- Einschätzung durch eine qualifizierte und autorisierte Person, ob das Restrisiko tolerierbar ist<br>- Begründung der Tolerierbarkeit des Restrisikos",
                        "C": "Bewertung<br>- Einschätzung durch eine qualifizierte und autorisierte Person, ob das Restrisiko tolerierbar ist<br>- Begründung der Tolerierbarkeit des Restrisikos",
                        "D": "Eine Bewertung wurde nicht durchgeführt",
                        "docs_id": "51",
                        "reference": "System",
                        "type": "Bewertung",
                        "weighting": "Maximalwert",
                        "links": "",
                        "criterion": "MA2",
                        "dimension": "MA"
                    }
                },
                "title": "Menschliche Aufsicht"
            }
        ]
    },
    "CY": {
        "title": "KI-spezifische Cybersicherheit",
        "short_title": "Cybersicherheit",
        "quality_dimension_id": 50,
        "icon": "ai-security",
        "criteria": [
            {
                "index": "CY1",
                "criterion_type_id": 60,
                "indicators": {
                    "CY1.1": {
                        "title": "Risiken für die Cybersicherheit des KI-Systems müssen unter Beachtung des Verwendungszwecks analysiert werden. ",
                        "tooltip": "Wichtige Standards sind zum Beispiel  BSI Grundschutz, ISO 27k series, IEC 62443, ISO/SAE 21434, ETSI EN 303 645, NIST AI RMF, ... ",
                        "A": "Analyse - Risiko<br>Detaillierte Risikoanalyse zur Cybersicherheit einschließlich Quantifizierung von Eintrittswahrscheinlichkeiten und Risiken:<br>- Identifikation der möglichen Risiken und ihrer Ursachen<br>- Zuweisung der Risikoverantwortung<br>- Schätzung der Eintrittswahrscheinlichkeit<br>- Schätzung der Aufdeckungswahrscheinlichkeit<br>- Schätzung der Auswirkung<br>- Strukturierte Abstufung und Priorisierung der Risiken <br> <br>Die Risikobewertung sollte unter Beachtung des Verwendungszwecks und Anwendungsbereichs (siehe TR1.1) mindestens berücksichtigen:<br>- Alle klassischen Schutzziele der Cybersicherheit, also Vertraulichkeit (z.B. Schutz von Trainingsdaten vor böswilliger Offenlegung oder Missbrauch), Integrität (z.B. Schutz des KI-Systems vor einer böswilligen Einflussnahme auf den Output zum Vorteil des Angreifers) und Verfügbarkeit (z.B. Schutz des KI-Systems vor einer böswillig ausgelösten Überlastung)<br>- Bedrohungsbewertung (Threat Modelling) zur Bestimmung von  Eintrittswahrscheinlichkeiten<br>- Schwachstellenanalyse zur Bestimmung von  Eintrittswahrscheinlichkeiten<br>- Analyse der zu schützenden System-Assets zur Bestimmung der Auswirkungen <br><br>Das Risikobewertungsframework sollte möglichst in ein Cybersicherheitsmanagementsystem eingebettet werden können und dabei idealerweise bekannten Standards folgen.",
                        "B": "Analyse - Risiko<br>Limitierte Risikoanalyse mit Fokus auf den Schutzbedarf ohne Quantifizierung von Wahrscheinlichkeiten<br>- Identifikation der möglichen Risiken<br>- Zuweisung der Risikoverantwortung<br>- Schätzung der Auswirkung<br>- Strukturierte Abstufung und Priorisierung der Risiken<br><br>Die Risikobewertung sollte unter Beachtung des Verwendungszwecks und Anwendungsbereichs (siehe TR1.1) mindestens berücksichtigen:<br>- Alle klassischen Schutzziele der Cybersicherheit, also Vertraulichkeit (z.B. Schutz personenbezogener Trainingsdaten vor böswilliger Offenlegung oder Missbrauch), Integrität (z.B. Schutz des KI-Systems vor einer böswilligen Einflussnahme auf den Output zum Vorteil des Angreifers) und Verfügbarkeit (z.B. Schutz des KI-Systems vor einer böswillig ausgelösten Überlastung)<br>- Bedrohungsbewertung (Threat Modelling) zur Bestimmung von  Eintrittswahrscheinlichkeiten<br>- Schwachstellenanalyse zur Bestimmung von  Eintrittswahrscheinlichkeiten<br>- Analyse der zu schützenden System-Assets zur Bestimmung der Auswirkungen<br><br>Das Risikobewertungsframework sollte möglichst in ein Cybersicherheitsmanagementsystem eingebettet werden können und dabei idealerweise bekannten Standards folgen.",
                        "C": "Analyse - Risiko<br>Hauptsächlich qualitative Abschätzung ohne Wahrscheinlichkeiten<br>- Identifikation der möglichen Risiken<br>- Zuweisung der Risikoverantwortung<br>- Qualitative Schätzung der Auswirkung<br>- Qualitative Abstufung und Priorisierung der Risiken<br><br>Die Risikobewertung sollte unter Beachtung des Verwendungszwecks und Anwendungsbereichs (siehe TR1.1) mindestens berücksichtigen:<br>- Alle klassischen Schutzziele der Cybersicherheit, also Vertraulichkeit (z.B. Schutz personenbezogener Trainingsdaten vor böswilliger Offenlegung oder Missbrauch), Integrität (z.B. Schutz des KI-Systems vor einer böswilligen Einflussnahme auf den Output zum Vorteil des Angreifers) und Verfügbarkeit (z.B. Schutz des KI-Systems vor einer böswillig ausgelösten Überlastung)<br>- Bedrohungsbewertung (Threat Modelling) zur Bestimmung von Eintrittswahrscheinlichkeiten<br>- Schwachstellenanalyse zur Bestimmung von  Eintrittswahrscheinlichkeiten<br>- Analyse der zu schützenden System-Assets zur Bestimmung der Auswirkungen<br><br>Das Risikobewertungsframework sollte möglichst in ein Cybersicherheitsmanagementsystem eingebettet werden können und dabei idealerweise bekannten Standards folgen.",
                        "D": "Es wurde keine Risikoanalyse durchgeführt",
                        "docs_id": "52",
                        "reference": "System",
                        "type": "Analyse",
                        "weighting": "Maximalwert",
                        "links": "TR1.1 (Verwendungszweck)",
                        "criterion": "CY1",
                        "dimension": "CY"
                    },
                    "CY1.2": {
                        "title": "Für das KI-System, einschließlich aller KI-Komponenten und des eingebetteten IKT-Systems, muss ein Cybersicherheitsmanagementsystem (CSMS) vorgesehen sein",
                        "tooltip": "Wichtige Standards sind zum Beispiel  BSI Grundschutz, ISO 27k series, IEC 62443, ISO/SAE 21434, ETSI EN 303 645, NIST AI RMF, ... ",
                        "A": "Orga. Maßnahmen - Governance & Tech. Maßnahmen - Betrieb<br>(Anbindung Cybersicherheitsmanagementsystem)<br><br>Es muss vorgesehen sein, dass  das KI-System in einer Cybersicherheitsmanagementsystem (CSMS) eingebettet werden kann, insbesondere:<br>- Monitoring und Logging müssen implementiert oder vorgesehen sein und Schnittstellen für ein CSMS bereit stellen<br>- die Dokumentation von Schwachstellen, Assets, Risikoanalyse und den Ergebnissen aus allen Mitigationsmaßnahmen sollte vollständig bereit gehalten sein<br>- eine Strategie für Software -und Sicherheitsupdates sollte vorhanden sein<br><br>Das KI-System sollte Schnittstellen bereithalten um mindestens die folgenden Aspekte eines CSM abdecken zu können:  <br>  - Ein Systemlebenszyklus basiertes System zur regelmäßigen Cybersicherheitsqualitätskontrolle einschließlich vorgesehener Reviews der Sicherheitsmaßnamen und Protokolle.<br>  - Grundlegendes Cybersecurity Asset Management, einschließlich für Sicherheitskontrollen und <br>Überwachungssysteme selber<br> - Management von Schwachstellen (Identifizierung während des gesamten Lebenszyklus, insbesondere Training/Evaluation und Deployment-Phasen; wo nötig, sollten Penetrationstests vorgeschrieben sein)<br> - Ein Cybersicherheits-Monitoringsystem<br>- Zugangsmanagement zu den verschiedenen Assets und Komponenten des Systems <br> - Aspekte des Personalmanagement, wie Schulung, Ausbildung und Rollenzuweisung in der Entwicklung und Begleitung des KI-Produkts<br>- eine Analyse des erwarteten und tatsächlichen Zeitrahmens innerhalb dessen Sicherheitsaktualisierungen für das KI-System zur Verfügung gestellt werden<br>- Strategien für regelmäßigen Review von Sicherheitsmaßnahmen - und Protokollen<br>- Dokumentation des CSMS. Die Informationen müssen direkt mit der KI-Anwendung einsehbar sein.<br>- Das CSMS kann durch Compliance mit entsprechenden Cybersicherheitsstandards nachgewiesen sein, ein entsprechender Nachweis für das entwickelte KI-System sollte automatisch als A gewertet sein (z.B.. BSI Grundschutz, ISO 27k series, IEC 62443, ISO/SAE 21434, ETSI EN 303 645, NIST AI RMF, ... ) ",
                        "B": "Orga. Maßnahmen - Governance & Tech. Maßnahmen - Betrieb<br>(Anbindung Cybersicherheitsmanagementsystem)<br><br>Es sollte so viele Information, wie möglich bereit gestellt werden, so dass das KI-System in einer Cybersicherheitsmanagementsystem (CSMS) eingebettet werden kann, insbesondere:<br>- Monitoring und Logging müssen mindestens vorgesehen sein und Schnittstellen für ein CSMS bereit stellen<br>- die Dokumentation von Schwachstellen, Assets, Risikoanalyse und den Ergebnissen aus allen Mitigationsmaßnahmen sollte vollständig bereit gehalten sein<br><br>Das KI-System sollte Schnittstellen bereithalten um mindestens die folgenden Aspekte eines CSMS abdecken zu können:  <br>  - Ein Systemlebenszyklus basiertes System zur regelmäßigen Cybersicherheitsqualitätskontrolle einschließlich vorgesehener Reviews der Sicherheitsmaßnamen und Protokolle.<br>  - Grundlegendes Cybersecurity Asset Management, einschließlich für Sicherheitskontrollen und <br>Überwachungssysteme selber<br> - Management von Schwachstellen (Identifizierung während des gesamten Lebenszyklus, insbesondere Training/Evaluation und Deployment-Phasen; wo nötig, sollten Penetrationstests vorgeschrieben sein)<br>- Zugangsmanagement zu den verschiedenen Assets und Komponenten des Systems <br>- eine Analyse des erwarteten und tatsächlichen Zeitrahmens innerhalb dessen Sicherheitsaktualisierungen für das KI System/Anwendung zur Verfügung gestellt werden<br>- Strategien für regelmäßigen Review von Sicherheitsmaßnahmen - und Protokollen<br>- Dokumentation des CSMS. Die Informationen müssen direkt mit der KI-Anwendung einsehbar sein.<br>- Das CSMS kann durch Compliance mit entsprechenden Cybersicherheitsstandards nachgewiesen sein, ein entsprechender Nachweis für das entwickelte KI-System sollte automatisch als A gewertet sein (z.B.. BSI Grundschutz, ISO 27k series, IEC 62443, ISO/SAE 21434, ETSI EN 303 645, NIST AI RMF, ... ) ",
                        "C": "Orga. Maßnahmen - Governance & Tech. Maßnahmen - Betrieb<br>(Anbindung Cybersicherheitsmanagementsystem)<br><br>- Es sollte so viele Information zur KI-spezifischen Cybersicherheit, wie möglich bereit gestellt werden um das KI-System in größere Systemkontexte einbetten zu können insbesondere die Dokumentation von Schwachstellen, Assets, Risikoanalyse und den Ergebnissen aus allen Mitigationsmaßnahmen",
                        "D": "Die Einbettung in ein CSMS wurde in keiner Weise vorgesehen oder erleichtert.",
                        "docs_id": "53",
                        "reference": "System/Komponente",
                        "type": "Maßnahme",
                        "weighting": "Normal",
                        "links": "CY1.5 (Datenzugang), CY2.3, CY2.2 (KI-spezifische Mitigationsmaßnahmen)",
                        "criterion": "CY1",
                        "dimension": "CY"
                    },
                    "CY1.3": {
                        "title": "Es müssen Maßnahmen zur Kontrolle der Cybersicherheitsaspekte des KI-Lieferkettenmanagements vorhanden sein, insbesondere im Hinblick auf Schwachstellen oder schädliche Praktiken bei der Verwendung von vortrainierten Modellen, Open-Source-Bibliotheken für maschinelles Lernen und Trainingsdaten von Dritten.",
                        "tooltip": "",
                        "A": "Orga. Maßnahmen - Systemnahe Prozesse<br>- Es sollte ein Prozess vorhanden sein zur Analyse der Cybersicherheit der Software- und Hardwarelieferketten hinsichtlich der Entwicklungs- und Produktumgebung des KI-Systems<br>-  Die Analyse der Lieferkette umfasst vortrainierte Modelle, Datensätze, und genutzte Softwarebibliotheken und die genutzte Hardware für Training- und ggf.. Produktionsphase des KI-Systems.<br>- Es sollte ein Prozess vorgesehen sein zur stetigen weiteren Überwachung der Lieferkette einschließlich eines Plans für Updates und Review nach Auftauchen bisher unentdeckter Schwachstellen in der Lieferkette. <br><br>Tech. Maßnahmen - Modelle, Daten<br>- Es muss eine Sicherheitsüberprüfung aller identifizierten genutzten vortrainierten Modelle, Datensätze und Softwarebibliotheken aus der Lieferkette nachgewiesen sein<br><br>Tech. Maßnahmen - Betrieb<br>- Es sollten Schnittstellen vorhanden sein, welche die technische Überwachung der benutzen Soft- und Hardware des KI-Systems auch bzgl. Schwachstellen durch ein Cybersicherheitsmonitoring erlauben",
                        "B": "Orga. Maßnahmen - Systemnahe Prozesse<br>- Es sollte ein Prozess vorhanden sein zur Analyse der Cybersicherheit der Software- und Hardwarelieferketten hinsichtlich der Entwicklungs- und Produktumgebung des KI-Systems<br>-  Die Analyse der Lieferkette umfasst vortrainierte Modelle, Datensätze, und genutzte Softwarebibliotheken und die genutzte Hardware für Training- und ggf.. Produktionsphase des KI-Systems.<br>- Es sollte ein Prozess vorgesehen sein zur stetigen weiteren Überwachung der Lieferkette einschließlich eines Plans für Updates und Review nach Auftauchen bisher unentdeckter Schwachstellen in der Lieferkette. ",
                        "C": "Orga. Maßnahmen - Systemnahe Prozesse<br>- Es sollte ein Prozess vorhanden sein zur Analyse der Cybersicherheit der Software- und Hardwarelieferketten hinsichtlich der Entwicklungs- und Produktumgebung des KI-Systems<br>-  Die Analyse der Lieferkette umfasst vortrainierte Modelle, Datensätze, und genutzte Softwarebibliotheken",
                        "D": "Es wurden keine Maßnahmen ergriffen zur Kontrolle der Cybersicherheitsaspekte des KI-Lieferkettenmanagements",
                        "docs_id": "54",
                        "reference": "System/Komponente",
                        "type": "Maßnahme",
                        "weighting": "Normal",
                        "links": "",
                        "criterion": "CY1",
                        "dimension": "CY"
                    },
                    "CY1.4": {
                        "title": "Es müssen Maßnahmen und Sicherheitskontrollen vorhanden sein, um fehlerhafte Nutzung und Missbrauch des KI-Systems zu verhindern.",
                        "tooltip": "",
                        "A": "Org. Maßnahmen - Systemnahe Prozesse<br>- Prozesse müssen eingeführt sein um den möglichen beabsichtigten Missbrauchs des KI-Systems im Betrieb adressieren zu können, einschließlich der Einbindung möglicher Abschaltungsmechanismen im Risikomanagement. <br>- Prozesse sollten eingeführt sein, um eine durch Monitoringsysteme und Logging festgestellte fehlerhafte Nutzung im Betrieb adressieren zu können<br>- Prozesse sollten insbesondere darauf achten, dass neben der Funktionalität, Integrität und Verfügbarkeit des KI-Systems auch die unter den unterschiedlichen Qualitätsdimensionen definierten Ziele geschützt sind bei fehlerhafter Nutzung oder Missbrauch, also Wahrung des Schutzes personenbezogener oder proprietärer Daten, des Schutzes vor Nicht-Diskriminierung, des Autonomiegrades und der dazugehörigen menschlichen Kontrollmechanismen<br><br><br>Tech. Maßnahmen - System / Betrieb<br>- Sicherheitskontrollen zur Verhinderung von Missbrauch und fehlerhafter Nutzung sollten vorgesehen sein und wenn möglich vor der Produktionsphase implementiert werden. Dies schließt Methoden der Prompt/Output-Filterung bei generativer KI mit ein. Zu Absicherung gegen Datenzugang siehe auch CY1.5<br>- Es muss Vorgesehen sein Inferenzeingaben, Anfragen und Prompts als Teil des Monitoring und Logging aufgezeichnet zu  werden, um im Falle einer Fehlnutzung, einer Kompromittierung oder eines Missbrauchs eine Untersuchung zu ermöglichen.<br>- Red Teaming des gesamten Systems mit Bezug auf Missbrauch oder fehlerhafte Nutzung des KI-Systems sollte durchgeführt werden",
                        "B": "Org. Maßnahmen - Systemnahe Prozesse<br>- Prozesse müssen eingeführt sein um den möglichen beabsichtigten Missbrauchs des KI-Systems im Betrieb adressieren zu können, einschließlich der Einbindung möglicher Abschaltungsmechanismen <br>- Prozesse sollten eingeführt sein, um eine durch Monitoringsysteme und Logging festgestellte fehlerhafte Nutzung im Betrieb adressieren zu können<br>- Prozesse sollten insbesondere darauf achten, dass neben der Funktionalität, Integrität und Verfügbarkeit des KI-Systems auch die unter den unterschiedlichen Qualitätsdimensionen definierten Ziele geschützt sind bei fehlerhafter Nutzung oder Missbrauch, also Wahrung des Schutzes personenbezogener oder proprietärer Daten, des Schutzes vor Nicht-Diskriminierung, des Autonomiegrades und der dazugehörigen Menschlichen Kontrollmechanismen<br><br><br>Tech. Maßnahmen - Betrieb<br>- Es muss Vorgesehen sein Inferenzeingaben, Anfragen und Prompts als Teil des Monitoring und Logging aufgezeichnet zu  werden, um im Falle einer Fehlnutzung, einer Kompromittierung oder eines Missbrauchs eine Untersuchung zu ermöglichen.",
                        "C": "Org. Maßnahmen - Systemnahe Prozesse<br>- Prozesse müssen eingeführt sein um den möglichen beabsichtigten Missbrauchs des KI-Systems im Betrieb adressieren zu können, einschließlich der Einbindung möglicher Abschaltungsmechanismen <br>- Prozesse sollten eingeführt sein, um eine durch Monitoringsysteme und Logging festgestellte fehlerhafte Nutzung im Betrieb adressieren zu können<br>- Prozesse sollten insbesondere darauf achten, dass neben der Funktionalität, Integrität und Verfügbarkeit des KI-Systems auch die unter den unterschiedlichen Qualitätsdimensionen definierten Ziele geschützt sind bei fehlerhafter Nutzung oder Missbrauch, also Wahrung des Schutzes personenbezogener oder proprietärer Daten, des Schutzes vor Nicht-Diskriminierung, des Autonomiegrades und der dazugehörigen Menschlichen Kontrollmechanismen",
                        "D": "Es sind keine Maßnahmen vorhanden um fehlerhafte Nutzung und Missbrauch des KI-Systems zu verhindern",
                        "docs_id": "55",
                        "reference": "System",
                        "type": "Maßnahme",
                        "weighting": "Normal",
                        "links": "VE2.5 (derselbe Indikator)",
                        "criterion": "CY1",
                        "dimension": "CY"
                    },
                    "CY1.5": {
                        "title": "Es müssen Maßnahmen und Sicherheitskontrollen vorhanden sein, die den Zugang zu Trainings-, Test-, Validierungs-, und allen anderen KI-spezifischen Daten regeln",
                        "tooltip": "",
                        "A": "Org. Maßnahme  - Governance<br>- Die individuellen Zugriffsrechte auf die Daten müssen festgelegt und dokumentiert werden und mit dem Zweck des KI-Systems übereinstimmen (siehe auch CY1.2)<br>-  ein entsprechendes Zugriffsmanagement sollte mindestens beinhalten:<br>a) Gewährung und Änderung (Provisionierung) von Zugriffsberechtigungen basierend auf dem Prinzip der minimalen Rechtevergabe und dem Need-to-know-Prinzip;<br>b) Trennung von Aufgaben;<br>c) Zugang zu Daten für unbefugte Subjekte wird verweigert;<br>d) Regelmäßige Überprüfung der gewährten Berechtigungen;<br>e) Entzug von Berechtigungen bei Änderungen im Beschäftigungsverhältnis oder der Rolle des Mitarbeiters <br>f) Im Falle von personenbezogenen Daten, die Möglichkeit der betroffenen Personen Zugriff auf ihre Daten zu erhalten, siehe auch MA1.3<br>g) Die Dokumentation der Daten sollte Details zum Zugangsmanagement beinhalten, siehe DA1.1<br><br><br>Tech. Maßnahme - Daten<br>- technische Maßnahmen wie ein Zugriffsmanagementsystem müssen definiert und vorhanden sein, um den Zugriff auf personenbezogene und proprietäre Trainings-, Test-, Validierungs-, und  anderen KI-spezifischen Daten durch nicht autorisierte Personen zu verhindern<br>- Die Übermittlung von personenbezogenen oder proprietären Daten zwischen Parteien oder in eine Cloud muss gesichert werden, mindestens durch<br>a) Nutzung und Dokumentierung von Verschlüsselungsverfahren für die Übertragung (Daten in Bewegung)<br>b) Implementierung technischer Schutzmaßnahmen für die Kommunikationssicherheit<br><br><br>Tech. Maßnahme - Betrieb<br>- technische Maßnahmen müssen definiert und vorgesehen sein, um den Zugriff auf personenbezogene und proprietäre Trainings-, Test-, Validierungs-, und  anderen KI-spezifischen Daten durch nicht autorisierte Personen während des Betriebs des KI-Systems zu verhindern, einschließlich Eingabe- und Ausgabedaten des KI-Systems",
                        "B": "Org. Maßnahme  - Governance<br>- Die individuellen Zugriffsrechte auf die Daten müssen festgelegt und dokumentiert werden und mit dem Zweck des KI-Systems übereinstimmen  (siehe auch CY1.2)<br>-  ein entsprechendes Zugriffsmanagement sollte mindestens beinhalten:<br>a) Gewährung und Änderung (Provisionierung) von Zugriffsberechtigungen basierend auf dem Prinzip der minimalen Rechtevergabe und dem Need-to-know-Prinzip;<br>b) Trennung von Aufgaben;<br>c) Zugang zu Daten für unbefugte Subjekte wird verweigert;<br>d) Regelmäßige Überprüfung der gewährten Berechtigungen;<br>e) Entzug von Berechtigungen bei Änderungen im Beschäftigungsverhältnis oder der Rolle des Mitarbeiters <br>f) Im Falle von personenbezogenen Daten, die Möglichkeit der betroffenen Personen Zugriff auf ihre Daten zu erhalten, siehe auch MA1.3<br>g) Die Dokumentation der Daten sollte Details zum Zugangsmanagement beinhalten, siehe DA1.1<br><br><br>Tech. Maßnahme - Daten<br>- technische Maßnahmen wie ein Zugriffsmanagementsystem müssen definiert und vorhanden sein, um den Zugriff auf personenbezogene und proprietäre Trainings-, Test-, Validierungs-, und  anderen KI-spezifischen Daten durch nicht autorisierte Personen zu verhindern<br>- Die Übermittlung von personenbezogenen oder proprietären Daten zwischen Parteien oder in eine Cloud muss gesichert werden, mindestens durch<br>a) Nutzung und Dokumentierung von Verschlüsselungsverfahren für die Übertragung (Daten in Bewegung)<br>b) Implementierung technischer Schutzmaßnahmen für die Kommunikationssicherheit",
                        "C": "Org. Maßnahme  - Governance<br>- Die individuellen Zugriffsrechte auf die Daten müssen festgelegt und dokumentiert werden und mit dem Zweck des KI-Systems übereinstimmen  (siehe auch CY1.2)<br><br><br>Tech. Maßnahme - Daten<br>- technische Maßnahmen wie ein Zugriffsmanagementsystem müssen definiert und vorhanden sein, um den Zugriff auf personenbezogene und proprietäre Trainings-, Test-, Validierungs-, und  anderen KI-spezifischen Daten durch nicht autorisierte Personen zu verhindern<br>- Die Übermittlung von personenbezogenen oder proprietären Daten zwischen Parteien oder in eine Cloud muss gesichert werden, mindestens durch<br>a) Nutzung und Dokumentierung von Verschlüsselungsverfahren für die Übertragung (Daten in Bewegung)<br>b) Implementierung technischer Schutzmaßnahmen für die Kommunikationssicherheit",
                        "D": "Es wurden keine Maßnahmen ergriffen oder Sicherheitskontrollen eingeführt um den Zugang zu KI-spezifischen Daten zu regeln.",
                        "docs_id": "56",
                        "reference": "Komponente",
                        "type": "Maßnahme",
                        "weighting": "Maximalwert",
                        "links": "CY1.2 (CSMS), CY2.3 (Angriffe auf die Trainingsphase) DA2.1, DA2.2, DA3.2, MA1.3",
                        "criterion": "CY1",
                        "dimension": "CY"
                    },
                    "CY1.6": {
                        "title": "Es muss bewertet werden, ob die ergriffenen Maßnahmen die festgestellten Risiken auf ein annehmbares Maß vermindert haben und die Qualität des KI-Systems den gesetzten Zielvorgaben entspricht",
                        "tooltip": "",
                        "A": "Bewertung<br>- Zusammenfassende Betrachtung der Effekte der Durchführung der technischen und organisatorischen Maßnahmen<br>- Abwägung von Wechselwirkungen der ergriffenen Maßnahmen, und Abwägung der Mitigation der Risiken im Zusammenspiel mit den Risiken anderer Qualitätsdimensionen<br>- Ermittlung und Beschreibung des Restrisikos nach Durchführung der technischen und organisatorischen Maßnahmen<br>- Einschätzung durch eine qualifizierte und autorisierte Person, ob das Restrisiko tolerierbar ist<br>- Begründung der Tolerierbarkeit des Restrisikos",
                        "B": "Bewertung<br>- Abwägung von Wechselwirkungen der ergriffenen Maßnahmen, und Abwägung der Mitigation der Risiken im Zusammenspiel mit den Risiken anderer Qualitätsdimensionen<br>- Einschätzung durch eine qualifizierte und autorisierte Person, ob das Restrisiko tolerierbar ist<br>- Begründung der Tolerierbarkeit des Restrisikos",
                        "C": "Bewertung<br>- Einschätzung durch eine qualifizierte und autorisierte Person, ob das Restrisiko tolerierbar ist<br>- Begründung der Tolerierbarkeit des Restrisikos",
                        "D": "Eine Bewertung wurde nicht durchgeführt",
                        "docs_id": "57",
                        "reference": "System",
                        "type": "Bewertung",
                        "weighting": "Maximalwert",
                        "links": "",
                        "criterion": "CY1",
                        "dimension": "CY"
                    }
                },
                "title": "Allgemeine KI-spezifische Cybersicherheit"
            },
            {
                "index": "CY2",
                "criterion_type_id": 61,
                "indicators": {
                    "CY2.1": {
                        "title": "Risiken für die Cybersicherheit des KI-Systems durch KI-spezifische Angriffe müssen unter Beachtung des Verwendungszwecks analysiert werden. ",
                        "tooltip": "Wichtige Standards sind zum Beispiel  BSI Grundschutz, ISO 27k series, IEC 62443, ISO/SAE 21434, ETSI EN 303 645, NIST AI RMF, ... ",
                        "A": "Analyse - Risiko<br>Detaillierte Risikoanalyse zur Cybersicherheit einschließlich Quantifizierung von Eintrittswahrscheinlichkeiten und Risiken:<br>- Identifikation der möglichen Risiken und ihrer Ursachen<br>- Zuweisung der Risikoverantwortung<br>- Schätzung der Eintrittswahrscheinlichkeit<br>- Schätzung der Aufdeckungswahrscheinlichkeit<br>- Schätzung der Auswirkung<br>- Strukturierte Abstufung und Priorisierung der Risiken <br> <br>Die Risikobewertung sollte unter Beachtung des Verwendungszwecks und Anwendungsbereichs (siehe TR1.1) mindestens berücksichtigen:<br>- Analyse aller potenziellen Angriffsszenarien und Angriffsvektoren auf die KI-Elemente des Systems, einschließlich KI-spezifische Angriffe  (z.B. Evasion Attacks oder Data Poisoning) oder klassische Angriffe (z.B. in KI-Softwarebibliotheken eingebettete Malware) <br><br>Das Risikobewertungsframework sollte möglichst in ein Cybersicherheitsmanagementsystem eingebettet werden können und dabei idealerweise bekannten Standards folgen.",
                        "B": "Analyse - Risiko<br>Limitierte Risikoanalyse mit Fokus auf den Schutzbedarf ohne Quantifizierung von Wahrscheinlichkeiten<br>- Identifikation der möglichen Risiken<br>- Zuweisung der Risikoverantwortung<br>- Schätzung der Auswirkung<br>- Strukturierte Abstufung und Priorisierung der Risiken<br><br>Die Risikobewertung sollte unter Beachtung des Verwendungszwecks und Anwendungsbereichs (siehe TR1.1) mindestens berücksichtigen:<br>- Analyse aller potenziellen Angriffsszenarien und Angriffsvektoren auf die KI-Elemente des Systems, einschließlich KI-spezifische Angriffe  (z.B. Evasion Attacks oder Data Poisoning) oder klassische Angriffe (z.B. in KI-Softwarebibliotheken eingebettete Malware) . <br><br>Das Risikobewertungsframework sollte möglichst in ein Cybersicherheitsmanagementsystem eingebettet werden können und dabei idealerweise bekannten Standards folgen.",
                        "C": "Analyse - Risiko<br>Hauptsächlich qualitative Abschätzung ohne Wahrscheinlichkeiten<br>- Identifikation der möglichen Risiken<br>- Zuweisung der Risikoverantwortung<br>- Qualitative Schätzung der Auswirkung<br>- Qualitative Abstufung und Priorisierung der Risiken<br><br>Die Risikobewertung sollte unter Beachtung des Verwendungszwecks und Anwendungsbereichs (siehe TR1.1) mindestens berücksichtigen:<br>- Analyse aller potenziellen Angriffsszenarien und Angriffsvektoren auf die KI-Elemente des Systems, einschließlich KI-spezifische  (z.B. Evasion Attacks oder Data Poisoning) oder klassische Angriffe (z.B. in KI-Softwarebibliotheken eingebettete Malware) <br><br>Das Risikobewertungsframework sollte möglichst in ein Cybersicherheitsmanagementsystem eingebettet werden können und dabei idealerweise bekannten Standards folgen.",
                        "D": "Es wurde keine Risikoanalyse durchgeführt",
                        "docs_id": "58",
                        "reference": "System",
                        "type": "Analyse",
                        "weighting": "Maximalwert",
                        "links": "TR1.1 (Verwendungszweck)",
                        "criterion": "CY2",
                        "dimension": "CY"
                    },
                    "CY2.2": {
                        "title": "Es müssen Maßnahmen und Sicherheitskontrollen vorhanden sein, um KI-spezifische Angriffe die während des Betriebs auftreten können zu mitigieren",
                        "tooltip": "Sicherheitskontrollen und Maßnahmen auf Modellebene können im Detail zum Beispiel sein:<br>Maßnahmen in der Modelarchitektur wie Model hardening durch Distillation, Maßnahmen im Training, wie Adversarielles Training, oder Unsicherheitsmethoden zur Erkennung adversarieller Inputs.<br><br>Sicherheitskontrollen auf Systemeben können zum Beispiel sein:<br> Zugangs-Management, Benutzungsrestriktionen für Anzahl der Aufrufe des Systems, Out-of-distribution Detection, Prompt Filtering<br><br>Für Details zur Taxonomy verschiedener Angriffsarten und Mitigationen siehe zum Beispiel MITRE ATLAS oder NIST AI 100-2 E2023 zu \"Adversarial Machine Learning: A Taxonomy and Terminology of Attacks and Mitigations\" ",
                        "A": "Tech. Maßnahmen - Test (Metriken KI-Modelle Angriffe on Inferenz- und Deploymentphase): <br>Prüfung von durch den Anwendungsbereich begründeter Auswahl und Anzahl an Metriken und Tests der adversariellen Robustheit in Bezug auf Angriffsszenarien in der Inferenz - und Deploymentphase, die gegen Vertraulichkeit, Integrität oder Verfügbarkeit des KI-Systems gerichtet sein können. <br>- Dies schließt eine Prüfung mit Basis- und fortgeschrittenen Methoden mindestens der folgende Angriffsarten ein:<br> a) evasion attacks,<br> b) latency attacks<br> c) model extraction attacks <br> d)  data reconstruction oder property inference attacks<br> e) prompt injection attacks oder jailbreaks <br>- Penetrationstests  von Systemaspekten mit Bezug auf KI-spezifische Angriffe während des Betriebs sollten durchgeführten werden.<br><br>Die ausgewählten Metriken und Tests sollten mindestens die folgenden Merkmale aufweisen:<br>- Methoden sollten für jedes KI-Modell im und für das KI-System als Ganzes angewendet werden, falls dieses einen gesammelten Output erzeugt<br>- wenn durch die Auswahl begründet, sollten die Metriken und Tests sowohl wichtige Basismethoden als auch fortgeschrittene Methoden (hinsichtlich Komplexität, Informationsgehalt, Implementierungsaufwand, z.B. umfangreiches Prüfwerkzeug) umfassen<br>- die ausgewählten Metriken und Tests sollten wenn möglich einen hohen Grad der Automatisierung erlauben<br>- ggf. Festlegung von Schwellenwerten (als Mindestanforderungen an die Funktionalität/Leistung) und Begründung der Schwellenwerte unter Berücksichtigung des Anwendungsbereichs und Verwendungszwecks<br>- falls anwendbar: Abstufung der Metriken und Schwellenwerte nach unterschiedlichen Einsatzszenarien mit Bezug zur Definition des Anwendungsbereichs.<br><br>Tech. Maßnahmen - Modell<br>- angemessene KI-spezifische Sicherheitskontrollen und technische Maßnahmen zur Mitigation des identifizierten Risikos von Angriffen in der Inferenzphase und während des Deployment des KI-Systems müssen auf Modellebene eingeführt werden (z.B. adversarielles Training, Methoden zur Stärkung der Modellrobustheit oder Unsicherheitsmethoden)<br>- es sollten Robustheitsnachweise für jedes KI-Modell geführt werden zu verschiedenen relevanten Angriffsarten<br><br>Tech. Maßnahmen - System<br>- angemessene KI-spezifische oder nicht-KI-spezifische Sicherheitskontrollen zur Mitigation des identifizierten Risikos von Angriffen in der Inferenzphase und während des Deployment des KI-Systems müssen auf Systemebene  eingeführt werden (z.B. Monitoring von Inputs, siehe MA2.3)<br>- klassisches Sicherheitskontrollen des gesamten Systems im Betrieb sollten vorhergesehen und eingeplant sein einschließlich einer Einbindung in ein existierendes CSMS.<br>- Red Teaming des gesamten Systems mit Bezug auf KI-spezifische Angriffe während der Betriebsphase sollten durchgeführten werden",
                        "B": "Tech. Maßnahmen - Test (Metriken KI-Modelle Angriffe on Inferenz- und Deploymentphase): <br>Prüfung von durch den Anwendungsbereich begründeter Auswahl und Anzahl an Metriken und Tests der adversariellen Robustheit in Bezug auf Angriffsszenarien in der Inferenz - und Deploymentphase, die gegen Vertraulichkeit, Integrität oder Verfügbarkeit des KI-Systems gerichtet sein können. <br>- Dies schließt eine Prüfung mit Basis-Methoden mindestens der folgende Angriffsarten ein:<br> a) evasion attacks,<br> b) latency attacks<br> c) model extraction attacks <br> d)  data reconstruction oder property inference attacks<br> e) prompt injection attacks oder jailbreaks <br>- Penetrationstests des gesamten Systems mit Bezug auf KI-spezifische Angriffe während des Betriebs sollten durchgeführten werden.<br><br>Die ausgewählten Metriken und Tests sollten mindestens die folgenden Merkmale aufweisen:<br>- Methoden sollten für jedes KI-Modell im und für das KI-System als Ganzes angewendet werden, falls dieses einen gesammelten Output erzeugt<br>- wenn durch die Auswahl begründet, sollten die Metriken und Tests sowohl wichtige Basismethoden als auch fortgeschrittene Methoden (hinsichtlich Komplexität, Informationsgehalt, Implementierungsaufwand, z.B. umfangreiches Prüfwerkzeug) umfassen<br>- die ausgewählten Metriken und Tests sollten wenn möglich einen hohen Grad der Automatisierung erlauben<br>- ggf. Festlegung von Schwellenwerten (als Mindestanforderungen an die Funktionalität/Leistung) und Begründung der Schwellenwerte unter Berücksichtigung des Anwendungsbereichs und Verwendungszwecks<br>- falls anwendbar: Abstufung der Metriken und Schwellenwerte nach unterschiedlichen Einsatzszenarien mit Bezug zur Definition des Anwendungsbereichs.<br><br>Tech. Maßnahmen - Modell<br>- angemessene KI-spezifische Sicherheitskontrollen zur Mitigation des identifizierten Risikos von Angriffen in der Inferenzphase und während des Deployment des KI-Systems müssen auf Modellebene eingeführt werden (z.B. adversarielles Training, Methoden zur Stärkung der Modellrobustheit oder Unsicherheitsmethoden)<br>- es sollten möglichst Robustheitsnachweise für jedes KI-Modell geführt werden zu verschiedenen relevanten Angriffsarten<br><br>Tech. Maßnahmen - System<br>- angemessene KI-spezifische oder nicht-KI-spezifische Sicherheitskontrollen zur Mitigation des identifizierten Risikos von Angriffen in der Inferenzphase und während des Deployment des KI-Systems müssen auf Systemebene  eingeführt werden. (z.B. Monitoring von Inputs, siehe MA2.3) <br>- klassisches Sicherheitskontrollen des gesamten Systems im Betrieb sollten vorhergesehen und eingeplant sein einschließlich einer Einbindung in ein existierendes CSMS.",
                        "C": "Tech. Maßnahmen - Test (Metriken KI-Modelle Angriffe on Inferenz- und Deploymentphase): <br>Prüfung von durch den Anwendungsbereich begründeter Auswahl und Anzahl an Metriken und Tests der adversariellen Robustheit in Bezug auf Angriffsszenarien in der Inferenz - und Deploymentphase, die gegen Vertraulichkeit, Integrität oder Verfügbarkeit des KI-Systems gerichtet sein können. <br>- Dies schließt eine Prüfung mit Basis-Methoden möglichst der folgende Angriffsarten ein:<br> a) evasion attacks,<br> b) latency attacks<br> c) model extraction attacks <br> d)  data reconstruction oder property inference attacks<br> e) prompt injection attacks oder jailbreaks <br><br>Die ausgewählten Metriken und Tests sollten möglichst die folgenden Merkmale aufweisen:<br>- Methoden können entweder für jedes KI-Modell oder für das KI-System als Ganzes angewendet werden, je nachdem, was sinnvoller und machbar ist <br>- es genügen Basismethoden (hinsichtlich Komplexität, Informationsgehalt, Implementierungsaufwand, z.B. eine simple Metrik) <br>- ggf. Festlegung von Schwellenwerten (als Mindestanforderungen an die Funktionalität/Leistung) und Begründung der Schwellenwerte unter Berücksichtigung des Anwendungsbereichs und Verwendungszwecks<br><br>Tech. Maßnahmen - Modell<br>- angemessene KI-spezifische Sicherheitskontrollen zur Mitigation des identifizierten Risikos von Angriffen in der Inferenzphase und während des Deployment des KI-Systems müssen auf Modellebene eingeführt werden (z.B. adversarielles Training, Methoden zur Stärkung der Modellrobustheit oder Unsicherheitsmethoden)<br>- es sollten Robustheitsnachweise für jedes KI-Modell geführt werden zu verschiedenen relevanten Angriffsarten<br><br>Tech. Maßnahmen - System<br>- angemessene KI-spezifische oder nicht-KI-spezifische Sicherheitskontrollen zur Mitigation des identifizierten Risikos von Angriffen in der Inferenzphase und während des Deployment des KI-Systems müssen auf Systemebene  eingeführt werden. (z.B. Monitoring von Inputs, siehe MA2.3)<br>- klassisches Sicherheitskontrollen des gesamten Systems im Betrieb sollten vorhergesehen und eingeplant sein einschließlich einer Einbindung in ein existierendes CSMS.",
                        "D": "Es wurden keine Maßnahmen ergriffen um KI-spezifische Angriffe während des Betriebs zu mitigieren.",
                        "docs_id": "59",
                        "reference": "System/Komponente",
                        "type": "Maßnahme",
                        "weighting": "Maximalwert",
                        "links": "CY1.1 (Risiko), CY1.2 (CSMS), MA2.3 (Monitoring), VE1.3 (Tests und Maßnahmen zur allgemeinen Robustheit), VE2.2 (Maßnahmen zur Mitigation von Systemfehler- und Ausfall), TR1.4, TR1.3",
                        "criterion": "CY2",
                        "dimension": "CY"
                    },
                    "CY2.3": {
                        "title": "Es müssen Maßnahmen und Sicherheitskontrollen vorhanden sein, um KI-spezifische Angriffe die während der Vorbereitungs- und Modelltrainingsphase der KI-Modelle stattfinden zu mitigieren",
                        "tooltip": "Sicherheitskontrollen auf Modellebene/Dateneben können zum Beispiel sein:<br>Mitigationen, wie zum Beispiel das Filtern auf Data Poisioning oder Suchsysteme für Modell-Backdoors<br><br>Sicherheitskontrollen auf Systemeben können zum Beispiel sein:<br> Access Management, Datensicherheitsmanagement, Out-of-distribution Detection, <br><br>Für Details zur Taxonomy verschiedener Angriffsarten und Mitigationen siehe zum Beispiel MITRE ATLAS oder NIST AI 100-2 E2023 zu \"Adversarial Machine Learning: A Taxonomy and Terminology of Attacks and Mitigations\" ",
                        "A": "Tech. Maßnahmen - Test<br>(Metriken KI-Modelle Angriffsszenarien Vorbereitungs- und Modelltrainingsphase): Prüfung von durch den Anwendungsbereich begründeter Auswahl und Anzahl an Metriken und Tests der adversariellen Robustheit in Bezug auf Angriffsszenarien der Vorbereitungs- und Modelltrainingsphase, die gegen Vertraulichkeit, Integrität oder Verfügbarkeit des KI-Systems gerichtet sein können.  <br>- Dies schließt eine Prüfung mit Basis- und fortgeschrittenen Methoden mindestens der folgende Angriffsarten ein:<br> a) data poisoning<br> b) label poisoning<br> c) KI-spezifische backdoor attacks<br><br>- Penetrationstests von Systemaspekten mit Bezug auf KI-spezifische Angriffe während der Vorbereitungs- und Modelltrainingsphase sollten durchgeführten werden.<br><br>Die ausgewählten Metriken und Tests sollten mindestens die folgenden Merkmale aufweisen:<br>- Methoden sollten für jedes KI-Modell im und für das KI-System als Ganzes angewendet werden, falls dieses einen gesammelten Output erzeugt<br>- wenn durch die Auswahl begründet, sollten die Metriken und Tests sowohl wichtige Basismethoden als auch fortgeschrittene Methoden (hinsichtlich Komplexität, Informationsgehalt, Implementierungsaufwand, z.B. umfangreiches Prüfwerkzeug) umfassen<br>- die ausgewählten Metriken und Tests sollten wenn möglich einen hohen Grad der Automatisierung erlauben<br>- ggf. Festlegung von Schwellenwerten (als Mindestanforderungen an die Funktionalität/Leistung) und Begründung der Schwellenwerte unter Berücksichtigung des Anwendungsbereichs und Verwendungszwecks<br>- falls anwendbar: Abstufung der Metriken und Schwellenwerte nach unterschiedlichen Einsatzszenarien mit Bezug zur Definition des Anwendungsbereichs.<br><br>Tech. Maßnahmen - Modell<br>- angemessene KI-spezifische Sicherheitskontrollen zur Mitigation des identifizierten Risikos von Angriffen in der  Vorbereitungs- und Modelltrainingsphase des KI-Systems müssen auf Modellebene eingeführt werden  (z. B Datenfiltermethoden oder Suchsysteme für Backdoors, Unsicherheitsmethoden)<br>- es sollten Robustheitsnachweise für jedes KI-Modell geführt werden zu verschiedenen relevanten Angriffsarten<br><br>Tech. Maßnahmen - System<br>- angemessene KI-spezifische oder nicht-KI-spezifische Sicherheitskontrollen zur Mitigation des identifizierten Risikos von Angriffen von Angriffen in der  Vorbereitungs- und Modelltrainingsphase des KI-Systems müssen auf Systemebene  eingeführt werden. <br>- klassisches Sicherheitskontrollen des gesamten Systems im Betrieb sollten vorhergesehen und eingeplant sein einschließlich einer Einbindung in ein existierendes CSMS.<br>- Red Teaming des gesamten Systems mit Bezug auf KI-spezifische Angriffe während der Vorbereitungs- und Modelltrainingsphase sollten durchgeführten werden.",
                        "B": "Tech. Maßnahmen - Test (Metriken KI-Modelle Angriffsszenarien Vorbereitungs- und Modelltrainingsphase): <br>Prüfung von durch den Anwendungsbereich begründeter Auswahl und Anzahl an Metriken und Tests der adversariellen Robustheit in Bezug auf Angriffsszenarien der Vorbereitungs- und Modelltrainingsphase, die gegen Vertraulichkeit, Integrität oder Verfügbarkeit des KI-Systems gerichtet sein können.  <br>- Dies schließt eine Prüfung mit Basis-Methoden mindestens der folgende Angriffsarten ein:<br> a) data poisoning<br> b) label poisoning<br> c) KI-spezifische backdoor attacks<br><br>Die ausgewählten Metriken und Tests sollten mindestens die folgenden Merkmale aufweisen:<br>- Methoden sollten für jedes KI-Modell im und für das KI-System als Ganzes angewendet werden, falls dieses einen gesammelten Output erzeugt<br>- wenn durch die Auswahl begründet, sollten die Metriken und Tests sowohl wichtige Basismethoden als auch fortgeschrittene Methoden (hinsichtlich Komplexität, Informationsgehalt, Implementierungsaufwand, z.B. umfangreiches Prüfwerkzeug) umfassen<br><br>- ggf. Festlegung von Schwellenwerten (als Mindestanforderungen an die Funktionalität/Leistung) und Begründung der Schwellenwerte unter Berücksichtigung des Anwendungsbereichs und Verwendungszwecks<br><br><br>Tech. Maßnahmen - Modell<br>- angemessene KI-spezifische Sicherheitskontrollen zur Mitigation des identifizierten Risikos von Angriffen in der  Vorbereitungs- und Modelltrainingsphase des KI-Systems müssen auf Modellebene eingeführt werden  (z. B Datenfiltermethoden oder Suchsysteme für Backdoors, Unsicherheitsmethoden)<br>- es sollten möglichst Robustheitsnachweise für jedes KI-Modell geführt werden zu verschiedenen relevanten Angriffsarten<br><br>Tech. Maßnahmen - System<br>- angemessene KI-spezifische oder nicht-KI-spezifische Sicherheitskontrollen zur Mitigation des identifizierten Risikos von Angriffen von Angriffen in der  Vorbereitungs- und Modelltrainingsphase des KI-Systems müssen auf Systemebene  eingeführt werden. ",
                        "C": "Tech. Maßnahmen - Test (Metriken KI-Modelle Angriffsszenarien Vorbereitungs- und Modelltrainingsphase): <br>Prüfung von durch den Anwendungsbereich begründeter Auswahl und Anzahl an Metriken und Tests der adversariellen Robustheit in Bezug auf Angriffsszenarien der Vorbereitungs- und Modelltrainingsphase, die gegen Vertraulichkeit, Integrität oder Verfügbarkeit des KI-Systems gerichtet sein können.  <br>- Dies schließt eine Prüfung mit Basis-Methoden möglichst der folgende Angriffsarten ein:<br> a) data poisoning<br> b) label poisoning<br> c) KI-spezifische backdoor attacks<br><br>Die ausgewählten Metriken und Tests sollten möglichst die folgenden Merkmale aufweisen:<br>- Methoden können entweder für jedes KI-Modell oder für das KI-System als Ganzes angewendet werden, je nachdem, was sinnvoller und machbar ist <br>- es genügen Basismethoden (hinsichtlich Komplexität, Informationsgehalt, Implementierungsaufwand, z.B. eine simple Metrik) <br>- ggf. Festlegung von Schwellenwerten (als Mindestanforderungen an die Funktionalität/Leistung) und Begründung der Schwellenwerte unter Berücksichtigung des Anwendungsbereichs und Verwendungszwecks<br><br>Tech. Maßnahmen - Modell<br>- angemessene KI-spezifische Sicherheitskontrollen zur Mitigation des identifizierten Risikos von Angriffen in der  Vorbereitungs- und Modelltrainingsphase des KI-Systems müssen auf Modellebene eingeführt werden  (z. B Datenfiltermethoden oder Suchsysteme für Backdoors, Unsicherheitsmethoden)<br>- es sollten möglichst Robustheitsnachweise für jedes KI-Modell geführt werden zu verschiedenen relevanten Angriffsarten<br><br>Tech. Maßnahmen - System<br>- angemessene KI-spezifische oder nicht-KI-spezifische Sicherheitskontrollen zur Mitigation des identifizierten Risikos von Angriffen von Angriffen in der  Vorbereitungs- und Modelltrainingsphase des KI-Systems müssen auf Systemebene  eingeführt werden. ",
                        "D": "Es wurden keine Maßnahmen ergriffen um KI-spezifische Angriffe während der Vorbereitungs- und Modelltrainingsphase zu mitigieren.",
                        "docs_id": "60",
                        "reference": "System/Komponente",
                        "type": "Maßnahme",
                        "weighting": "Maximalwert",
                        "links": "CY1.1 (Risiko), DA1.1 (Risiko), CY1.2 (CSMS), CY1.8 (Datenzugang), VE1.3 (Tests und Maßnahmen zur allgemeinen Robustheit), VE2.2 (Maßnahmen zur Mitigation von Systemfehler- und Ausfall), TR1.4, TR1.3",
                        "criterion": "CY2",
                        "dimension": "CY"
                    },
                    "CY2.4": {
                        "title": "Es muss bewertet werden, ob die ergriffenen Maßnahmen die festgestellten Risiken auf ein annehmbares Maß vermindert haben und die Qualität des KI-Systems den gesetzten Zielvorgaben entspricht",
                        "tooltip": "",
                        "A": "Bewertung<br>- Zusammenfassende Betrachtung der Effekte der Durchführung der technischen und organisatorischen Maßnahmen<br>- Abwägung von Wechselwirkungen der ergriffenen Maßnahmen, und Abwägung der Mitigation der Risiken im Zusammenspiel mit den Risiken anderer Qualitätsdimensionen<br>- Ermittlung und Beschreibung des Restrisikos nach Durchführung der technischen und organisatorischen Maßnahmen<br>- Einschätzung durch eine qualifizierte und autorisierte Person, ob das Restrisiko tolerierbar ist<br>- Begründung der Tolerierbarkeit des Restrisikos",
                        "B": "Bewertung<br>- Abwägung von Wechselwirkungen der ergriffenen Maßnahmen, und Abwägung der Mitigation der Risiken im Zusammenspiel mit den Risiken anderer Qualitätsdimensionen<br>- Einschätzung durch eine qualifizierte und autorisierte Person, ob das Restrisiko tolerierbar ist<br>- Begründung der Tolerierbarkeit des Restrisikos",
                        "C": "Bewertung<br>- Einschätzung durch eine qualifizierte und autorisierte Person, ob das Restrisiko tolerierbar ist<br>- Begründung der Tolerierbarkeit des Restrisikos",
                        "D": "Eine Bewertung wurde nicht durchgeführt",
                        "docs_id": "61",
                        "reference": "System",
                        "type": "Bewertung",
                        "weighting": "Maximalwert",
                        "links": "",
                        "criterion": "CY2",
                        "dimension": "CY"
                    }
                },
                "title": "Widerstandsfähigkeit gegen KI-spezifische Angriffe"
            }
        ]
    },
    "VE": {
        "title": "Verlässlichkeit",
        "short_title": "Verlässlichkeit",
        "quality_dimension_id": 60,
        "icon": "reliability",
        "criteria": [
            {
                "index": "VE1",
                "criterion_type_id": 50,
                "indicators": {
                    "VE1.1": {
                        "title": "Risiken, die zu unzureichender Leistungsfähigkeit und Robustheit von KI-Komponenten des KI-Systems führen können, müssen unter Beachtung des Verwendungszwecks analysiert werden. ",
                        "tooltip": "Bei Verwendung von Modellen externer Anbieter Dokumentationen und klare Begründungen zur Validierung bereitstellen<br><br>Im Gegensatz zu VE2.1 geht es hier nicht um die Risiken die aus einem KI-System mit unzureichender Leistungsfähigkeit entstehen, sondern um die Risiken die zu unzureichender Leistungsfähigkeit selber führen und damit den Verwendungszweck gefährden können. <br><br>Risiko = Gefährdung x Wahrscheinlichkeit des Eintritts.",
                        "A": "Analyse - Risiko<br>Detaillierte Risikoanalyse einschließlich Quantifizierung von Eintrittswahrscheinlichkeiten und Risiken:<br>- Identifikation der möglichen Risiken und ihrer Ursachen<br>- Zuweisung der Risikoverantwortung<br>- Schätzung der Eintrittswahrscheinlichkeit<br>- Schätzung der Aufdeckungswahrscheinlichkeit<br>- Schätzung der Auswirkung<br>- Strukturierte Abstufung und Priorisierung der Risiken <br><br>Mindestens die folgenden Risikoquellen sind unter Beachtung des Verwendungszwecks (siehe TR1.1) zu berücksichtigen:<br>- Fehlerhaftes Modelltraining, die falsche Wahl des Modells oder ungeeignete Optimierungs- und Validierungsstrategien <br>- schlecht gewählte Metriken und Tests<br>- Limits im Modelltraining, z.B. durch zu schlechte oder zu wenige Trainings- oder Validierungs- oder Testdaten, Overfitting (direkte/indirekte Analyse)<br>- Limitierungen durch Hardware bei Training und Inferenz<br>- Auswirkung einer Änderung der Zusammensetzung des KI-Systems (Soft - und Hardwareebene), insbesondere Risiken durch Neutraining oder Online-Learning",
                        "B": "Analyse - Risiko<br>Limitierte Risikoanalyse mit Fokus auf den Schutzbedarf ohne Quantifizierung von Wahrscheinlichkeiten<br>- Identifikation der möglichen Risiken<br>- Zuweisung der Risikoverantwortung<br>- Schätzung der Auswirkung<br>- Strukturierte Abstufung und Priorisierung der Risiken<br><br>Mindestens die folgenden Risikoquellen sind unter Beachtung des Verwendungszwecks (siehe TR1.1) zu berücksichtigen:<br>- Fehlerhaftes Modelltraining, die falsche Wahl des Modells oder ungeeignete Optimierungs- und Validierungsstrategien <br>- schlecht gewählte Metriken und Tests<br>- Limits im Modelltraining, z.B. durch zu schlechte oder zu wenige Trainings- oder Validierungs- oder Testdaten, Overfitting<br>- Limitierungen durch Hardware bei Training und Inferenz<br>- Notwendigkeit einer gut kalibrierten Unsicherheitsabschätzung<br>- Auswirkung einer Änderung der Zusammensetzung des KI-Systems (Soft - und Hardwareebene), insbesondere Risiken durch Neutraining oder Online-Learning",
                        "C": "Analyse - Risiko<br>Hauptsächlich qualitative Abschätzung der Gefährdungen ohne Wahrscheinlichkeiten<br>- Identifikation der möglichen Gefährdungen:<br>- Zuweisung der Risikoverantwortung<br>- Qualitative Schätzung der Auswirkung<br>- Qualitative Abstufung und Priorisierung der Gefährdungen<br><br>Mindestens die folgenden Risikoquellen sind unter Beachtung des Verwendungszwecks (siehe TR1.1) zu berücksichtigen:<br>- Fehlerhaftes Modelltraining, die falsche Wahl des Modells oder ungeeignete Optimierungs- und Validierungsstrategien <br>- schlecht gewählte Metriken und Tests<br>- Limits im Modelltraining, z.B. durch zu schlechte oder zu wenige Trainings- oder Validierungs- oder Testdaten, Overfitting<br>- Limitierungen durch Hardware bei Training und Inferenz<br>- Notwendigkeit einer gut kalibrierten Unsicherheitsabschätzung<br>- Auswirkung einer Änderung der Zusammensetzung des KI-Systems (Soft - und Hardwareebene), insbesondere Risiken durch Neutraining oder Online-Learning",
                        "D": "Es wurde keine Risikoanalyse oder Gefährdungsabschätzung durchgeführt",
                        "docs_id": "62",
                        "reference": "Komponente",
                        "type": "Analyse",
                        "weighting": "Maximalwert",
                        "links": "TR1.1, TR1.3",
                        "criterion": "VE1",
                        "dimension": "VE"
                    },
                    "VE1.2": {
                        "title": "Es müssen geeignete Metriken und Tests definiert werden, um zu bewerten, ob die Leistung des KI-Systems die beabsichtigte Funktionsweise realisiert.",
                        "tooltip": "Bei Verwendung von Modellen externer Anbieter Dokumentationen und klare Begründungen zur Validierung bereitstellen<br><br>Die beabsichtigte Funktionsweise sollte sich aus dem Verwendungszweck und Anwendungsbereich ergeben.<br><br>Unterscheidung zwischen Basismethoden und fortgeschrittene Methoden: <br>- In der \"Technische Prüfmethodensammlung.xlsx\" sind einige gängige Methoden gelistet und in Basis- und fortgeschrittene Methoden kategorisiert<br>- Selbst entwickelte Testmethoden werden als fortgeschrittene Methoden anerkannt<br><br>Die ausgewählten Metriken und Tests sollten wenn möglich einen hohen Grad der Automatisierung erlauben",
                        "A": "Analyse - Metriken / Schwellenwerte  [Leistungsfähigkeit]  <br>Durch den Anwendungsbereich begründete Auswahl und Anzahl an Metriken und Tests, je nach Nutzen möglichst unterschiedlicher Kategorien. Dies schließt ein:<br>- statistische Auswertung des KI-Modells oder empirische Auswertung der Systemfunktionalität auf das gesamte KI-System z.B. im Sinne von Nutzerexperimenten oder Befragungen<br>- abhängig vom KI-Modell gewählte passende Methoden zur Unsicherheitsbestimmung oder die Nutzung probabilistischer KI- Modellarchitekturen; Metriken für Kalibrierung von Unsicherheitsbestimmung (z.B. über Konfidenzwerte)<br><br>Die ausgewählten Metriken und Tests sollten möglichst die folgenden Merkmale und Rahmenbedingungen aufweisen:<br>- Methoden sollten für jedes KI-Modell im und für das KI-System als Ganzes angewendet werden, falls dieses einen gesammelten Output erzeugt<br>- wenn durch die Auswahl begründet, sollten die Metriken und Tests sowohl Basismethoden (simple Metrik) und einige fortgeschrittene Methoden (hinsichtlich Informationsgehalt, Aussagekräftigkeit, Implementierungsaufwand, z.B. umfangreiches Prüfwerkzeug - siehe zusätzliche Information) umfassen<br>- Festlegung von Schwellenwerten (als Mindestanforderungen an die Funktionalität/Leistung) und Begründung der Schwellenwerte unter Berücksichtigung des Anwendungsbereichs und Verwendungszwecks (falls anwendbar: Abstufung der Metriken und Schwellenwerte nach unterschiedlichen Einsatzszenarien mit Bezug zur Definition des Anwendungsbereichs)<br><br>Die Begründung der Metriken, Tests und Methoden geht auf folgende Aspekte ein: <br>- Anwendungsbereich, Zweck des KI-Systems, <br>- Modelltyp, <br>- Zusammensetzung des KI-Systems (d.h., Zusammenspiel der Komponenten bzw. Zusammenhang von ML-Modell und Gesamtsystem),  Aufgabenbereich der KI-Systems (z.B. Klassifikation vs. Regression) ",
                        "B": "Analyse - Metriken / Schwellenwerte  [Leistungsfähigkeit]  <br>Durch den Anwendungsbereich begründete Auswahl und Anzahl an Metriken und Tests, je nach Nutzen möglichst unterschiedlicher Kategorien. Dies schließt ein:<br>- statistische Auswertung des KI-Modells oder empirische Auswertung der Systemfunktionalität auf das gesamte KI-System z.B. im Sinne von Nutzerexperimenten oder Befragungen<br>- abhängig vom KI-Modell gewählte passende Methoden zur Unsicherheitsbestimmung oder die Nutzung probabilistischer KI- Modellarchitekturen;  Metriken für Kalibrierung von Unsicherheitsbestimmung (z.B. über Konfidenzwerte)<br><br>Die ausgewählten Metriken und Tests sollten möglichst die folgenden Merkmale und Rahmenbedingungen aufweisen:<br>- Methoden sollten für jedes KI-Modell im und für das KI-System als Ganzes angewendet werden, falls dieses einen gesammelten Output erzeugt<br>- wenn durch die Auswahl begründet, sollten die Metriken und Tests sowohl Basismethoden (simple Metrik) und einige fortgeschrittene Methoden (hinsichtlich Informationsgehalt, Aussagekräftigkeit, Implementierungsaufwand, z.B. umfangreiches Prüfwerkzeug - siehe zusätzliche Information) umfassen<br>- Festlegung von Schwellenwerten (als Mindestanforderungen an die Funktionalität/Leistung) und Begründung der Schwellenwerte unter Berücksichtigung des Anwendungsbereichs und Verwendungszwecks<br><br>Die Begründung der Metriken, Tests und Methoden geht auf folgende Aspekte ein: <br>- Anwendungsbereich, Zweck des KI-Systems, <br>- Modelltyp, <br>- Zusammensetzung des KI-Systems (d.h., Zusammenspiel der Komponenten bzw. Zusammenhang von ML-Modell und Gesamtsystem), Aufgabenbereich der KI-Systems (z.B. Klassifikation vs. Regression) ",
                        "C": "Analyse - Metriken / Schwellenwerte  [Leistungsfähigkeit]  <br>Durch den Anwendungsbereich begründete Auswahl und Anzahl an Metriken und Tests. Dies schließt je nach KI- Modell mindestes eine Methode ein  aus:<br>- statistische Auswertung des KI-Modells oder empirische Auswertung der Systemfunktionalität auf das gesamte KI-System z.B. im Sinne von Nutzerexperimenten oder Befragungen<br><br>Die ausgewählten Metriken und Tests sollten möglichst die folgenden Merkmale und Rahmenbedingungen aufweisen:<br>- Methoden können entweder für jedes KI-Modell oder für das KI-System als Ganzes angewendet werden, je nachdem, was sinnvoller und machbar ist <br>- Es genügen Basismethoden (hinsichtlich Informationsgehalt, Aussagekräftigkeit, Implementierungsaufwand, z.B. umfangreiches Prüfwerkzeug - siehe zusätzliche Information) <br>- Festlegung von Schwellenwerten (als Mindestanforderungen an die Funktionalität/Leistung) und Begründung der Schwellenwerte unter Berücksichtigung des Anwendungsbereichs und Verwendungszwecks<br><br>Die Begründung der Metriken, Tests und Methoden geht auf mindestens einen der folgenden Aspekte ein: <br>- Anwendungsbereich, Zweck des KI-Systems, <br>- Modelltyp, <br>- Zusammensetzung des KI-Systems (d.h., Zusammenspiel der Komponenten bzw. Zusammenhang von ML-Modell und Gesamtsystem), Aufgabenbereich der KI-Systems (z.B. Klassifikation vs. Regression) ",
                        "D": "Es wurden systematisch keine Metriken oder Tests festgelegt, die zur Untersuchung der Leistungsfähigkeit des Systems dienen. ",
                        "docs_id": "63",
                        "reference": "Komponente",
                        "type": "Analyse",
                        "weighting": "Maximalwert",
                        "links": "TR1.3, TR1.4",
                        "criterion": "VE1",
                        "dimension": "VE"
                    },
                    "VE1.3": {
                        "title": "Es müssen geeignete Metriken und Tests  definiert werden, um zu bewerten, ob die Robustheit des KI-Systems die beabsichtigte Funktionsweise realisiert.",
                        "tooltip": "Die beabsichtigte Funktionsweise sollte sich aus dem Verwendungszweck und Anwendungsbereich ergeben.<br><br>Die Begründung der Metriken geht auf zum Beispiel auf folgende Aspekte ein: <br>- Anwendungsbereich, Zweck des KI-Systems, <br>- Modelltyp, <br>- Zusammensetzung des KI-Systems (d.h., Zusammenspiel der Komponenten bzw. Zusammenhang von ML-Modell und Gesamtsystem), - ML-Task (Classification/Regression/Generation/Unsupervised (z.B. Clustering,  Anomaly Detection…)/Reinforcement Learning etc.)<br><br>Für die statistische Auswertung: falls vorhanden auf etablierten Benchmark-Datensätzen, z.B. mit passenden Augmentierungen zur Abdeckung von Robustheitstests <br><br>Unterscheidung zwischen Basismethoden und fortgeschrittene Methoden: <br>- In der \"Technische Prüfmethodensammlung.xlsx\" sind einige gängige Methoden gelistet und in Basis- und fortgeschrittene Methoden kategorisiert<br>- Selbst entwickelte Testmethoden werden als fortgeschrittene Methoden anerkannt<br><br>Die ausgewählten Metriken und Tests sollten wenn möglich einen hohen Grad der Automatisierung erlauben",
                        "A": "Analyse - Metriken / Schwellenwerte [Robustheit] <br><br>Durch den Anwendungsbereich begründete Auswahl und Anzahl an Metriken, Tests und Methoden zur Analyse der Robustheit des Systems, je nach Nutzen möglichst unterschiedlicher Kategorien. Dies schließt ein:<br>- statistische Auswertung der Robustheit des KI-Modells. z.B. zur Bestimmung von Edge-Cases oder empirische Auswertung der Systemfunktionalität z.B. im Sinne von Experimenten zu Extrembedingungen<br>- abhängig vom KI-Modell gewählte passende Methoden zur Unsicherheitsbestimmung oder die Nutzung probabilistischer KI- Modellarchitekturen;  Metriken für Kalibrierung von Unsicherheitsbestimmung  z.B. zur Bewertung von Outliereffekten<br>- Detektion von fehlerhaften Eingaben oder Fehlfunktionen auf Modellebene<br><br>Die ausgewählten Metriken und Tests sollten mindestens die folgenden Merkmale aufweisen:<br>- Methoden sollten für jedes KI-Modell im und für das KI-System als Ganzes angewendet werden, falls dieses einen gesammelten Output erzeugt<br>- wenn durch die Auswahl begründet, sollten die Metriken und Tests sowohl Basismethoden (simple Metrik) und einige fortgeschrittene Methoden (hinsichtlich Informationsgehalt, Aussagekräftigkeit, Implementierungsaufwand, z.B. umfangreiches Prüfwerkzeug - siehe zusätzliche Information) umfassen<br>- Festlegung von Schwellenwerten (als Mindestanforderungen an die Robustheit) und Begründung der Schwellenwerte unter Berücksichtigung des Anwendungsbereichs und Verwendungszwecks (falls anwendbar: Abstufung der Metriken und Schwellenwerte nach unterschiedlichen Einsatzszenarien mit Bezug zur Definition des Anwendungsbereichs)<br><br>Die Begründung der Metriken, Tests und Methoden geht auf folgende Aspekte ein: <br>- Anwendungsbereich, Zweck des KI-Systems, <br>- Modelltyp, <br>- Zusammensetzung des KI-Systems (d.h., Zusammenspiel der Komponenten bzw. Zusammenhang von ML-Modell und Gesamtsystem), Aufgabenbereich der KI-Systems (z.B. Klassifikation vs. Regression) ",
                        "B": "Analyse - Metriken / Schwellenwerte [Robustheit] <br><br>Durch den Anwendungsbereich begründete Auswahl und Anzahl an Metriken und Tests, je nach Nutzen möglichst unterschiedlicher Kategorien. Dies schließt ein:<br>- statistische Auswertung des KI-Modells oder empirische Auswertung der Systemfunktionalität auf das gesamte KI-System z.B. im Sinne von Nutzerexperimenten oder Befragungen<br>-  abhängig vom KI-Modell gewählte passende Methoden zur Unsicherheitsbestimmung oder die Nutzung probabilistischer KI- Modellarchitekturen;  Metriken für Kalibrierung von Unsicherheitsbestimmung z.B. zur Bewertung von Outliereffekten<br>- Detektion von fehlerhaften Eingaben oder Fehlfunktionen auf Modellebene <br><br>Die ausgewählten Metriken und Tests sollten möglichst die folgenden Merkmale aufweisen:<br>- Methoden sollten für jedes KI-Modell im und für das KI-System als Ganzes angewendet werden, falls dieses einen gesammelten Output erzeugt<br>- wenn durch die Auswahl begründet, sollten die Metriken und Tests sowohl Basismethoden (simple Metrik) und einige fortgeschrittene Methoden (hinsichtlich Informationsgehalt, Aussagekräftigkeit, Implementierungsaufwand, z.B. umfangreiches Prüfwerkzeug - siehe zusätzliche Information) umfassen<br>- Festlegung von Schwellenwerten (als Mindestanforderungen an die Funktionalität/Leistung) und Begründung der Schwellenwerte unter Berücksichtigung des Anwendungsbereichs und Verwendungszwecks<br><br>Die Begründung der Metriken, Tests und Methoden geht auf folgende Aspekte ein: <br>- Anwendungsbereich, Zweck des KI-Systems, <br>- Modelltyp, <br>- Zusammensetzung des KI-Systems (d.h., Zusammenspiel der Komponenten bzw. Zusammenhang von ML-Modell und Gesamtsystem), Aufgabenbereich der KI-Systems (z.B. Klassifikation vs. Regression) ",
                        "C": "Analyse - Metriken / Schwellenwerte  [Leistungsfähigkeit]  <br>Durch den Anwendungsbereich begründete Auswahl und Anzahl an Metriken und Tests. Dies schließt je nach KI- Modell mindestes eine Methode ein  aus:<br>- statistische Auswertung des KI-Modells oder empirische Auswertung der Systemfunktionalität auf das gesamte KI-System z.B. im Sinne von Nutzerexperimenten oder Befragungen<br>- Detektion von fehlerhaften Eingaben oder Fehlfunktionen auf Modellebene<br><br><br>Die ausgewählten Metriken und Tests sollten möglichst die folgenden Merkmale aufweisen:<br>- Methoden können entweder für jedes KI-Modell oder für das KI-System als Ganzes angewendet werden, je nachdem, was sinnvoller und machbar ist <br>- Es genügen Basismethoden (hinsichtlich Informationsgehalt, Aussagekräftigkeit, Implementierungsaufwand, z.B. umfangreiches Prüfwerkzeug - siehe zusätzliche Information)<br>- Festlegung von Schwellenwerten (als Mindestanforderungen an die Funktionalität/Leistung) und Begründung der Schwellenwerte unter Berücksichtigung des Anwendungsbereichs und Verwendungszwecks<br><br>Die Begründung der Metriken, Tests und Methoden geht auf folgende Aspekte ein: <br>- Anwendungsbereich, Zweck des KI-Systems, <br>- Modelltyp, <br>- Zusammensetzung des KI-Systems (d.h., Zusammenspiel der Komponenten bzw. Zusammenhang von ML-Modell und Gesamtsystem), Aufgabenbereich der KI-Systems (z.B. Klassifikation vs. Regression) ",
                        "D": "Es wurden systematisch keine Metriken oder Tests festgelegt, die zur Untersuchung der Robustheit des Systems dienen. ",
                        "docs_id": "64",
                        "reference": "Komponente",
                        "type": "Analyse",
                        "weighting": "Normal",
                        "links": "TR1.3, TR1.4, CY2.2, CY2.3 (Tests und Mitigationen zur Robustheit gegen Angriffe)",
                        "criterion": "VE1",
                        "dimension": "VE"
                    },
                    "VE1.4": {
                        "title": "Es muss ein Testplan entwickelt und implementiert sein, der das Prüfen aller vorgesehenen Metriken und Tests umfasst, einschließlich einer Prüfung des KI-Systems unter repräsentativen Bedingungen des Anwendungsbereiches.",
                        "tooltip": "Die Einteilung der Metriken und Methoden in einfach bis fortgeschritten hängt von vielen Details ab, aber orientiert sich grob and Komplexität und erwarteten Informationsgehalt (z.B. einfach Metrik, Benchmark, bis hin zu Expertengetriebene Validierungsansätze wie etwa systematische Schwachstellensuche, visuelle Exploration, Anwendung von XAI-Methoden, etc.)<br><br>Der Grad der Automatisierung der Tests, wenn möglich sollten automatisierbare Methoden bevorzugt eingesetzt werden ",
                        "A": "Orga. Maßnahmen - Systemnahe Prozesse<br>Dokumentierter Testplan für Leistungsfähigkeit und Robustheit, der mindestens die folgenden Punkte definiert (z.B. tabellarisch): <br>- Testobjekte müssen definiert werden (d.h., zu testendes Modell (mit Versionsnummer) oder andere zu testende Komponente/Algorithmus wie etwa eine Unsicherheitsschätzung zur Bewertung von Outliereffekten)<br>- vorgesehene Testmethoden müssen mindestens die in VE1.2-VE1.3 zuvor definierten Metriken und Tests beinhalten und müssen, soweit möglich Leistungsfähigkeit, Robustheit und Unsicherheitsabschätzung abdecken. Je nach zuvor festgestellter Analyse müssen möglicherweise auch fortgeschrittene Methoden im Testplan vorgesehen werden (zum Beispiel hinsichtlich Implementierungsaufwand und Hardwareanforderungen) und die Eigenschaften der Testmethoden klar und im Detail festgehalten sein hinsichtlich Komplexität und Informationsgehalt <br>- ggf. müssen zusätzliche Vorgaben zu den Testparametern festgelegt werden<br>- Verwendeten Testdaten müssen beschrieben werden<br>- die Testumgebung muss eine Prüfung des KI-Systems unter repräsentativen Bedingungen des Anwendungsbereichs erlauben, mit einer hohen Nähe zur späteren Produktivumgebung <br>- Zeitpunkt bzw. Regelmäßigkeit der Tests, einschließlich Vorbereitung von Testplänen für eine zukünftige Betriebsphase des KI-Systems, um die Leistungsfähigkeit und Robustheit des KI-Systems fortwährend testen zu können, insbesondere hinsichtlich auf eine Änderung der Systemzusammensetzung oder sich verändernder Trainingsdaten, siehe VE1.6<br>- Beachtung der Auswirkung möglicher signifikanter Änderungen des KI-Systems in Robustheitstests<br>- die für die Durchführung benötigten Testressourcen (Software- und Hardwareanforderungen) müssen bestimmt und festgehalten sein<br>- verantwortliche Person zur Durchführung und Dokumentation der Tests muss festgelegt sein<br>- Begründung des Testplans mit Bezug auf den Anwendungskontext (einschließlich ggf.. einer ODD) und auf VE1.2-VE1.3 mit einer Argumentation  dass der Testplan alle wichtigen Aspekte der Leistungsfähigkeit und Robustheit (bzgl. aller notwendigen, repräsentativen Szenarien) abdeckt.",
                        "B": "Orga. Maßnahmen - Systemnahe Prozesse<br>Dokumentierter Testplan für Leistungsfähigkeit und Robustheit, der mindestens die folgenden Punkte definiert (z.B. tabellarisch): <br>- Testobjekte müssen definiert werden (d.h., zu testendes Modell (mit Versionsnummer) oder andere zu testende Komponente/Algorithmus wie etwa eine Unsicherheitsschätzung zur Bewertung von Outliereffekten)<br>- Vorgesehene Testmethoden müssen mindestens die in VE1.2-VE1.3 zuvor definierten Metriken und Tests beinhalten und müssen, soweit möglich Leistungsfähigkeit, Robustheit und Unsicherheitsabschätzung abdecken. Je nach zuvor festgestellter Analyse müssen möglicherweise auch fortgeschrittene Methoden im Testplan vorgesehen werden (zum Beispiel hinsichtlich Implementierungsaufwand und Hardwareanforderungen) und die Eigenschaften der Testmethoden klar und im Detail festgehalten sein hinsichtlich Komplexität und Informationsgehalt <br>- ggf. müssen zusätzliche Vorgaben zu den Testparametern festgelegt werden<br>- Verwendeten Testdaten müssen beschrieben werden<br>- Die Testumgebung muss eine Prüfung des KI-Systems unter möglichst repräsentativen Bedingungen des Anwendungsbereichs erlauben, aber nicht unbedingt die endgültige Produktivumgebung genau widerspiegeln<br>- Zeitpunkt bzw. Regelmäßigkeit der Tests, einschließlich Vorbereitung von Testplänen für eine zukünftige Betriebsphase des KI-Systems, um die Leistungsfähigkeit und Robustheit des KI-Systems fortwährend testen zu können, insbesondere hinsichtlich auf eine Änderung der Systemzusammensetzung oder sich verändernder Trainingsdaten, siehe VE1.6<br>- Die für die Durchführung benötigten Testressourcen (Software- und Hardwareanforderungen) müssen bestimmt und festgehalten sein<br>- Verantwortliche Person zur Durchführung und Dokumentation der Tests muss festgelegt sein<br>- Begründung des Testplans mit Bezug auf den Anwendungskontext (einschließlich ggf.. einer ODD) und auf VE1.2-VE1.3",
                        "C": "Orga. Maßnahmen - Systemnahe Prozesse<br>Dokumentierter Testplan für Leistungsfähigkeit und Robustheit, der mindestens die folgenden Punkte definiert (z.B. tabellarisch): <br>- Testobjekte müssen definiert werden (d.h., zu testendes Modell (mit Versionsnummer) oder andere zu testende Komponente/Algorithmus wie etwa eine Unsicherheitsschätzung zur Bewertung von Outliereffekten)<br>- Vorgesehene Testmethoden müssen mindestens die in VE1.2-VE1.3 zuvor definierten Metriken und Tests beinhalten und müssen, soweit möglich Leistungsfähigkeit, Robustheit und Unsicherheitsabschätzung abdecken. Die Eigenschaften der Testmethoden müssen klar und im Detail festgehalten sein hinsichtlich Komplexität und Informationsgehalt <br>- ggf. müssen zusätzliche Vorgaben zu den Testparametern festgelegt werden<br>- Verwendeten Testdaten müssen beschrieben werden<br>- Zeitpunkt bzw. Regelmäßigkeit der Tests, einschließlich Vorbereitung von Testplänen für eine zukünftige Betriebsphase des KI-Systems, um die Leistungsfähigkeit und Robustheit des KI-Systems fortwährend testen zu können, insbesondere hinsichtlich auf eine Änderung der Systemzusammensetzung oder sich verändernder Trainingsdaten, siehe VE1.6<br>- Die für die Durchführung benötigten Testressourcen (Software- und Hardwareanforderungen) müssen bestimmt und festgehalten sein<br>- Verantwortliche Person zur Durchführung und Dokumentation der Tests muss festgelegt sein",
                        "D": "Es wurden keine systematischen Testpläne definiert",
                        "docs_id": "65",
                        "reference": "System/Komponente",
                        "type": "Maßnahme",
                        "weighting": "Normal",
                        "links": "TR1.6 (Entwicklungsprozessdokumentation)",
                        "criterion": "VE1",
                        "dimension": "VE"
                    },
                    "VE1.5": {
                        "title": "Das KI-System muss gemäß dem Testplan mit unterschiedlichen Eingaben, Bedingungen und Umgebungen getestet werden, um seine Leistungsfähigkeit und Robustheit sicherzustellen",
                        "tooltip": "Für die technische Details zur Beschreibung von Anwendungsbereichen siehe z.B. der Fraunhofer KI-Prüfkatalog z.B. [VE-R-RE-RI-01], [VE-R-RE-KR-02], [VE-R-RO-RI-01], [VE-R-RO- KR-01], [VE-R-RO-KR-03] und generell die Testmaßnahmen im Kapitel Verlässlichkeit.",
                        "A": "Tech. Maßnahme - Tests<br>- Formelle Beschreibung des Anwendungsbereichs als Eingabe für Testmethoden (Eingaberaum, Anwendungsbereich mit Verteilung, Anwendungsgrenze, ggfs. Beschreibung einer ODD)<br>- Entlang des Testplans (siehe VE1.4), Analyse der Abdeckung des Anwendungsbereichs (oder ggfls. einer ODD) durch die vorhandenen Testdaten<br>- Beschreibung des gegebenen Formats d.h. die Eingaben, Bedingungen und Umgebungen, auf denen auf Leistungsfähigkeit und Robustheit direkt oder indirekt getestet wird<br>- Durchführung des Tests entlang des Testplans und Dokumentation aller Testergebnisse<br>- Dokumentation von Schwachstellen, dabei mindestens<br>a) Jede aufgrund des Systemdesigns und in Bezug auf den Verwendungszweck unerwartete Minderung in der tatsächlichen Leistungsfähigkeit des KI-Systems<br>b) Grenzen des Eingabebereichs (In welchen Situationen/ bei welchen Eingaben funktioniert das KI-System nur eingeschränkt oder gar nicht mehr?<br>c) Shortcuts in Modellen (falls keine identifiziert wurden ist dies so zu dokumentieren)",
                        "B": "Tech. Maßnahme - Tests<br>- Formelle Beschreibung des Anwendungsbereichs als Eingabe für Testmethoden (Eingaberaum, Anwendungsbereich mit Verteilung, Anwendungsgrenze, ggfls. Beschreibung einer ODD)<br>- Durchführung des Tests entlang des Testplans und Dokumentation aller Testergebnisse<br>- Dokumentation von Schwachstellen, dabei mindestens<br>a) Jede aufgrund des Systemdesigns und in Bezug auf den Verwendungszweck unerwartete Minderung in der tatsächlichen Leistungsfähigkeit des KI-Systems<br>b) Grenzen des Eingabebereichs (In welchen Situationen/ bei welchen Eingaben funktioniert das KI-System nur eingeschränkt oder gar nicht mehr?",
                        "C": "Tech. Maßnahme - Tests<br>- Formelle Beschreibung des Anwendungsbereichs als Eingabe für Testmethoden (Eingaberaum, Anwendungsbereich mit Verteilung, Anwendungsgrenze, ggfls. Beschreibung einer ODD)<br>- Durchführung des Tests entlang des Testplans und Dokumentation aller Testergebnisse",
                        "D": "Es wurden keine dokumentierten Tests durchgeführt.",
                        "docs_id": "66",
                        "reference": "System/Komponente",
                        "type": "Maßnahme",
                        "weighting": "Maximalwert",
                        "links": "TR1.6 (Entwicklungsprozessdokumentation)",
                        "criterion": "VE1",
                        "dimension": "VE"
                    },
                    "VE1.6": {
                        "title": "Ein Monitoring der Leistungsfähigkeit und Robustheit des KI-Systems muss möglich sein",
                        "tooltip": "",
                        "A": "Tech. Maßnahme - Betrieb<br>Eine kontinuierliche Überwachung muss für die Implementierung des  KI-Systems vorgesehen sein und auf Basis entsprechender Protokollierung (siehe TR1.7) umgesetzt werden können. Dies beinhaltet die Erprobung folgenden Möglichkeiten:<br><br>- Monitoring der Leistung inklusive einer Überwachung der Modelle und Daten (d.h. einkommende Produktionsdaten und ggf. sich erweiternde Trainingsdatenbasis)<br>- Monitoring von Verzerrungen inklusive einer Überwachung der Daten (d.h. einkommende Produktionsdaten und ggf. sich erweiternde Trainingsdatenbasis) im Kontext der Vermeidung von ungerechtfertigter Diskriminierung und Verzerrungen<br>- Durchführung von Tests (z.B. Sanity Checks), die im Rahmen des Monitorings eingesetzt werden, um etwa Model und Concept Drift  oder auch schädliche Eingabedaten zu erkennen<br>- Falls anwendbar, Durchführung von Tests zur Erkennung von Missbrauch und schädlichen Eingabedaten<br>- Ggf. Qualitätsüberprüfung der sich erweiternden Trainingsdatenbasis  <br><br>Organisatorische Maßnahme - Systemnahe Prozesse<br>Zusätzlich zur technischen Ermöglichung des Monitorings sollten die folgenden Aspekte vorbereitet werden:<br>- Konzept zur (automatischen) Überwachung und -prüfung größerer Veränderungen am KI-System, inklusive bei Soft- und Hardware-Komponenten, aber insbesondere im Fall von Online Learning<br>- Empfohlene Tests müssen als Teil eines kontinuierlichen Testplans dokumentiert sein, insbesondere im Fall von Online Learning<br>- Falls möglich, Mechanismen in Form sinnvoller Definition von Schwellwerten bzw. Szenarien, bei denen (menschliche) Überprüfung und Mitigationsmaßnahmen eintreten sollten<br>- Mechanismen zum Teilen von neuen Informationen über mögliche sicherheitsrelevante Vorfälle und ihrer Vermeidung ",
                        "B": "Tech. Maßnahme - Betrieb<br>Eine kontinuierliche Überwachung muss für die Implementierung des  KI-Systems vorgesehen sein und auf Basis entsprechender Protokollierung (siehe TR1.7) umgesetzt werden können. Dies beinhaltet die folgenden Möglichkeiten:<br><br>- Monitoring der Leistung inklusive einer Überwachung der Modelle und Daten (d.h. einkommende Produktionsdaten und ggf. sich erweiternde Trainingsdatenbasis)<br>- Monitoring von Verzerrungen inklusive einer Überwachung der Daten (d.h. einkommende Produktionsdaten und ggf. sich erweiternde Trainingsdatenbasis) im Kontext der Vermeidung von ungerechtfertigter Diskriminierung und Verzerrungen<br>- Durchführung von Tests (z.B. Sanity Checks), die im Rahmen des Monitorings eingesetzt werden, um etwa Model und Concept Drift, oder auch schädliche Eingabedaten zu erkennen<br><br>Organisatorische Maßnahme - Systemnahe Prozesse<br>Zusätzlich zur technischen Ermöglichung des Monitorings sollten die folgenden Aspekte vorbereitet werden:<br>- Konzept zur (automatischen) Überwachung und -prüfung größerer Veränderungen am KI-System, inklusive bei Soft- und Hardware-Komponenten, aber insbesondere im Fall von Online Learning<br>- Empfohlene Tests müssen als Teil eines kontinuierlichen Testplans dokumentiert sein, insbesondere im Fall von Online Learning",
                        "C": "Tech. Maßnahme - Betrieb<br>Eine kontinuierliche Überwachung muss für die Implementierung des  KI-Systems vorgesehen sein und auf Basis entsprechender Protokollierung (siehe TR1.7) umgesetzt werden können. Dies beinhaltet die folgenden Möglichkeiten:<br><br>- Monitoring der Leistung inklusive einer Überwachung der Modelle und Daten (d.h. einkommende Produktionsdaten und ggf. sich erweiternde Trainingsdatenbasis)<br>- Monitoring von Verzerrungen inklusive einer Überwachung der Daten (d.h. einkommende Produktionsdaten und ggf. sich erweiternde Trainingsdatenbasis) im Kontext der Vermeidung von ungerechtfertigter Diskriminierung und Verzerrungen<br>- Durchführung von Tests (z.B. Sanity Checks), die im Rahmen des Monitorings eingesetzt werden, um etwa Model und Concept Drift, oder auch schädliche Eingabedaten zu erkennen",
                        "D": "",
                        "docs_id": "67",
                        "reference": "System/Komponente",
                        "type": "Maßnahme",
                        "weighting": "Normal",
                        "links": "VE1.6",
                        "criterion": "VE1",
                        "dimension": "VE"
                    },
                    "VE1.7": {
                        "title": "Es muss bewertet werden, ob die ergriffenen Maßnahmen die festgestellten Risiken auf ein annehmbares Maß vermindert haben und die Qualität des KI-Systems den gesetzten Zielvorgaben entspricht",
                        "tooltip": "",
                        "A": "Bewertung<br>- Zusammenfassende Betrachtung der Effekte der Durchführung der technischen und organisatorischen Maßnahmen<br>- Abwägung von Wechselwirkungen der ergriffenen Maßnahmen, und Abwägung der Mitigation der Risiken im Zusammenspiel mit den Risiken anderer Qualitätsdimensionen<br>- Ermittlung und Beschreibung des Restrisikos nach Durchführung der technischen und organisatorischen Maßnahmen<br>- Einschätzung durch eine qualifizierte und autorisierte Person, ob das Restrisiko tolerierbar ist<br>- Begründung der Tolerierbarkeit des Restrisikos",
                        "B": "Bewertung<br>- Abwägung von Wechselwirkungen der ergriffenen Maßnahmen, und Abwägung der Mitigation der Risiken im Zusammenspiel mit den Risiken anderer Qualitätsdimensionen<br>- Einschätzung durch eine qualifizierte und autorisierte Person, ob das Restrisiko tolerierbar ist<br>- Begründung der Tolerierbarkeit des Restrisikos",
                        "C": "Bewertung<br>- Einschätzung durch eine qualifizierte und autorisierte Person, ob das Restrisiko tolerierbar ist<br>- Begründung der Tolerierbarkeit des Restrisikos",
                        "D": "Eine Bewertung wurde nicht durchgeführt",
                        "docs_id": "68",
                        "reference": "System",
                        "type": "Bewertung",
                        "weighting": "Maximalwert",
                        "links": "",
                        "criterion": "VE1",
                        "dimension": "VE"
                    }
                },
                "title": "Leistungsfähigkeit und Robustheit"
            },
            {
                "index": "VE2",
                "criterion_type_id": 51,
                "indicators": {
                    "VE2.1": {
                        "title": "Risiken für mögliche Folgen einer Fehlfunktion oder eines Ausfalls und für die funktionale Sicherheit des KI-System müssen unter Beachtung des Verwendungszwecks analysiert werden. ",
                        "tooltip": "Hier kann zusätzlich auf die Schutzbedarfsanalyse hingewiesen werden. Es sollte aber beachtet werden, dass hier nicht eine Risikoanalyse vollständig vom Prüfenden durchgeführt werden soll sondern die Existenz einer solchen und deren Umfang bewertet werden soll.<br><br>Hier wäre es möglich auf gängige Standards, z.B. zu funktionalen Sicherheit und Safety hinzuweisen so wie ISO/IEC Guide 51 und das Durchführen einer FMEA (die falls vorhanden hier eigentlich angerechnet werden sollte)<br><br>Mehr Details können im KI-Prüfkatalog des Fraunhofer IAIS Kapitel 8 gefunden werden.<br><br>Klassische Referenz zu funktionaler KI-Sicherheit Amodei 2006.",
                        "A": "Analyse - Risiko<br>Die Risikoanalyse zu möglichen Folgen eine (Teil-) Ausfalls des KI-Systems sowie für die funktionale Sicherheit soll sich mit durch das KI-System erzeugten Gefährdungen und schädlichen Auswirkungen für die Außenwelt durch Fehlfunktion oder Ausfall aufgrund unzureichender Leistungsfähigkeit oder Robustheit beschäftigen. Die Risikoanalyse sollte beinhalten:<br><br>Detaillierte Risikoanalyse einschließlich Quantifizierung von Eintrittswahrscheinlichkeiten und Risiken:<br>- Identifikation der möglichen Risiken und ihrer Ursachen<br>- Zuweisung der Risikoverantwortung<br>- Schätzung der Eintrittswahrscheinlichkeit<br>- Schätzung der Aufdeckungswahrscheinlichkeit<br>- Schätzung der Auswirkung<br>- Strukturierte Abstufung und Priorisierung der Risiken <br><br>Mindestens die folgenden Risikoquellen sind unter Beachtung des Verwendungszwecks (siehe TR1.1) zu berücksichtigen:<br>- für den Verwendungszweck unzureichende Leistungsfähigkeit und Robustheit der KI-Komponenten des KI-Systems (siehe VE1) <br>- Kritikalität des Verwendungszwecks und Anwendungsbereichs in Bezug auf mögliche Schäden und Folgen durch unzureichende Leistungsfähigkeit und Robustheit<br>- mögliche funktionale Gründe für den Ausfall oder Teilausfall des KI-Systems mit deren Eintrittswahrscheinlichkeiten<br>- fehlerhafter (systematisch und zufällig) oder missbräuchlicher Einsatz des KI-Systems außerhalb des Verwendungszwecks<br>- Systemkomponenten mit unmittelbaren Schnittstellen mit dem KI-System (z.B. die Inputdaten liefern oder Outputdaten des KI-Systems verwenden)<br><br>Mögliche Folgen und Schäden die aus Unfallrisiken herrühren können, sollten mindestens berücksichtigt werden für: <br>- Leib & Leben und die körperliche Gesundheit von Menschen<br>- Grundrechte   <br>- Eigentum und Sachen",
                        "B": "Analyse - Risiko<br>Die Risikoanalyse zu möglichen Folgen eine (Teil-) Ausfalls des KI-Systems sowie für die funktionale Sicherheit soll sich mit durch das KI-System erzeugten Gefährdungen und schädlichen Auswirkungen für die Außenwelt durch Fehlfunktion oder Ausfall aufgrund unzureichender Leistungsfähigkeit oder Robustheit beschäftigen. Die Risikoanalyse sollte beinhalten: <br><br>Limitierte Risikoanalyse mit Fokus auf den Schutzbedarf ohne Quantifizierung von Wahrscheinlichkeiten<br>- Identifikation der möglichen Risiken<br>- Zuweisung der Risikoverantwortung<br>- Schätzung der Auswirkung<br>- Strukturierte Abstufung und Priorisierung der Risiken<br><br>Mindestens die folgenden Risikoquellen sind unter Beachtung des Verwendungszwecks (siehe TR1.1) zu berücksichtigen:<br>- für den Verwendungszweck unzureichende Leistungsfähigkeit und Robustheit der KI-Komponenten des KI-Systems (siehe VE1)  (siehe VE1) <br>- Kritikalität des Verwendungszwecks und Anwendungsbereichs in Bezug auf mögliche Schäden und Folgen durch unzureichende Leistungsfähigkeit und Robustheit<br>- mögliche funktionale Gründe für den Ausfall oder Teilausfall des KI-Systems mit deren Eintrittswahrscheinlichkeiten<br>- fehlerhafter (systematisch und zufällig) oder missbräuchlicher Einsatz des KI-Systems außerhalb des Verwendungszwecks<br>- Systemkomponenten mit unmittelbaren Schnittstellen mit dem KI-System (z.B. die Inputdaten liefern oder Outputdaten des KI-Systems verwenden)<br><br>Mögliche Folgen und Schäden die aus Unfallrisiken herrühren können, sollten mindestens berücksichtigt werden für: <br>- Leib & Leben und die körperliche Gesundheit von Menschen<br>- Grundrechte   <br>- Eigentum und Sachen",
                        "C": "Analyse - Risiko<br>Die Risikoanalyse zu möglichen Folgen eine (Teil-) Ausfalls des KI-Systems sowie für die funktionale Sicherheit soll sich mit durch das KI-System erzeugten Gefährdungen und schädlichen Auswirkungen für die Außenwelt durch Fehlfunktion oder Ausfall aufgrund unzureichender Leistungsfähigkeit oder Robustheit beschäftigen. Die Risikoanalyse sollte beinhalten:<br><br>Hauptsächlich qualitative Abschätzung ohne Wahrscheinlichkeiten<br>- Identifikation der möglichen Gefährdungen<br>- Zuweisung der Risikoverantwortung<br>- Qualitative Schätzung der Auswirkung<br>- Qualitative Abstufung und Priorisierung der Gefährdungen<br><br>Mindestens die folgenden Risikoquellen sind unter Beachtung des Verwendungszwecks (siehe TR1.1) zu berücksichtigen:<br>- für den Verwendungszweck unzureichende Leistungsfähigkeit und Robustheit der KI-Komponenten des KI-Systems (siehe VE1)<br>- Kritikalität des Verwendungszwecks und Anwendungsbereichs in Bezug auf mögliche Schäden und Folgen durch unzureichende Leistungsfähigkeit und Robustheit<br>- mögliche funktionale Gründe für den Ausfall oder Teilausfall des KI-Systems mit deren Eintrittswahrscheinlichkeiten<br>- fehlerhafter (systematisch und zufällig) oder missbräuchlicher Einsatz des KI-Systems außerhalb des Verwendungszwecks<br>- Systemkomponenten mit unmittelbaren Schnittstellen mit dem KI-System (z.B. die Inputdaten liefern oder Outputdaten des KI-Systems verwenden)<br><br>Mögliche Folgen und Schäden die aus Unfallrisiken herrühren können, sollten mindestens berücksichtigt werden für: <br>- Leib & Leben und die körperliche Gesundheit von Menschen<br>- Grundrechte   <br>- Eigentum und Sachen",
                        "D": "Es wurde keine Risikoanalyse durchgeführt",
                        "docs_id": "69",
                        "reference": "System",
                        "type": "Analyse",
                        "weighting": "Maximalwert",
                        "links": "",
                        "criterion": "VE2",
                        "dimension": "VE"
                    },
                    "VE2.2": {
                        "title": "Es müssen geeignete technische Maßnahmen im Betrieb des KI-Systems zur Mitigation des Risikos einer Fehlfunktion oder eines Ausfalls des KI-System definiert werden.",
                        "tooltip": "",
                        "A": "Techn. Maßnahme - Betrieb<br>- systemische Redundanz, und Rückfallmechanismen sollten im KI-System für den Betrieb vorgesehen sein (z.B. Umschaltung auf einen sicheren Modus, Not-Aus-Schalter), <br>- Mechanismen für den sicheren Ausfall sollten geplant und wenn möglich schon implementiert sein (z.B. Manipulationsschutz, sicherer Modus), <br>- Schnittstellen des in VE1.6 vorgesehenen Monitoringsystems mit den Rückfall- und Ausfallsystemen sollten sichergestellt sein um das Monitoring von KI-Komponenten mit denen eines größeren IT-Systems verbinden zu können<br>- Schnittstellen für ein Alarmsystem sollten geplant sein (Endbenutzer, Anbieter, zuständige Behörde), <br>- Ausfallsicheres Logging eines unter Betrieb befindlichen Produkts muss unterstützbar sein durch das KI-System (z.B. Blackbox), siehe auch nach TR1.7<br>- Interventionsmaßnahmen (\"incident response\") zur Fehlerbehebung und eine Systemwiederherstellung aus dem Betrieb sollte möglich sein",
                        "B": "Techn. Maßnahme - Betrieb<br>- systemische Redundanz, und Rückfallmechanismen sollten im KI-System für den Betrieb vorgesehen sein (z.B. Umschaltung auf einen sicheren Modus, Not-Aus-Schalter), <br>- Mechanismen für den sicheren Ausfall sollten geplant und wenn möglich schon implementiert sein (z.B. Manipulationsschutz, sicherer Modus), <br>- Schnittstellen des in VE1.6 vorgesehenen Monitoringsystems mit den Rückfall- und Ausfallsystemen sollten sichergestellt sein um das Monitoring von KI-Komponenten mit denen eines größeren IT-Systems verbinden zu können, siehe auch nach TR1.7",
                        "C": "Techn. Maßnahme - Betrieb<br>- Mechanismen für den sicheren Ausfall sollten geplant und wenn möglich schon implementiert sein (z.B. Manipulationsschutz, sicherer Modus), ",
                        "D": "Es wurden keine <br>Maßnahmen ergriffen, es zu ermöglichen im Betrieb das Risiko von Fehlfunktionen und Ausfall zu mitigieren.",
                        "docs_id": "70",
                        "reference": "System",
                        "type": "Analyse",
                        "weighting": "Normal",
                        "links": "MA2.3 (Monitoring), TR1.7(Logging), <br>CY2.2, CY2.3 (Maßnahmen zur Mitigation von Angriffen auf das System)",
                        "criterion": "VE2",
                        "dimension": "VE"
                    },
                    "VE2.3": {
                        "title": "Es müssen geeignete technische <br>Maßnahmen in Form von Metriken und Tests  zur Mitigation des Risikos einer Fehlfunktion oder eines Ausfalls des KI-System definiert werden.",
                        "tooltip": "Unterscheidung zwischen Basismethoden und fortgeschrittene Methoden: <br>- In der  Prüfmethodensammlung sind einige gängige Methoden gelistet und in Basis- und fortgeschrittene Methoden kategorisiert<br>- Selbst entwickelte Testmethoden werden als fortgeschrittene Methoden anerkannt<br><br>Die ausgewählten Metriken und Tests sollten wenn möglich einen hohen Grad der Automatisierung erlauben",
                        "A": "Techn. Maßnahmen - Metriken & Schwellenwerte<br><br>Durch den Anwendungsbereich begründete Auswahl und Anzahl an Metriken und Tests, je nach Nutzen möglichst unterschiedlicher Kategorien. Dies schließt ein:<br>- Methoden, die die Verlässlichkeit der KI-Komponenten fördern/sicherstellen, z.B. gut gewählte Optimierungsmethode, Unsicherheitsbestimmungen (z.B. Konfidenzwerte)<br>- Detektionsmethoden und Abfangen von Fehlern in Checks auf Daten, Modellebene oder auf den Ausgaben einschließlich sinnvoller Schwellenwerte. <br>-  Detektionsmethoden und Abfangen von Fehlern in Checks auf Systemebene einschließlich nicht KI-spezifischer Maßnahmen und sinnvoller Schwellenwerte<br><br><br>Die ausgewählten Metriken und Tests sollten mindestens die folgenden Merkmale aufweisen:<br>- wenn durch die Auswahl begründet, sollten die Metriken und Tests sowohl Basismethoden (simple Metrik) und einige fortgeschrittene Methoden (hinsichtlich Informationsgehalt, Aussagekräftigkeit, Implementierungsaufwand, z.B. umfangreiches Prüfwerkzeug - siehe zusätzliche Information) umfassen<br>- ggf. Festlegung von Schwellenwerten (als Mindestanforderungen an die Funktionalität/Leistung des gesamten Systems) und Begründung der Schwellenwerte unter Berücksichtigung des Anwendungsbereichs und Verwendungszwecks",
                        "B": "Techn. Maßnahmen - Metriken & Schwellenwerte<br><br>Durch den Anwendungsbereich begründete Auswahl und Anzahl an Metriken und Tests, je nach Nutzen möglichst unterschiedlicher Kategorien. Dies schließt ein:<br>- Methoden, die die Verlässlichkeit der KI-Komponenten fördern/sicherstellen, z.B. gut gewählte Optimierungsmethode, Unsicherheitsbestimmung ((z.B. Konfidenzwerte) <br>- Detektionsmethoden und Abfangen von Fehlern in Checks auf Daten, Modellebene oder auf den Ausgaben einschließlich sinnvoller Schwellenwerte. <br><br>Die ausgewählten Metriken und Tests sollten möglichst die folgenden Merkmale aufweisen:<br>- wenn durch die Auswahl begründet, sollten die Metriken und Tests sowohl Basismethoden (simple Metrik) und einige fortgeschrittene Methoden (hinsichtlich Informationsgehalt, Aussagekräftigkeit, Implementierungsaufwand, z.B. umfangreiches Prüfwerkzeug - siehe zusätzliche Information) umfassen<br>- ggf. Festlegung von Schwellenwerten (als Mindestanforderungen an die Funktionalität/Leistung des gesamten Systems) und Begründung der Schwellenwerte unter Berücksichtigung des Anwendungsbereichs und Verwendungszwecks",
                        "C": "Techn. Maßnahmen - Metriken & Schwellenwerte<br><br>Durch den Anwendungsbereich begründete Auswahl und Anzahl an Metriken und Tests. Dies schließt mindestens eine Methode ein aus:<br>- Methoden, die die Verlässlichkeit der KI-Komponenten fördern/sicherstellen, z.B. gut gewählte Optimierungsmethode, Unsicherheitsbestimmung (z.B. Konfidenzwerte) <br>- Detektionsmethoden und Abfangen von Fehlern in Checks auf Daten, Modellebene oder auf den Ausgaben einschließlich sinnvoller Schwellenwerte. <br><br>Die ausgewählten Metriken und Tests sollten möglichst die folgenden Merkmale aufweisen:<br>- es genügen Basismethoden (hinsichtlich Informationsgehalt, Aussagekräftigkeit, Implementierungsaufwand, z.B. eine simple Metrik - siehe zusätzliche Information) <br>- ggf. Festlegung von Schwellenwerten (als Mindestanforderungen an die Funktionalität/Leistung des gesamten Systems) und Begründung der Schwellenwerte unter Berücksichtigung des Anwendungsbereichs und Verwendungszwecks",
                        "D": "Es wurden keine technischen Methoden oder Metriken implementiert um das Risiko von Fehlfunktionen und Ausfall zu mitigieren.",
                        "docs_id": "71",
                        "reference": "System",
                        "type": "Analyse",
                        "weighting": "Normal",
                        "links": "",
                        "criterion": "VE2",
                        "dimension": "VE"
                    },
                    "VE2.4": {
                        "title": "Es müssen geeignete organisatorische Maßnahmen zur Mitigation des Risikos einer Fehlfunktion oder eines Ausfalls des KI-System definiert werden.",
                        "tooltip": "",
                        "A": "Orga. Maßnahmen - Governance<br><br>- Planung von, oder, wo möglich, Einbindung von organisatorischen oder technischen Maßnahmen zur Mitigation von Fehlern in ein Management System, insbesondere hinsichtlich menschlich bedingter systematischer Fehler und fehlerhafter Handlungen während des Lebenszyklus<br>- Planung von Maßnahmen zur Mitigation der Auswirkung zweiter Ordnung auf Stakeholder, einschließlich Kommunikation<br>- Einrichtung eines Incident Response Kanals für zukünftige Kunden, über den sofort (ohne schuldhafte Verzögerung) weitere Mitigationsmaßnahmen ergriffen werden können.<br>- die Mitigationsmaßnahmen sollten Teil einer definierten Strategie sein, die in ein fortlaufendes Governancesystem zum Management von Sicherheitsrisiken eingebunden werden kann",
                        "B": "Orga. Maßnahmen - Governance<br><br>- Planung von, oder, wo möglich, Einbindung von organisatorischen oder technischen Maßnahmen zur Mitigation von Fehlern in ein Management System, insbesondere hinsichtlich menschlich bedingter systematischer Fehler fehlerhafter Handlungen während des Lebenszyklus<br>- die Mitigationsmaßnahmen sollten Teil einer definierten Strategie sein, die in ein fortlaufendes Governancesystem zum Management von Sicherheitsrisiken eingebunden werden kann",
                        "C": "Orga. Maßnahmen - Governance<br><br>- Planung  von organisatorischen oder technischen Maßnahmen zur Mitigation zufälliger Fehler in ein Management System, insbesondere hinsichtlich menschlich bedingter systematischer Fehler und fehlerhafter Handlungen während des Lebenszyklus",
                        "D": "Es wurden keine organisatorischen Methoden vorgesehen, um das Risiko von Fehlfunktionen und Ausfall zu mitigieren.",
                        "docs_id": "72",
                        "reference": "System",
                        "type": "Analyse",
                        "weighting": "Normal",
                        "links": "",
                        "criterion": "VE2",
                        "dimension": "VE"
                    },
                    "VE2.5": {
                        "title": "Im Rahmen der beabsichtigen Funktionsweise und unter Berücksichtigung des Anwendungsbereichs müssen die definierten Maßnahmen vor dem Betrieb getestet werden",
                        "tooltip": "",
                        "A": "Tech. Maßnahme - Test<br>Die in V2.2-V2.4 definierten Mitigationsmaßnahmen und -strategien müssen soweit möglich unter Berücksichtigung des Anwendungsbereichs und Verwendungszwecks getestet und bewertet werden. Dies beinhaltet:<br><br>- Testen und Bewerten von Monitoring und Logging (siehe auch VE1.8) hinsichtlich der in VE2.1 identifizierten Risiken, insbesondere in Bezug auf fehlerhafter Eingaben, falscher Anwendungsumgebungen, externer Änderungen und Extremfälle <br>- Testen von Rückfallmechanismen, Fail-safe Modi und Alarmsystemen definiert in VE2.2, mindestens aber muss die Möglichkeit getestet werden solche Systeme an das KI-System anbinden zu können<br>- wenn anwendbar, Prüfen von Metriken und Tests  zur Mitigation des Risikos einer Fehlfunktion oder eines Ausfalls des KI-System definiert werden, definiert in VE2.3<br>- Dokumentation aller Testergebnisse",
                        "B": "Tech. Maßnahme - Test<br>Die in V2.2-V2.4 definierten Mitigationsmaßnahmen- und Strategien müssen soweit möglich unter Berücksichtigung des Anwendungsbereichs und Verwendungszwecks getestet und bewertet werden. Dies beinhaltet:<br><br>- Testen und Bewerten von Monitoring und Logging (siehe auch VE1.8) hinsichtlich der in VE2.1 identifizierten Risiken, insbesondere in Bezug auf fehlerhafter Eingaben, falscher Anwendungsumgebungen, externen Änderungen und Extremfälle <br>- wenn anwendbar, Prüfen von Metriken und Tests  zur Mitigation des Risikos einer Fehlfunktion oder eines Ausfalls des KI-System definiert werden, definiert in VE2.3<br>- Dokumentation aller Testergebnisse",
                        "C": "Tech. Maßnahme - Test<br>Die in V2.2-V2.4 definierten Mitigationsmaßnahmen- und strategien müssen soweit möglich unter Berücksichtigung des Anwendungsbereichs und Verwendungszwecks getestet und bewertet werden. Dies beinhaltet:<br><br>- Bewerten von Monitoring und Logging (siehe auch VE1.8) und der Mitigationsmaßnahmen in VE2.2-VE2.4 hinsichtlich der in VE2.1 identifizierten Risiken, insbesondere in Bezug auf fehlerhafter Eingaben, falscher Anwendungsumgebungen, externen Änderungen und Extremfälle <br>- Dokumentation aller Testergebnisse",
                        "D": "Es wurden keine Test der technischen Maßnahmen durchgeführt.",
                        "docs_id": "73",
                        "reference": "System/Komponente",
                        "type": "Maßnahme",
                        "weighting": "Maximalwert",
                        "links": "",
                        "criterion": "VE2",
                        "dimension": "VE"
                    },
                    "VE2.6": {
                        "title": "Es müssen Maßnahmen und Sicherheitskontrollen vorhanden sein, um fehlerhafte Nutzung oder Missbrauch des KI-Systems zu verhindern",
                        "tooltip": "",
                        "A": "Org. Maßnahmen - Systemnahe Prozesse<br>- Prozesse müssen eingeführt sein um den möglichen beabsichtigten Missbrauchs des KI-Systems im Betrieb adressieren zu können, einschließlich der Einbindung möglicher Abschaltungsmechanismen im Risikomanagement. <br>- Prozesse sollten eingeführt sein, um eine durch Monitoringsysteme und Logging festgestellte fehlerhafte Nutzung im Betrieb adressieren zu können<br>- Prozesse sollten insbesondere darauf achten, dass neben der Funktionalität, Integrität und Verfügbarkeit des KI-Systems auch die unter den unterschiedlichen Qualitätsdimensionen definierten Ziele geschützt sind bei fehlerhafter Nutzung oder Missbrauch, also Wahrung des Schutzes personenbezogener oder proprietärer Daten, des Schutzes vor Nicht-Diskriminierung, des Autonomiegrades und der dazugehörigen menschlichen Kontrollmechanismen<br><br><br>Tech. Maßnahmen - System / Betrieb<br>- Sicherheitskontrollen zur Verhinderung von Missbrauch und fehlerhafter Nutzung sollten vorgesehen sein und wenn möglich vor der Produktionsphase implementiert werden. Dies schließt Methoden der Prompt/Output-Filterung bei generativer KI mit ein. Zu Absicherung gegen Datenzugang siehe auch CY1.5<br>- Es muss Vorgesehen sein Inferenzeingaben, Anfragen und Prompts als Teil des Monitoring und Logging aufgezeichnet zu  werden, um im Falle einer Fehlnutzung, einer Kompromittierung oder eines Missbrauchs eine Untersuchung zu ermöglichen.<br>- Red Teaming des gesamten Systems mit Bezug auf Missbrauch oder fehlerhafte Nutzung des KI-Systems sollte durchgeführt werden",
                        "B": "Org. Maßnahmen - Systemnahe Prozesse<br>- Prozesse müssen eingeführt sein um den möglichen beabsichtigten Missbrauchs des KI-Systems im Betrieb adressieren zu können, einschließlich der Einbindung möglicher Abschaltungsmechanismen <br>- Prozesse sollten eingeführt sein, um eine durch Monitoringsysteme und Logging festgestellte fehlerhafte Nutzung im Betrieb adressieren zu können<br>- Prozesse sollten insbesondere darauf achten, dass neben der Funktionalität, Integrität und Verfügbarkeit des KI-Systems auch die unter den unterschiedlichen Qualitätsdimensionen definierten Ziele geschützt sind bei fehlerhafter Nutzung oder Missbrauch, also Wahrung des Schutzes personenbezogener oder proprietärer Daten, des Schutzes vor Nicht-Diskriminierung, des Autonomiegrades und der dazugehörigen Menschlichen Kontrollmechanismen<br><br><br>Tech. Maßnahmen - Betrieb<br>- Es muss Vorgesehen sein Inferenzeingaben, Anfragen und Prompts als Teil des Monitoring und Logging aufgezeichnet zu  werden, um im Falle einer Fehlnutzung, einer Kompromittierung oder eines Missbrauchs eine Untersuchung zu ermöglichen.",
                        "C": "Org. Maßnahmen - Systemnahe Prozesse<br>- Prozesse müssen eingeführt sein um den möglichen beabsichtigten Missbrauchs des KI-Systems im Betrieb adressieren zu können, einschließlich der Einbindung möglicher Abschaltungsmechanismen <br>- Prozesse sollten eingeführt sein, um eine durch Monitoringsysteme und Logging festgestellte fehlerhafte Nutzung im Betrieb adressieren zu können<br>- Prozesse sollten insbesondere darauf achten, dass neben der Funktionalität, Integrität und Verfügbarkeit des KI-Systems auch die unter den unterschiedlichen Qualitätsdimensionen definierten Ziele geschützt sind bei fehlerhafter Nutzung oder Missbrauch, also Wahrung des Schutzes personenbezogener oder proprietärer Daten, des Schutzes vor Nicht-Diskriminierung, des Autonomiegrades und der dazugehörigen Menschlichen Kontrollmechanismen",
                        "D": "Es sind keine Maßnahmen vorhanden um fehlerhafte Nutzung und Missbrauch des KI-Systems zu verhindern",
                        "docs_id": "74",
                        "reference": "System/Komponente",
                        "type": "Maßnahme",
                        "weighting": "Normal",
                        "links": "",
                        "criterion": "VE2",
                        "dimension": "VE"
                    },
                    "VE2.7": {
                        "title": "Es muss bewertet werden, ob die ergriffenen Maßnahmen die festgestellten Risiken auf ein annehmbares Maß vermindert haben und die Qualität des KI-Systems den gesetzten Zielvorgaben entspricht",
                        "tooltip": "",
                        "A": "Bewertung<br>- Zusammenfassende Betrachtung der Effekte der Durchführung der technischen und organisatorischen Maßnahmen<br>- Abwägung von Wechselwirkungen der ergriffenen Maßnahmen, und Abwägung der Mitigation der Risiken im Zusammenspiel mit den Risiken anderer Qualitätsdimensionen<br>- Ermittlung und Beschreibung des Restrisikos nach Durchführung der technischen und organisatorischen Maßnahmen<br>- Einschätzung durch eine qualifizierte und autorisierte Person, ob das Restrisiko tolerierbar ist<br>- Begründung der Tolerierbarkeit des Restrisikos",
                        "B": "Bewertung<br>- Abwägung von Wechselwirkungen der ergriffenen Maßnahmen, und Abwägung der Mitigation der Risiken im Zusammenspiel mit den Risiken anderer Qualitätsdimensionen<br>- Einschätzung durch eine qualifizierte und autorisierte Person, ob das Restrisiko tolerierbar ist<br>- Begründung der Tolerierbarkeit des Restrisikos",
                        "C": "Bewertung<br>- Einschätzung durch eine qualifizierte und autorisierte Person, ob das Restrisiko tolerierbar ist<br>- Begründung der Tolerierbarkeit des Restrisikos",
                        "D": "Eine Bewertung wurde nicht durchgeführt",
                        "docs_id": "75",
                        "reference": "System",
                        "type": "Bewertung",
                        "weighting": "Maximalwert",
                        "links": "",
                        "criterion": "VE2",
                        "dimension": "VE"
                    }
                },
                "title": "Rückfallpläne und funktionale Sicherheit "
            }
        ]
    }
}
